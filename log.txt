{"ts":1737231157545,"crit":"DEBUG","id":"nexran","mdc":{},"msg":"Starting app"}
{"ts":1737231157545,"crit":"DEBUG","id":"nexran","mdc":{},"msg":"initialized northbound interface (0.0.0.0:8000"}
{"ts":1737231157545,"crit":"DEBUG","id":"nexran","mdc":{},"msg":"started northbound interface"}
1737231157548 1/RMR [INFO] sends: ts=1737231157 src=service-ricxapp-dc-rmr.ricxapp:4560 target=service-ricplt-e2term-rmr-alpha.ricplt:38000 open=0 succ=0 fail=0 (hard=0 soft=0)
Module loaded
1737231188841 1/RMR [INFO] sends: ts=1737231188 src=service-ricxapp-dc-rmr.ricxapp:4560 target=10.106.64.163:38000 open=0 succ=0 fail=0 (hard=0 soft=0)
1737231188841 1/RMR [INFO] sends: ts=1737231188 src=service-ricxapp-dc-rmr.ricxapp:4560 target=service-ricplt-e2term-rmr-alpha.ricplt:38000 open=0 succ=0 fail=0 (hard=0 soft=0)
1737231188841 1/RMR [INFO] sends: ts=1737231188 src=service-ricxapp-dc-rmr.ricxapp:4560 target=service-ricplt-submgr-rmr.ricplt:4560 open=0 succ=0 fail=0 (hard=0 soft=0)
1737231188841 1/RMR [INFO] sends: ts=1737231188 src=service-ricxapp-dc-rmr.ricxapp:4560 target=service-ricplt-e2mgr-rmr.ricplt:3801 open=0 succ=0 fail=0 (hard=0 soft=0)
1737231188841 1/RMR [INFO] sends: ts=1737231188 src=service-ricxapp-dc-rmr.ricxapp:4560 target=service-ricplt-a1mediator-rmr.ricplt:4562 open=0 succ=0 fail=0 (hard=0 soft=0)
<E2SM-NexRAN-ControlHeader>
    <controlHeaderFormat1>
        <controlMessageId><sliceStatusRequest/></controlMessageId>
    </controlHeaderFormat1>
</E2SM-NexRAN-ControlHeader>
<E2SM-NexRAN-ControlMessage>
    <controlMessageFormat1>
        <sliceStatusRequest>
            <sliceNameList>
            </sliceNameList>
        </sliceStatusRequest>
    </controlMessageFormat1>
</E2SM-NexRAN-ControlMessage>
<E2AP-PDU>
    <initiatingMessage>
        <procedureCode>4</procedureCode>
        <criticality><reject/></criticality>
        <value>
            <RICcontrolRequest>
                <protocolIEs>
                    <RICcontrolRequest-IEs>
                        <id>29</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICrequestID>
                                <ricRequestorID>50526</ricRequestorID>
                                <ricInstanceID>1</ricInstanceID>
                            </RICrequestID>
                        </value>
                    </RICcontrolRequest-IEs>
                    <RICcontrolRequest-IEs>
                        <id>5</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RANfunctionID>1</RANfunctionID>
                        </value>
                    </RICcontrolRequest-IEs>
                    <RICcontrolRequest-IEs>
                        <id>22</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICcontrolHeader>08</RICcontrolHeader>
                        </value>
                    </RICcontrolRequest-IEs>
                    <RICcontrolRequest-IEs>
                        <id>23</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICcontrolMessage>10 00</RICcontrolMessage>
                        </value>
                    </RICcontrolRequest-IEs>
                    <RICcontrolRequest-IEs>
                        <id>21</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICcontrolAckRequest><ack/></RICcontrolAckRequest>
                        </value>
                    </RICcontrolRequest-IEs>
                </protocolIEs>
            </RICcontrolRequest>
        </value>
    </initiatingMessage>
</E2AP-PDU>
<E2SM-KPM-EventTriggerDefinition>
    <eventDefinition-Format1>
        <policyTest-List>
            <Trigger-ConditionIE-Item>
{"ts":1737231201707,"crit":"DEBUG","id":"nexran","mdc":{},"msg":"sent control request (subid=-2115548042,requestor_id=50526,instance_id=1,meid=enB_macro_001_001_0019b0) "}
                <report-Period-IE><ms5120/></report-Period-IE>
            </Trigger-ConditionIE-Item>
        </policyTest-List>
    </eventDefinition-Format1>
</E2SM-KPM-EventTriggerDefinition>
<E2AP-PDU>
    <initiatingMessage>
        <procedureCode>8</procedureCode>
        <criticality><reject/></criticality>
        <value>
            <RICsubscriptionRequest>
                <protocolIEs>
                    <RICsubscriptionRequest-IEs>
                        <id>29</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICrequestID>
                                <ricRequestorID>50526</ricRequestorID>
                                <ricInstanceID>2</ricInstanceID>
                            </RICrequestID>
                        </value>
                    </RICsubscriptionRequest-IEs>
                    <RICsubscriptionRequest-IEs>
                        <id>5</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RANfunctionID>0</RANfunctionID>
                        </value>
                    </RICsubscriptionRequest-IEs>
                    <RICsubscriptionRequest-IEs>
                        <id>30</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICsubscriptionDetails>
                                <ricEventTriggerDefinition>20 48</ricEventTriggerDefinition>
                                <ricAction-ToBeSetup-List>
                                    <ProtocolIE-SingleContainer>
                                        <id>19</id>
                                        <criticality><reject/></criticality>
                                        <value>
                                            <RICaction-ToBeSetup-Item>
                                                <ricActionID>1</ricActionID>
                                                <ricActionType><report/></ricActionType>
                                            </RICaction-ToBeSetup-Item>
                                        </value>
                                    </ProtocolIE-SingleContainer>
                                </ricAction-ToBeSetup-List>
                            </RICsubscriptionDetails>
                        </value>
                    </RICsubscriptionRequest-IEs>
                </protocolIEs>
            </RICsubscriptionRequest>
        </value>
    </initiatingMessage>
</E2AP-PDU>
<E2SM-Zylinium-ControlHeader>
    <controlHeaderFormat1>
        <controlMessageId><maskStatusRequest/></controlMessageId>
    </controlHeaderFormat1>
</E2SM-Zylinium-ControlHeader>
{"ts":1737231201709,"crit":"DEBUG","id":"nexran","mdc":{},"msg":"sent subscription request (xid=50526.2,requestor_id=50526,instance_id=2,meid=enB_macro_001_001_0019b0) "}
<E2SM-Zylinium-ControlMessage>
    <controlMessageFormat1>
        <maskStatusRequest>
        </maskStatusRequest>
    </controlMessageFormat1>
</E2SM-Zylinium-ControlMessage>
<E2AP-PDU>
    <initiatingMessage>
        <procedureCode>4</procedureCode>
        <criticality><reject/></criticality>
        <value>
            <RICcontrolRequest>
                <protocolIEs>
                    <RICcontrolRequest-IEs>
                        <id>29</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICrequestID>
                                <ricRequestorID>50526</ricRequestorID>
                                <ricInstanceID>3</ricInstanceID>
                            </RICrequestID>
                        </value>
                    </RICcontrolRequest-IEs>
                    <RICcontrolRequest-IEs>
                        <id>5</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RANfunctionID>2</RANfunctionID>
                        </value>
                    </RICcontrolRequest-IEs>
                    <RICcontrolRequest-IEs>
{"ts":1737231201710,"crit":"DEBUG","id":"nexran","mdc":{},"msg":"sent control request (subid=-1064953304,requestor_id=50526,instance_id=3,meid=enB_macro_001_001_0019b0) "}
{"ts":1737231201710,"crit":"DEBUG","id":"nexran","mdc":{},"msg":"sent subscription request (xid=50526.4,requestor_id=50526,instance_id=4,meid=enB_macro_001_001_0019b0) "}
{"ts":1737231201711,"crit":"DEBUG","id":"nexran","mdc":{},"msg":"sent control request (subid=761670900,requestor_id=50526,instance_id=5,meid=enB_macro_001_001_0019b0) "}
{"ts":1737231201711,"crit":"DEBUG","id":"nexran","mdc":{},"msg":"added nodeb enB_macro_001_001_0019b0"}
                        <id>22</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICcontrolHeader>10</RICcontrolHeader>
                        </value>
                    </RICcontrolRequest-IEs>
                    <RICcontrolRequest-IEs>
                        <id>23</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICcontrolMessage>20</RICcontrolMessage>
                        </value>
                    </RICcontrolRequest-IEs>
                    <RICcontrolRequest-IEs>
                        <id>21</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICcontrolAckRequest><ack/></RICcontrolAckRequest>
                        </value>
                    </RICcontrolRequest-IEs>
                </protocolIEs>
            </RICcontrolRequest>
        </value>
    </initiatingMessage>
</E2AP-PDU>
<E2SM-Zylinium-EventTriggerDefinition>
    <ranEventDefinition>
    </ranEventDefinition>
</E2SM-Zylinium-EventTriggerDefinition>
<E2AP-PDU>
    <initiatingMessage>
        <procedureCode>8</procedureCode>
        <criticality><reject/></criticality>
        <value>
            <RICsubscriptionRequest>
                <protocolIEs>
                    <RICsubscriptionRequest-IEs>
                        <id>29</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICrequestID>
                                <ricRequestorID>50526</ricRequestorID>
                                <ricInstanceID>4</ricInstanceID>
                            </RICrequestID>
                        </value>
                    </RICsubscriptionRequest-IEs>
                    <RICsubscriptionRequest-IEs>
                        <id>5</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RANfunctionID>2</RANfunctionID>
                        </value>
                    </RICsubscriptionRequest-IEs>
                    <RICsubscriptionRequest-IEs>
                        <id>30</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICsubscriptionDetails>
                                <ricEventTriggerDefinition>00</ricEventTriggerDefinition>
                                <ricAction-ToBeSetup-List>
                                    <ProtocolIE-SingleContainer>
                                        <id>19</id>
                                        <criticality><reject/></criticality>
                                        <value>
                                            <RICaction-ToBeSetup-Item>
                                                <ricActionID>1</ricActionID>
                                                <ricActionType><report/></ricActionType>
                                            </RICaction-ToBeSetup-Item>
                                        </value>
                                    </ProtocolIE-SingleContainer>
                                </ricAction-ToBeSetup-List>
                            </RICsubscriptionDetails>
                        </value>
                    </RICsubscriptionRequest-IEs>
                </protocolIEs>
            </RICsubscriptionRequest>
        </value>
    </initiatingMessage>
</E2AP-PDU>
<E2SM-Zylinium-ControlHeader>
    <controlHeaderFormat1>
        <controlMessageId><maskConfigRequest/></controlMessageId>
    </controlHeaderFormat1>
</E2SM-Zylinium-ControlHeader>
<E2SM-Zylinium-ControlMessage>
    <controlMessageFormat1>
        <maskConfigRequest>
            <dlDefault>0x0</dlDefault>
            <ulDefault>0x0</ulDefault>
            <dlSched>
            </dlSched>
            <ulSched>
            </ulSched>
        </maskConfigRequest>
    </controlMessageFormat1>
</E2SM-Zylinium-ControlMessage>
<E2AP-PDU>
    <initiatingMessage>
        <procedureCode>4</procedureCode>
        <criticality><reject/></criticality>
        <value>
            <RICcontrolRequest>
                <protocolIEs>
                    <RICcontrolRequest-IEs>
                        <id>29</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICrequestID>
{"ts":1737231201713,"crit":"DEBUG","id":"nexran","mdc":{},"msg":"RMR message (type 12041, source enB_macro_001_001_0019b0)"}
                                <ricRequestorID>50526</ricRequestorID>
                                <ricInstanceID>5</ricInstanceID>
                            </RICrequestID>
                        </value>
                    </RICcontrolRequest-IEs>
                    <RICcontrolRequest-IEs>
                        <id>5</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RANfunctionID>2</RANfunctionID>
                        </value>
                    </RICcontrolRequest-IEs>
                    <RICcontrolRequest-IEs>
                        <id>22</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICcontrolHeader>00</RICcontrolHeader>
                        </value>
                    </RICcontrolRequest-IEs>
                    <RICcontrolRequest-IEs>
                        <id>23</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICcontrolMessage>00 00 02 30 78 30 00 02 30 78 30 00 00 00 00</RICcontrolMessage>
                        </value>
                    </RICcontrolRequest-IEs>
                    <RICcontrolRequest-IEs>
                        <id>21</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICcontrolAckRequest><ack/></RICcontrolAckRequest>
                        </value>
                    </RICcontrolRequest-IEs>
                </protocolIEs>
            </RICcontrolRequest>
        </value>
    </initiatingMessage>
</E2AP-PDU>
<E2AP-PDU>
    <successfulOutcome>
        <procedureCode>4</procedureCode>
        <criticality><reject/></criticality>
        <value>
            <RICcontrolAcknowledge>
                <protocolIEs>
                    <RICcontrolAcknowledge-IEs>
                        <id>29</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICrequestID>
                                <ricRequestorID>50526</ricRequestorID>
                                <ricInstanceID>1</ricInstanceID>
                            </RICrequestID>
                        </value>
                    </RICcontrolAcknowledge-IEs>
                    <RICcontrolAcknowledge-IEs>
                        <id>5</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RANfunctionID>1</RANfunctionID>
                        </value>
                    </RICcontrolAcknowledge-IEs>
                    <RICcontrolAcknowledge-IEs>
                        <id>24</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICcontrolStatus><success/></RICcontrolStatus>
                        </value>
                    </RICcontrolAcknowledge-IEs>
                    <RICcontrolAcknowledge-IEs>
                        <id>32</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICcontrolOutcome>00</RICcontrolOutcome>
                        </value>
                    </RICcontrolAcknowledge-IEs>
                </protocolIEs>
            </RICcontrolAcknowledge>
        </value>
{"ts":1737231201714,"crit":"INFO","id":"nexran","mdc":{},"msg":"decoded successful outcome RICcontrol (4) "}
{"ts":1737231201714,"crit":"DEBUG","id":"nexran","mdc":{},"msg":"nexran ControlAck handler"}
    </successfulOutcome>
</E2AP-PDU>
<E2SM-NexRAN-ControlOutcome>
    <controlOutcomeFormat1>
        <sliceStatusReport>
            <sliceStatusList>
            </sliceStatusList>
        </sliceStatusReport>
    </controlOutcomeFormat1>
</E2SM-NexRAN-ControlOutcome>
<E2AP-PDU>
    <successfulOutcome>
        <procedureCode>8</procedureCode>
        <criticality><ignore/></criticality>
        <value>
            <RICsubscriptionResponse>
                <protocolIEs>
                    <RICsubscriptionResponse-IEs>
                        <id>29</id>
                        <criticality><reject/></criticality>
{"ts":1737231201719,"crit":"DEBUG","id":"nexran","mdc":{},"msg":"RMR message (type 12011, source enB_macro_001_001_0019b0)"}
                        <value>
                            <RICrequestID>
                                <ricRequestorID>50526</ricRequestorID>
                                <ricInstanceID>7</ricInstanceID>
                            </RICrequestID>
                        </value>
                    </RICsubscriptionResponse-IEs>
                    <RICsubscriptionResponse-IEs>
                        <id>5</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RANfunctionID>0</RANfunctionID>
                        </value>
                    </RICsubscriptionResponse-IEs>
                    <RICsubscriptionResponse-IEs>
                        <id>17</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICaction-Admitted-List>
                                <ProtocolIE-SingleContainer>
                                    <id>14</id>
                                    <criticality><reject/></criticality>
                                    <value>
                                        <RICaction-Admitted-Item>
                                            <ricActionID>1</ricActionID>
                                        </RICaction-Admitted-Item>
                                    </value>
                                </ProtocolIE-SingleContainer>
                            </RICaction-Admitted-List>
                        </value>
                    </RICsubscriptionResponse-IEs>
                </protocolIEs>
            </RICsubscriptionResponse>
        </value>
    </successfulOutcome>
</E2AP-PDU>
{"ts":1737231201720,"crit":"INFO","id":"nexran","mdc":{},"msg":"decoded successful outcome RICsubscription (8) "}
{"ts":1737231201721,"crit":"DEBUG","id":"nexran","mdc":{},"msg":"subscription request succeeded (xid=50526.2,subid=7) "}
{"ts":1737231201721,"crit":"DEBUG","id":"nexran","mdc":{},"msg":"nexran SubscriptionResponse handler"}
{"ts":1737231201754,"crit":"DEBUG","id":"nexran","mdc":{},"msg":"RMR message (type 12041, source enB_macro_001_001_0019b0)"}
<E2AP-PDU>
    <successfulOutcome>
        <procedureCode>4</procedureCode>
        <criticality><reject/></criticality>
        <value>
            <RICcontrolAcknowledge>
                <protocolIEs>
                    <RICcontrolAcknowledge-IEs>
                        <id>29</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICrequestID>
                                <ricRequestorID>50526</ricRequestorID>
                                <ricInstanceID>3</ricInstanceID>
                            </RICrequestID>
                        </value>
                    </RICcontrolAcknowledge-IEs>
                    <RICcontrolAcknowledge-IEs>
                        <id>5</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RANfunctionID>2</RANfunctionID>
                        </value>
                    </RICcontrolAcknowledge-IEs>
                    <RICcontrolAcknowledge-IEs>
                        <id>24</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICcontrolStatus><success/></RICcontrolStatus>
                        </value>
                    </RICcontrolAcknowledge-IEs>
                    <RICcontrolAcknowledge-IEs>
                        <id>32</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICcontrolOutcome>
                                00 00 02 30 78 30 00 00 01 00 00 00 02 30 78 30 
                                00 00 01 00 00 02 30 78 30 00 02 30 78 30 00 00 
                                00 00
                            </RICcontrolOutcome>
                        </value>
                    </RICcontrolAcknowledge-IEs>
                </protocolIEs>
            </RICcontrolAcknowledge>
        </value>
    </successfulOutcome>
</E2AP-PDU>
{"ts":1737231201754,"crit":"INFO","id":"nexran","mdc":{},"msg":"decoded successful outcome RICcontrol (4) "}
<E2SM-Zylinium-ControlOutcome>
    <controlOutcomeFormat1>
        <maskStatusReport>
            <dlMask>
                <mask>0x0</mask>
                <start>0</start>
                <end>0</end>
                <id>0</id>
            </dlMask>
            <ulMask>
                <mask>0x0</mask>
                <start>0</start>
                <end>0</end>
                <id>0</id>
            </ulMask>
            <dlDefault>0x0</dlDefault>
            <ulDefault>0x0</ulDefault>
            <dlSched>
            </dlSched>
            <ulSched>
            </ulSched>
        </maskStatusReport>
    </controlOutcomeFormat1>
</E2SM-Zylinium-ControlOutcome>
{"ts":1737231201755,"crit":"DEBUG","id":"nexran","mdc":{},"msg":"nexran ControlAck handler"}
<E2AP-PDU>
    <successfulOutcome>
        <procedureCode>4</procedureCode>
        <criticality><reject/></criticality>
        <value>
{"ts":1737231201758,"crit":"DEBUG","id":"nexran","mdc":{},"msg":"RMR message (type 12041, source enB_macro_001_001_0019b0)"}
            <RICcontrolAcknowledge>
                <protocolIEs>
                    <RICcontrolAcknowledge-IEs>
                        <id>29</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICrequestID>
                                <ricRequestorID>50526</ricRequestorID>
                                <ricInstanceID>5</ricInstanceID>
                            </RICrequestID>
                        </value>
                    </RICcontrolAcknowledge-IEs>
                    <RICcontrolAcknowledge-IEs>
                        <id>5</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RANfunctionID>2</RANfunctionID>
                        </value>
                    </RICcontrolAcknowledge-IEs>
                    <RICcontrolAcknowledge-IEs>
                        <id>24</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICcontrolStatus><success/></RICcontrolStatus>
                        </value>
                    </RICcontrolAcknowledge-IEs>
                    <RICcontrolAcknowledge-IEs>
                        <id>32</id>
                        <criticality><reject/></criticality>
                        <value>
{"ts":1737231201759,"crit":"INFO","id":"nexran","mdc":{},"msg":"decoded successful outcome RICcontrol (4) "}
                            <RICcontrolOutcome>
                                00 00 02 30 78 30 00 00 01 00 00 00 02 30 78 30 
                                00 00 01 00 00 02 30 78 30 00 02 30 78 30 00 00 
                                00 00
                            </RICcontrolOutcome>
                        </value>
                    </RICcontrolAcknowledge-IEs>
                </protocolIEs>
            </RICcontrolAcknowledge>
        </value>
    </successfulOutcome>
</E2AP-PDU>
<E2SM-Zylinium-ControlOutcome>
    <controlOutcomeFormat1>
        <maskStatusReport>
            <dlMask>
                <mask>0x0</mask>
                <start>0</start>
                <end>0</end>
                <id>0</id>
            </dlMask>
            <ulMask>
                <mask>0x0</mask>
                <start>0</start>
                <end>0</end>
                <id>0</id>
            </ulMask>
            <dlDefault>0x0</dlDefault>
            <ulDefault>0x0</ulDefault>
            <dlSched>
            </dlSched>
            <ulSched>
            </ulSched>
        </maskStatusReport>
    </controlOutcomeFormat1>
</E2SM-Zylinium-ControlOutcome>
{"ts":1737231201759,"crit":"DEBUG","id":"nexran","mdc":{},"msg":"nexran ControlAck handler"}
{"ts":1737231201769,"crit":"DEBUG","id":"nexran","mdc":{},"msg":"RMR message (type 12011, source enB_macro_001_001_0019b0)"}
<E2AP-PDU>
    <successfulOutcome>
        <procedureCode>8</procedureCode>
        <criticality><ignore/></criticality>
        <value>
            <RICsubscriptionResponse>
                <protocolIEs>
                    <RICsubscriptionResponse-IEs>
                        <id>29</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICrequestID>
                                <ricRequestorID>50526</ricRequestorID>
                                <ricInstanceID>8</ricInstanceID>
                            </RICrequestID>
                        </value>
                    </RICsubscriptionResponse-IEs>
                    <RICsubscriptionResponse-IEs>
                        <id>5</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RANfunctionID>2</RANfunctionID>
                        </value>
                    </RICsubscriptionResponse-IEs>
                    <RICsubscriptionResponse-IEs>
                        <id>17</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICaction-Admitted-List>
                                <ProtocolIE-SingleContainer>
                                    <id>14</id>
                                    <criticality><reject/></criticality>
                                    <value>
                                        <RICaction-Admitted-Item>
                                            <ricActionID>1</ricActionID>
                                        </RICaction-Admitted-Item>
                                    </value>
                                </ProtocolIE-SingleContainer>
                            </RICaction-Admitted-List>
                        </value>
                    </RICsubscriptionResponse-IEs>
                </protocolIEs>
            </RICsubscriptionResponse>
        </value>
    </successfulOutcome>
</E2AP-PDU>
{"ts":1737231201771,"crit":"INFO","id":"nexran","mdc":{},"msg":"decoded successful outcome RICsubscription (8) "}
{"ts":1737231201771,"crit":"DEBUG","id":"nexran","mdc":{},"msg":"subscription request succeeded (xid=50526.4,subid=8) "}
{"ts":1737231201771,"crit":"DEBUG","id":"nexran","mdc":{},"msg":"nexran SubscriptionResponse handler"}
{"ts":1737231206741,"crit":"DEBUG","id":"nexran","mdc":{},"msg":"added slice fast"}
<E2AP-PDU>
    <initiatingMessage>
        <procedureCode>5</procedureCode>
        <criticality><reject/></criticality>
        <value>
            <RICindication>
                <protocolIEs>
                    <RICindication-IEs>
                        <id>29</id>
{"ts":1737231206849,"crit":"DEBUG","id":"nexran","mdc":{},"msg":"RMR message (type 12050, source enB_macro_001_001_0019b0)"}
                        <criticality><reject/></criticality>
                        <value>
                            <RICrequestID>
                                <ricRequestorID>123</ricRequestorID>
                                <ricInstanceID>7</ricInstanceID>
                            </RICrequestID>
                        </value>
                    </RICindication-IEs>
                    <RICindication-IEs>
                        <id>5</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RANfunctionID>0</RANfunctionID>
                        </value>
                    </RICindication-IEs>
                    <RICindication-IEs>
                        <id>15</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICactionID>1</RICactionID>
                        </value>
                    </RICindication-IEs>
                    <RICindication-IEs>
                        <id>27</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICindicationSN>1</RICindicationSN>
                        </value>
                    </RICindication-IEs>
                    <RICindication-IEs>
                        <id>28</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICindicationType><report/></RICindicationType>
                        </value>
                    </RICindication-IEs>
{"ts":1737231206850,"crit":"INFO","id":"nexran","mdc":{},"msg":"decoded initiating RICindication (5) "}
                    <RICindication-IEs>
                        <id>26</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICindicationMessage>
                                01 04 00 00 02 40 00 00 60 00 F1 10 00 00 00 00 
                                10 00 64 00 64 02 00 F1 10 80 00 00 00 03 00 5C 
                                00 01 00 00 46 20 04 3C 48 10 13 85 01 03 01 00 
                                03 03 73 50 01 00 01 00 01 00 00 00 00 00 00 00 
                                00 01 00 03 80 02 07 01 0F 06 00 EB 30 0C C1 0C 
                                00 00 47 20 03 ED 48 10 11 F0 01 03 01 00 03 02 
                                D5 78 01 01 01 00 02 10 28 00 00 00 00 00 00 00 
                                01 02 00 01 00 06 00 EB 30 0C C1 15 4A 00 01 50 
                                10 08 00 F1 10 80 01 60 00 10 01 EC 00 00 60 07 
                                30 02 F7 DC 1C 20 06 75 D2 03 00 1A 00 01 00 00 
                                46 30 01 8B 7F 16 20 03 67 4D 00 00 47 30 01 6C 
                                5E F2 20 03 0E 85
                            </RICindicationMessage>
                        </value>
                    </RICindication-IEs>
                    <RICindication-IEs>
                        <id>25</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICindicationHeader>08 00 F1 10</RICindicationHeader>
                        </value>
                    </RICindication-IEs>
                </protocolIEs>
            </RICindication>
        </value>
    </initiatingMessage>
</E2AP-PDU>
<E2SM-KPM-IndicationHeader>
    <indicationHeader-Format1>
        <pLMN-Identity>00 F1 10</pLMN-Identity>
    </indicationHeader-Format1>
</E2SM-KPM-IndicationHeader>
<E2SM-KPM-IndicationMessage>
    <ric-Style-Type>4</ric-Style-Type>
    <indicationMessage>
        <indicationMessage-Format1>
            <pm-Containers>
                <PM-Containers-List>
                    <performanceContainer>
                        <oDU>
                            <cellResourceReportList>
                                <CellResourceReportListItem>
                                    <nRCGI>
                                        <pLMN-Identity>00 F1 10</pLMN-Identity>
                                        <nRCellIdentity>
                                            000000000000000000000000000000000001
                                        </nRCellIdentity>
                                    </nRCGI>
                                    <dl-TotalofAvailablePRBs>100</dl-TotalofAvailablePRBs>
                                    <ul-TotalofAvailablePRBs>100</ul-TotalofAvailablePRBs>
                                    <servedPlmnPerCellList>
                                        <ServedPlmnPerCellListItem>
                                            <pLMN-Identity>00 F1 10</pLMN-Identity>
                                            <du-PM-EPC>
                                                <perQCIReportList>
                                                    <PerQCIReportListItem>
                                                        <qci>0</qci>
                                                    </PerQCIReportListItem>
                                                </perQCIReportList>
                                                <perUEReportList>
                                                    <PerUEReportListItem>
                                                        <rnti>70</rnti>
                                                        <dl-PRBUsage>277576</dl-PRBUsage>
                                                        <ul-PRBUsage>4997</ul-PRBUsage>
                                                        <tx-pkts>3</tx-pkts>
                                                        <tx-errors>0</tx-errors>
                                                        <tx-brate>226128</tx-brate>
                                                        <rx-pkts>0</rx-pkts>
                                                        <rx-errors>0</rx-errors>
                                                        <rx-brate>0</rx-brate>
                                                        <dl-cqi>0</dl-cqi>
                                                        <dl-ri>0</dl-ri>
                                                        <dl-pmi>0</dl-pmi>
                                                        <ul-phr>0</ul-phr>
                                                        <ul-sinr>0</ul-sinr>
                                                        <ul-rssi>0</ul-rssi>
                                                        <ul-mcs>0</ul-mcs>
                                                        <ul-samples>0</ul-samples>
                                                        <dl-mcs>28.0</dl-mcs>
                                                        <dl-samples>15</dl-samples>
                                                        <imsi>1010123456780</imsi>
                                                    </PerUEReportListItem>
                                                    <PerUEReportListItem>
                                                        <rnti>71</rnti>
                                                        <dl-PRBUsage>257352</dl-PRBUsage>
                                                        <ul-PRBUsage>4592</ul-PRBUsage>
                                                        <tx-pkts>3</tx-pkts>
                                                        <tx-errors>0</tx-errors>
                                                        <tx-brate>185720</tx-brate>
                                                        <rx-pkts>1</rx-pkts>
                                                        <rx-errors>0</rx-errors>
                                                        <rx-brate>4136</rx-brate>
                                                        <dl-cqi>0</dl-cqi>
                                                        <dl-ri>0</dl-ri>
                                                        <dl-pmi>0</dl-pmi>
                                                        <ul-phr>0</ul-phr>
                                                        <ul-sinr>0</ul-sinr>
                                                        <ul-rssi>0</ul-rssi>
                                                        <ul-mcs>0</ul-mcs>
                                                        <ul-samples>2</ul-samples>
                                                        <dl-mcs>0</dl-mcs>
                                                        <dl-samples>0</dl-samples>
                                                        <imsi>1010123456789</imsi>
                                                    </PerUEReportListItem>
                                                </perUEReportList>
                                            </du-PM-EPC>
                                        </ServedPlmnPerCellListItem>
                                    </servedPlmnPerCellList>
                                </CellResourceReportListItem>
                            </cellResourceReportList>
                        </oDU>
                    </performanceContainer>
                </PM-Containers-List>
                <PM-Containers-List>
                    <performanceContainer>
                        <oCU-CP>
                            <cu-CP-Resource-Status>
                                <numberOfActive-UEs>2</numberOfActive-UEs>
                            </cu-CP-Resource-Status>
                        </oCU-CP>
                    </performanceContainer>
                </PM-Containers-List>
                <PM-Containers-List>
                    <performanceContainer>
                        <oCU-UP>
                            <pf-ContainerList>
                                <PF-ContainerListItem>
                                    <interface-type><f1-u/></interface-type>
                                    <o-CU-UP-PM-Container>
                                        <plmnList>
                                            <PlmnID-List>
                                                <pLMN-Identity>00 F1 10</pLMN-Identity>
                                                <cu-UP-PM-EPC>
                                                    <perQCIReportList>
                                                        <PerQCIReportListItemFormat>
                                                            <qci>0</qci>
                                                            <pDCPBytesDL>492</pDCPBytesDL>
                                                            <pDCPBytesUL>0</pDCPBytesUL>
                                                        </PerQCIReportListItemFormat>
                                                        <PerQCIReportListItemFormat>
                                                            <qci>7</qci>
                                                            <pDCPBytesDL>49798172</pDCPBytesDL>
                                                            <pDCPBytesUL>423378</pDCPBytesUL>
                                                        </PerQCIReportListItemFormat>
                                                    </perQCIReportList>
                                                    <perUEReportList>
                                                        <PerUEReportListItemFormat>
                                                            <rnti>70</rnti>
                                                            <bytesDL>25919254</bytesDL>
                                                            <bytesUL>223053</bytesUL>
                                                        </PerUEReportListItemFormat>
                                                        <PerUEReportListItemFormat>
                                                            <rnti>71</rnti>
                                                            <bytesDL>23879410</bytesDL>
                                                            <bytesUL>200325</bytesUL>
                                                        </PerUEReportListItemFormat>
                                                    </perUEReportList>
                                                </cu-UP-PM-EPC>
                                            </PlmnID-List>
                                        </plmnList>
                                    </o-CU-UP-PM-Container>
                                </PF-ContainerListItem>
                            </pf-ContainerList>
                        </oCU-UP>
                    </performanceContainer>
                </PM-Containers-List>
            </pm-Containers>
{"ts":1737231206852,"crit":"DEBUG","id":"nexran","mdc":{},"msg":"kpm indication report style 4 "}
{"ts":1737231206852,"crit":"DEBUG","id":"nexran","mdc":{},"msg":"nexran Indication handler"}
        </indicationMessage-Format1>
    </indicationMessage>
</E2SM-KPM-IndicationMessage>
{"ts":1737231206852,"crit":"INFO","id":"nexran","mdc":{},"msg":"KpmIndication: KpmReport(period=5120 ms) available_dl_prbs=100 available_ul_prbs=100 ue[70]={dl_bytes=25919254,ul_bytes=223053,dl_prbs=277576,ul_prbs=4997,tx_pkts=3,tx_errors=0,tx_brate=226128,rx_pkts=0,rx_errors=0,rx_brate=0,dl_cqi=0,dl_ri=0,dl_pmi=0,ul_phr=0,ul_sinr=0,ul_mcs=0,ul_samples=0,dl_mcs=28,dl_samples=15,imsi=1010123456780,} ue[71]={dl_bytes=23879410,ul_bytes=200325,dl_prbs=257352,ul_prbs=4592,tx_pkts=3,tx_errors=0,tx_brate=185720,rx_pkts=1,rx_errors=0,rx_brate=4136,dl_cqi=0,dl_ri=0,dl_pmi=0,ul_phr=0,ul_sinr=0,ul_mcs=0,ul_samples=2,dl_mcs=0,dl_samples=0,imsi=1010123456789,} "}
{"ts":1737231206995,"crit":"DEBUG","id":"nexran","mdc":{},"msg":"no slices in KPM report; not autoequalizing"}
{"ts":1737231206995,"crit":"DEBUG","id":"nexran","mdc":{},"msg":"current shares: fast[share=1024] "}
{"ts":1737231211769,"crit":"DEBUG","id":"nexran","mdc":{},"msg":"added slice secure_slice"}
{"ts":1737231211967,"crit":"DEBUG","id":"nexran","mdc":{},"msg":"RMR message (type 12050, source enB_macro_001_001_0019b0)"}
<E2AP-PDU>
    <initiatingMessage>
        <procedureCode>5</procedureCode>
        <criticality><reject/></criticality>
        <value>
            <RICindication>
                <protocolIEs>
                    <RICindication-IEs>
                        <id>29</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICrequestID>
                                <ricRequestorID>123</ricRequestorID>
                                <ricInstanceID>7</ricInstanceID>
                            </RICrequestID>
                        </value>
                    </RICindication-IEs>
                    <RICindication-IEs>
                        <id>5</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RANfunctionID>0</RANfunctionID>
                        </value>
                    </RICindication-IEs>
                    <RICindication-IEs>
                        <id>15</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICactionID>1</RICactionID>
                        </value>
                    </RICindication-IEs>
                    <RICindication-IEs>
                        <id>27</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICindicationSN>2</RICindicationSN>
                        </value>
                    </RICindication-IEs>
                    <RICindication-IEs>
                        <id>28</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICindicationType><report/></RICindicationType>
                        </value>
                    </RICindication-IEs>
                    <RICindication-IEs>
                        <id>26</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICindicationMessage>
                                01 04 00 00 02 40 00 00 60 00 F1 10 00 00 00 00 
                                10 00 64 00 64 02 00 F1 10 80 00 00 00 03 00 6F 
                                00 01 00 00 46 20 01 13 3C 10 05 08 01 0F 01 00 
                                03 10 A2 B8 01 03 01 00 02 4A 98 03 80 00 0F 00 
                                00 03 80 01 0F 00 00 00 01 03 06 80 EE 00 6F 83 
                                E1 01 21 06 00 EB 30 0C C1 0C 00 00 47 20 01 17 
                                D4 10 04 BE 01 18 01 00 03 1A FC A8 01 02 01 00 
                                02 2B 60 03 80 00 0F 00 00 00 00 00 00 01 02 06 
                                80 ED 00 DE F6 85 01 36 06 00 EB 30 0C C1 15 4A 
                                00 01 50 10 08 00 F1 10 80 01 60 00 00 00 00 00 
                                60 07 20 CB 59 24 20 01 A8 88 03 00 16 00 01 00 
                                00 46 20 65 AC 92 10 D1 D4 00 00 47 20 65 AC 92 
                                10 D6 B4
                            </RICindicationMessage>
                        </value>
                    </RICindication-IEs>
                    <RICindication-IEs>
                        <id>25</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICindicationHeader>08 00 F1 10</RICindicationHeader>
                        </value>
                    </RICindication-IEs>
                </protocolIEs>
            </RICindication>
        </value>
{"ts":1737231211968,"crit":"INFO","id":"nexran","mdc":{},"msg":"decoded initiating RICindication (5) "}
    </initiatingMessage>
</E2AP-PDU>
<E2SM-KPM-IndicationHeader>
    <indicationHeader-Format1>
        <pLMN-Identity>00 F1 10</pLMN-Identity>
    </indicationHeader-Format1>
</E2SM-KPM-IndicationHeader>
<E2SM-KPM-IndicationMessage>
    <ric-Style-Type>4</ric-Style-Type>
    <indicationMessage>
        <indicationMessage-Format1>
            <pm-Containers>
                <PM-Containers-List>
                    <performanceContainer>
                        <oDU>
                            <cellResourceReportList>
                                <CellResourceReportListItem>
                                    <nRCGI>
                                        <pLMN-Identity>00 F1 10</pLMN-Identity>
                                        <nRCellIdentity>
                                            000000000000000000000000000000000001
                                        </nRCellIdentity>
                                    </nRCGI>
                                    <dl-TotalofAvailablePRBs>100</dl-TotalofAvailablePRBs>
                                    <ul-TotalofAvailablePRBs>100</ul-TotalofAvailablePRBs>
                                    <servedPlmnPerCellList>
                                        <ServedPlmnPerCellListItem>
                                            <pLMN-Identity>00 F1 10</pLMN-Identity>
                                            <du-PM-EPC>
                                                <perQCIReportList>
                                                    <PerQCIReportListItem>
                                                        <qci>0</qci>
                                                    </PerQCIReportListItem>
                                                </perQCIReportList>
                                                <perUEReportList>
                                                    <PerUEReportListItem>
                                                        <rnti>70</rnti>
                                                        <dl-PRBUsage>70460</dl-PRBUsage>
                                                        <ul-PRBUsage>1288</ul-PRBUsage>
                                                        <tx-pkts>15</tx-pkts>
                                                        <tx-errors>0</tx-errors>
                                                        <tx-brate>1090232</tx-brate>
                                                        <rx-pkts>3</rx-pkts>
                                                        <rx-errors>0</rx-errors>
                                                        <rx-brate>19096</rx-brate>
                                                        <dl-cqi>15.0</dl-cqi>
                                                        <dl-ri>0</dl-ri>
                                                        <dl-pmi>0</dl-pmi>
                                                        <ul-phr>30.0</ul-phr>
                                                        <ul-sinr>0</ul-sinr>
                                                        <ul-rssi>0</ul-rssi>
                                                        <ul-mcs>0</ul-mcs>
                                                        <ul-samples>3</ul-samples>
                                                        <dl-mcs>27.878787994384766</dl-mcs>
                                                        <dl-samples>33</dl-samples>
                                                        <imsi>1010123456780</imsi>
                                                    </PerUEReportListItem>
                                                    <PerUEReportListItem>
                                                        <rnti>71</rnti>
                                                        <dl-PRBUsage>71636</dl-PRBUsage>
                                                        <ul-PRBUsage>1214</ul-PRBUsage>
                                                        <tx-pkts>24</tx-pkts>
                                                        <tx-errors>0</tx-errors>
                                                        <tx-brate>1768616</tx-brate>
                                                        <rx-pkts>2</rx-pkts>
                                                        <rx-errors>0</rx-errors>
                                                        <rx-brate>11104</rx-brate>
                                                        <dl-cqi>15.0</dl-cqi>
                                                        <dl-ri>0</dl-ri>
                                                        <dl-pmi>0</dl-pmi>
                                                        <ul-phr>0</ul-phr>
                                                        <ul-sinr>0</ul-sinr>
                                                        <ul-rssi>0</ul-rssi>
                                                        <ul-mcs>0</ul-mcs>
                                                        <ul-samples>2</ul-samples>
                                                        <dl-mcs>27.870370864868164</dl-mcs>
                                                        <dl-samples>54</dl-samples>
                                                        <imsi>1010123456789</imsi>
                                                    </PerUEReportListItem>
                                                </perUEReportList>
                                            </du-PM-EPC>
                                        </ServedPlmnPerCellListItem>
                                    </servedPlmnPerCellList>
                                </CellResourceReportListItem>
                            </cellResourceReportList>
                        </oDU>
                    </performanceContainer>
                </PM-Containers-List>
                <PM-Containers-List>
                    <performanceContainer>
                        <oCU-CP>
                            <cu-CP-Resource-Status>
                                <numberOfActive-UEs>2</numberOfActive-UEs>
                            </cu-CP-Resource-Status>
                        </oCU-CP>
                    </performanceContainer>
                </PM-Containers-List>
                <PM-Containers-List>
                    <performanceContainer>
                        <oCU-UP>
                            <pf-ContainerList>
                                <PF-ContainerListItem>
                                    <interface-type><f1-u/></interface-type>
                                    <o-CU-UP-PM-Container>
                                        <plmnList>
                                            <PlmnID-List>
                                                <pLMN-Identity>00 F1 10</pLMN-Identity>
                                                <cu-UP-PM-EPC>
                                                    <perQCIReportList>
                                                        <PerQCIReportListItemFormat>
                                                            <qci>0</qci>
                                                            <pDCPBytesDL>0</pDCPBytesDL>
                                                            <pDCPBytesUL>0</pDCPBytesUL>
                                                        </PerQCIReportListItemFormat>
                                                        <PerQCIReportListItemFormat>
                                                            <qci>7</qci>
                                                            <pDCPBytesDL>13326628</pDCPBytesDL>
                                                            <pDCPBytesUL>108680</pDCPBytesUL>
                                                        </PerQCIReportListItemFormat>
                                                    </perQCIReportList>
                                                    <perUEReportList>
                                                        <PerUEReportListItemFormat>
                                                            <rnti>70</rnti>
                                                            <bytesDL>6663314</bytesDL>
                                                            <bytesUL>53716</bytesUL>
                                                        </PerUEReportListItemFormat>
                                                        <PerUEReportListItemFormat>
                                                            <rnti>71</rnti>
                                                            <bytesDL>6663314</bytesDL>
                                                            <bytesUL>54964</bytesUL>
                                                        </PerUEReportListItemFormat>
                                                    </perUEReportList>
                                                </cu-UP-PM-EPC>
                                            </PlmnID-List>
                                        </plmnList>
                                    </o-CU-UP-PM-Container>
                                </PF-ContainerListItem>
                            </pf-ContainerList>
                        </oCU-UP>
                    </performanceContainer>
                </PM-Containers-List>
            </pm-Containers>
        </indicationMessage-Format1>
    </indicationMessage>
</E2SM-KPM-IndicationMessage>
{"ts":1737231211970,"crit":"DEBUG","id":"nexran","mdc":{},"msg":"kpm indication report style 4 "}
{"ts":1737231211970,"crit":"DEBUG","id":"nexran","mdc":{},"msg":"nexran Indication handler"}
{"ts":1737231211971,"crit":"INFO","id":"nexran","mdc":{},"msg":"KpmIndication: KpmReport(period=5120 ms) available_dl_prbs=100 available_ul_prbs=100 ue[70]={dl_bytes=6663314,ul_bytes=53716,dl_prbs=70460,ul_prbs=1288,tx_pkts=15,tx_errors=0,tx_brate=1090232,rx_pkts=3,rx_errors=0,rx_brate=19096,dl_cqi=15,dl_ri=0,dl_pmi=0,ul_phr=30,ul_sinr=0,ul_mcs=0,ul_samples=3,dl_mcs=27.8788,dl_samples=33,imsi=1010123456780,} ue[71]={dl_bytes=6663314,ul_bytes=54964,dl_prbs=71636,ul_prbs=1214,tx_pkts=24,tx_errors=0,tx_brate=1768616,rx_pkts=2,rx_errors=0,rx_brate=11104,dl_cqi=15,dl_ri=0,dl_pmi=0,ul_phr=0,ul_sinr=0,ul_mcs=0,ul_samples=2,dl_mcs=27.8704,dl_samples=54,imsi=1010123456789,} "}
{"ts":1737231212008,"crit":"DEBUG","id":"nexran","mdc":{},"msg":"no slices in KPM report; not autoequalizing"}
{"ts":1737231212008,"crit":"DEBUG","id":"nexran","mdc":{},"msg":"current shares: fast[share=1024] secure_slice[share=1] "}
<E2SM-NexRAN-ControlHeader>
    <controlHeaderFormat1>
        <controlMessageId><sliceConfigRequest/></controlMessageId>
    </controlHeaderFormat1>
</E2SM-NexRAN-ControlHeader>
<E2SM-NexRAN-ControlMessage>
    <controlMessageFormat1>
        <sliceConfigRequest>
            <sliceConfigList>
                <SliceConfig>
                    <sliceName>fast</sliceName>
                    <schedPolicy>
                        <proportionalAllocationPolicy>
                            <share>1024</share>
                        </proportionalAllocationPolicy>
                    </schedPolicy>
                </SliceConfig>
            </sliceConfigList>
        </sliceConfigRequest>
    </controlMessageFormat1>
</E2SM-NexRAN-ControlMessage>
<E2AP-PDU>
    <initiatingMessage>
        <procedureCode>4</procedureCode>
        <criticality><reject/></criticality>
        <value>
            <RICcontrolRequest>
                <protocolIEs>
                    <RICcontrolRequest-IEs>
                        <id>29</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICrequestID>
                                <ricRequestorID>50526</ricRequestorID>
                                <ricInstanceID>6</ricInstanceID>
                            </RICrequestID>
                        </value>
                    </RICcontrolRequest-IEs>
                    <RICcontrolRequest-IEs>
                        <id>5</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RANfunctionID>1</RANfunctionID>
                        </value>
                    </RICcontrolRequest-IEs>
                    <RICcontrolRequest-IEs>
                        <id>22</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICcontrolHeader>00</RICcontrolHeader>
                        </value>
                    </RICcontrolRequest-IEs>
                    <RICcontrolRequest-IEs>
                        <id>23</id>
{"ts":1737231216797,"crit":"DEBUG","id":"nexran","mdc":{},"msg":"sent control request (subid=-1618497910,requestor_id=50526,instance_id=6,meid=enB_macro_001_001_0019b0) "}
{"ts":1737231216797,"crit":"DEBUG","id":"nexran","mdc":{},"msg":"bound slice fast to nodeb enB_macro_001_001_0019b0"}
                        <criticality><reject/></criticality>
                        <value>
                            <RICcontrolMessage>00 00 C0 66 61 73 74 00 04 00</RICcontrolMessage>
                        </value>
                    </RICcontrolRequest-IEs>
                    <RICcontrolRequest-IEs>
                        <id>21</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICcontrolAckRequest><ack/></RICcontrolAckRequest>
                        </value>
                    </RICcontrolRequest-IEs>
                </protocolIEs>
            </RICcontrolRequest>
        </value>
    </initiatingMessage>
</E2AP-PDU>
{"ts":1737231216802,"crit":"DEBUG","id":"nexran","mdc":{},"msg":"RMR message (type 12041, source enB_macro_001_001_0019b0)"}
<E2AP-PDU>
    <successfulOutcome>
        <procedureCode>4</procedureCode>
        <criticality><reject/></criticality>
        <value>
            <RICcontrolAcknowledge>
                <protocolIEs>
                    <RICcontrolAcknowledge-IEs>
                        <id>29</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICrequestID>
                                <ricRequestorID>50526</ricRequestorID>
                                <ricInstanceID>6</ricInstanceID>
                            </RICrequestID>
{"ts":1737231216803,"crit":"INFO","id":"nexran","mdc":{},"msg":"decoded successful outcome RICcontrol (4) "}
{"ts":1737231216803,"crit":"DEBUG","id":"nexran","mdc":{},"msg":"nexran ControlAck handler"}
                        </value>
                    </RICcontrolAcknowledge-IEs>
                    <RICcontrolAcknowledge-IEs>
                        <id>5</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RANfunctionID>1</RANfunctionID>
                        </value>
                    </RICcontrolAcknowledge-IEs>
                    <RICcontrolAcknowledge-IEs>
                        <id>24</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICcontrolStatus><success/></RICcontrolStatus>
                        </value>
                    </RICcontrolAcknowledge-IEs>
                    <RICcontrolAcknowledge-IEs>
                        <id>32</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICcontrolOutcome>01 03 66 61 73 74 00 04 00 00 00</RICcontrolOutcome>
                        </value>
                    </RICcontrolAcknowledge-IEs>
                </protocolIEs>
            </RICcontrolAcknowledge>
        </value>
    </successfulOutcome>
</E2AP-PDU>
<E2SM-NexRAN-ControlOutcome>
    <controlOutcomeFormat1>
        <sliceStatusReport>
            <sliceStatusList>
                <SliceStatus>
                    <sliceName>fast</sliceName>
                    <schedPolicy>
                        <proportionalAllocationPolicy>
                            <share>1024</share>
                        </proportionalAllocationPolicy>
                    </schedPolicy>
                    <ueList>
                    </ueList>
                </SliceStatus>
            </sliceStatusList>
        </sliceStatusReport>
    </controlOutcomeFormat1>
</E2SM-NexRAN-ControlOutcome>
{"ts":1737231217089,"crit":"DEBUG","id":"nexran","mdc":{},"msg":"RMR message (type 12050, source enB_macro_001_001_0019b0)"}
{"ts":1737231217090,"crit":"INFO","id":"nexran","mdc":{},"msg":"decoded initiating RICindication (5) "}
<E2AP-PDU>
    <initiatingMessage>
        <procedureCode>5</procedureCode>
        <criticality><reject/></criticality>
        <value>
            <RICindication>
                <protocolIEs>
                    <RICindication-IEs>
                        <id>29</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICrequestID>
                                <ricRequestorID>123</ricRequestorID>
                                <ricInstanceID>7</ricInstanceID>
                            </RICrequestID>
                        </value>
                    </RICindication-IEs>
                    <RICindication-IEs>
                        <id>5</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RANfunctionID>0</RANfunctionID>
                        </value>
                    </RICindication-IEs>
                    <RICindication-IEs>
                        <id>15</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICactionID>1</RICactionID>
                        </value>
                    </RICindication-IEs>
                    <RICindication-IEs>
                        <id>27</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICindicationSN>3</RICindicationSN>
                        </value>
                    </RICindication-IEs>
                    <RICindication-IEs>
                        <id>28</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICindicationType><report/></RICindicationType>
                        </value>
                    </RICindication-IEs>
                    <RICindication-IEs>
                        <id>26</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICindicationMessage>
                                01 04 00 00 02 40 00 00 60 00 F1 10 00 00 00 00 
                                10 00 64 00 64 02 00 F1 10 80 00 00 00 03 00 80 
                                88 00 01 00 00 46 20 01 16 7C 10 04 EA 01 1F 01 
                                00 03 21 45 30 01 06 01 00 03 00 94 A0 03 80 00 
                                0F 00 00 03 80 01 0F 06 80 EF 00 D0 D4 AD 00 06 
                                80 EF 00 2D 11 11 01 0F 06 80 ED 00 DF 45 D1 01 
                                42 06 00 EB 30 0C C1 0C 00 00 47 20 01 14 F4 10 
                                04 97 01 1E 01 00 03 21 46 30 01 04 01 00 02 40 
                                A0 03 80 00 0F 00 00 03 80 01 0F 06 80 EF 00 D1 
                                09 61 00 03 80 01 0B 01 09 06 80 ED 00 DF 21 ED 
                                01 53 06 00 EB 30 0C C1 15 4A 00 01 50 10 08 00 
                                F1 10 80 01 60 00 00 00 00 00 60 07 20 C9 45 F2 
                                20 01 B1 44 03 00 16 00 01 00 00 46 20 63 99 60 
                                10 DB 60 00 00 47 20 65 AC 92 10 D5 E4
                            </RICindicationMessage>
                        </value>
                    </RICindication-IEs>
                    <RICindication-IEs>
                        <id>25</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICindicationHeader>08 00 F1 10</RICindicationHeader>
                        </value>
                    </RICindication-IEs>
                </protocolIEs>
            </RICindication>
        </value>
    </initiatingMessage>
</E2AP-PDU>
<E2SM-KPM-IndicationHeader>
    <indicationHeader-Format1>
        <pLMN-Identity>00 F1 10</pLMN-Identity>
    </indicationHeader-Format1>
</E2SM-KPM-IndicationHeader>
<E2SM-KPM-IndicationMessage>
    <ric-Style-Type>4</ric-Style-Type>
    <indicationMessage>
        <indicationMessage-Format1>
            <pm-Containers>
                <PM-Containers-List>
                    <performanceContainer>
                        <oDU>
                            <cellResourceReportList>
                                <CellResourceReportListItem>
                                    <nRCGI>
                                        <pLMN-Identity>00 F1 10</pLMN-Identity>
                                        <nRCellIdentity>
                                            000000000000000000000000000000000001
                                        </nRCellIdentity>
                                    </nRCGI>
                                    <dl-TotalofAvailablePRBs>100</dl-TotalofAvailablePRBs>
                                    <ul-TotalofAvailablePRBs>100</ul-TotalofAvailablePRBs>
                                    <servedPlmnPerCellList>
                                        <ServedPlmnPerCellListItem>
                                            <pLMN-Identity>00 F1 10</pLMN-Identity>
                                            <du-PM-EPC>
                                                <perQCIReportList>
                                                    <PerQCIReportListItem>
                                                        <qci>0</qci>
                                                    </PerQCIReportListItem>
                                                </perQCIReportList>
                                                <perUEReportList>
                                                    <PerUEReportListItem>
                                                        <rnti>70</rnti>
                                                        <dl-PRBUsage>71292</dl-PRBUsage>
                                                        <ul-PRBUsage>1258</ul-PRBUsage>
                                                        <tx-pkts>31</tx-pkts>
                                                        <tx-errors>0</tx-errors>
                                                        <tx-brate>2180400</tx-brate>
                                                        <rx-pkts>6</rx-pkts>
                                                        <rx-errors>0</rx-errors>
                                                        <rx-brate>38048</rx-brate>
                                                        <dl-cqi>15.0</dl-cqi>
                                                        <dl-ri>0</dl-ri>
                                                        <dl-pmi>0</dl-pmi>
                                                        <ul-phr>30.0</ul-phr>
                                                        <ul-sinr>104.415382385253906</ul-sinr>
                                                        <ul-rssi>0</ul-rssi>
                                                        <ul-mcs>22.533332824707031</ul-mcs>
                                                        <ul-samples>15</ul-samples>
                                                        <dl-mcs>27.909090042114258</dl-mcs>
                                                        <dl-samples>66</dl-samples>
                                                        <imsi>1010123456780</imsi>
                                                    </PerUEReportListItem>
                                                    <PerUEReportListItem>
                                                        <rnti>71</rnti>
                                                        <dl-PRBUsage>70900</dl-PRBUsage>
                                                        <ul-PRBUsage>1175</ul-PRBUsage>
                                                        <tx-pkts>30</tx-pkts>
                                                        <tx-errors>0</tx-errors>
                                                        <tx-brate>2180656</tx-brate>
                                                        <rx-pkts>4</rx-pkts>
                                                        <rx-errors>0</rx-errors>
                                                        <rx-brate>16544</rx-brate>
                                                        <dl-cqi>15.0</dl-cqi>
                                                        <dl-ri>0</dl-ri>
                                                        <dl-pmi>0</dl-pmi>
                                                        <ul-phr>30.0</ul-phr>
                                                        <ul-sinr>104.518318176269531</ul-sinr>
                                                        <ul-rssi>0</ul-rssi>
                                                        <ul-mcs>22.0</ul-mcs>
                                                        <ul-samples>9</ul-samples>
                                                        <dl-mcs>27.891565322875977</dl-mcs>
                                                        <dl-samples>83</dl-samples>
                                                        <imsi>1010123456789</imsi>
                                                    </PerUEReportListItem>
                                                </perUEReportList>
                                            </du-PM-EPC>
                                        </ServedPlmnPerCellListItem>
                                    </servedPlmnPerCellList>
                                </CellResourceReportListItem>
                            </cellResourceReportList>
                        </oDU>
                    </performanceContainer>
                </PM-Containers-List>
                <PM-Containers-List>
                    <performanceContainer>
                        <oCU-CP>
                            <cu-CP-Resource-Status>
                                <numberOfActive-UEs>2</numberOfActive-UEs>
                            </cu-CP-Resource-Status>
                        </oCU-CP>
                    </performanceContainer>
                </PM-Containers-List>
                <PM-Containers-List>
                    <performanceContainer>
                        <oCU-UP>
                            <pf-ContainerList>
                                <PF-ContainerListItem>
                                    <interface-type><f1-u/></interface-type>
                                    <o-CU-UP-PM-Container>
                                        <plmnList>
                                            <PlmnID-List>
                                                <pLMN-Identity>00 F1 10</pLMN-Identity>
                                                <cu-UP-PM-EPC>
                                                    <perQCIReportList>
                                                        <PerQCIReportListItemFormat>
                                                            <qci>0</qci>
                                                            <pDCPBytesDL>0</pDCPBytesDL>
                                                            <pDCPBytesUL>0</pDCPBytesUL>
                                                        </PerQCIReportListItemFormat>
                                                        <PerQCIReportListItemFormat>
                                                            <qci>7</qci>
                                                            <pDCPBytesDL>13190642</pDCPBytesDL>
                                                            <pDCPBytesUL>110916</pDCPBytesUL>
                                                        </PerQCIReportListItemFormat>
                                                    </perQCIReportList>
                                                    <perUEReportList>
                                                        <PerUEReportListItemFormat>
                                                            <rnti>70</rnti>
                                                            <bytesDL>6527328</bytesDL>
                                                            <bytesUL>56160</bytesUL>
                                                        </PerUEReportListItemFormat>
                                                        <PerUEReportListItemFormat>
                                                            <rnti>71</rnti>
                                                            <bytesDL>6663314</bytesDL>
                                                            <bytesUL>54756</bytesUL>
                                                        </PerUEReportListItemFormat>
                                                    </perUEReportList>
                                                </cu-UP-PM-EPC>
                                            </PlmnID-List>
                                        </plmnList>
                                    </o-CU-UP-PM-Container>
                                </PF-ContainerListItem>
                            </pf-ContainerList>
                        </oCU-UP>
{"ts":1737231217093,"crit":"DEBUG","id":"nexran","mdc":{},"msg":"kpm indication report style 4 "}
{"ts":1737231217093,"crit":"DEBUG","id":"nexran","mdc":{},"msg":"nexran Indication handler"}
                    </performanceContainer>
                </PM-Containers-List>
            </pm-Containers>
        </indicationMessage-Format1>
    </indicationMessage>
</E2SM-KPM-IndicationMessage>
{"ts":1737231217094,"crit":"INFO","id":"nexran","mdc":{},"msg":"KpmIndication: KpmReport(period=5120 ms) available_dl_prbs=100 available_ul_prbs=100 ue[70]={dl_bytes=6527328,ul_bytes=56160,dl_prbs=71292,ul_prbs=1258,tx_pkts=31,tx_errors=0,tx_brate=2180400,rx_pkts=6,rx_errors=0,rx_brate=38048,dl_cqi=15,dl_ri=0,dl_pmi=0,ul_phr=30,ul_sinr=104.415,ul_mcs=22.5333,ul_samples=15,dl_mcs=27.9091,dl_samples=66,imsi=1010123456780,} ue[71]={dl_bytes=6663314,ul_bytes=54756,dl_prbs=70900,ul_prbs=1175,tx_pkts=30,tx_errors=0,tx_brate=2180656,rx_pkts=4,rx_errors=0,rx_brate=16544,dl_cqi=15,dl_ri=0,dl_pmi=0,ul_phr=30,ul_sinr=104.518,ul_mcs=22,ul_samples=9,dl_mcs=27.8916,dl_samples=83,imsi=1010123456789,} "}
{"ts":1737231217107,"crit":"DEBUG","id":"nexran","mdc":{},"msg":"no slices in KPM report; not autoequalizing"}
{"ts":1737231217108,"crit":"DEBUG","id":"nexran","mdc":{},"msg":"current shares: fast[share=1024] secure_slice[share=1] "}
1737231219960 1/RMR [INFO] sends: ts=1737231219 src=service-ricxapp-dc-rmr.ricxapp:4560 target=10.106.64.163:38000 open=1 succ=4 fail=0 (hard=0 soft=0)
1737231219960 1/RMR [INFO] sends: ts=1737231219 src=service-ricxapp-dc-rmr.ricxapp:4560 target=service-ricplt-e2term-rmr-alpha.ricplt:38000 open=0 succ=0 fail=0 (hard=0 soft=0)
1737231219960 1/RMR [INFO] sends: ts=1737231219 src=service-ricxapp-dc-rmr.ricxapp:4560 target=service-ricplt-submgr-rmr.ricplt:4560 open=1 succ=2 fail=0 (hard=0 soft=0)
1737231219960 1/RMR [INFO] sends: ts=1737231219 src=service-ricxapp-dc-rmr.ricxapp:4560 target=service-ricplt-e2mgr-rmr.ricplt:3801 open=0 succ=0 fail=0 (hard=0 soft=0)
1737231219960 1/RMR [INFO] sends: ts=1737231219 src=service-ricxapp-dc-rmr.ricxapp:4560 target=service-ricplt-a1mediator-rmr.ricplt:4562 open=0 succ=0 fail=0 (hard=0 soft=0)
<E2SM-NexRAN-ControlHeader>
    <controlHeaderFormat1>
        <controlMessageId><sliceConfigRequest/></controlMessageId>
    </controlHeaderFormat1>
</E2SM-NexRAN-ControlHeader>
<E2SM-NexRAN-ControlMessage>
    <controlMessageFormat1>
        <sliceConfigRequest>
            <sliceConfigList>
                <SliceConfig>
                    <sliceName>secure_slice</sliceName>
                    <schedPolicy>
                        <proportionalAllocationPolicy>
                            <share>1</share>
                        </proportionalAllocationPolicy>
                    </schedPolicy>
                </SliceConfig>
            </sliceConfigList>
        </sliceConfigRequest>
    </controlMessageFormat1>
</E2SM-NexRAN-ControlMessage>
<E2AP-PDU>
    <initiatingMessage>
        <procedureCode>4</procedureCode>
        <criticality><reject/></criticality>
        <value>
            <RICcontrolRequest>
                <protocolIEs>
                    <RICcontrolRequest-IEs>
                        <id>29</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICrequestID>
                                <ricRequestorID>50526</ricRequestorID>
                                <ricInstanceID>7</ricInstanceID>
                            </RICrequestID>
                        </value>
                    </RICcontrolRequest-IEs>
                    <RICcontrolRequest-IEs>
                        <id>5</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RANfunctionID>1</RANfunctionID>
                        </value>
                    </RICcontrolRequest-IEs>
                    <RICcontrolRequest-IEs>
                        <id>22</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICcontrolHeader>00</RICcontrolHeader>
                        </value>
                    </RICcontrolRequest-IEs>
                    <RICcontrolRequest-IEs>
                        <id>23</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICcontrolMessage>
                                00 02 C0 73 65 63 75 72 65 5F 73 6C 69 63 65 00 
                                00 01
                            </RICcontrolMessage>
                        </value>
                    </RICcontrolRequest-IEs>
                    <RICcontrolRequest-IEs>
                        <id>21</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICcontrolAckRequest><ack/></RICcontrolAckRequest>
                        </value>
                    </RICcontrolRequest-IEs>
                </protocolIEs>
            </RICcontrolRequest>
        </value>
    </initiatingMessage>
</E2AP-PDU>
{"ts":1737231221827,"crit":"DEBUG","id":"nexran","mdc":{},"msg":"sent control request (subid=-1125698825,requestor_id=50526,instance_id=7,meid=enB_macro_001_001_0019b0) "}
{"ts":1737231221827,"crit":"DEBUG","id":"nexran","mdc":{},"msg":"bound slice secure_slice to nodeb enB_macro_001_001_0019b0"}
<E2AP-PDU>
    <successfulOutcome>
        <procedureCode>4</procedureCode>
        <criticality><reject/></criticality>
        <value>
            <RICcontrolAcknowledge>
                <protocolIEs>
                    <RICcontrolAcknowledge-IEs>
                        <id>29</id>
                        <criticality><reject/></criticality>
                        <value>
{"ts":1737231221834,"crit":"DEBUG","id":"nexran","mdc":{},"msg":"RMR message (type 12041, source enB_macro_001_001_0019b0)"}
                            <RICrequestID>
                                <ricRequestorID>50526</ricRequestorID>
                                <ricInstanceID>7</ricInstanceID>
                            </RICrequestID>
                        </value>
                    </RICcontrolAcknowledge-IEs>
                    <RICcontrolAcknowledge-IEs>
                        <id>5</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RANfunctionID>1</RANfunctionID>
                        </value>
                    </RICcontrolAcknowledge-IEs>
                    <RICcontrolAcknowledge-IEs>
                        <id>24</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICcontrolStatus><success/></RICcontrolStatus>
                        </value>
                    </RICcontrolAcknowledge-IEs>
                    <RICcontrolAcknowledge-IEs>
                        <id>32</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICcontrolOutcome>
                                02 03 66 61 73 74 00 04 00 00 00 0B 73 65 63 75 
                                72 65 5F 73 6C 69 63 65 00 00 01 00 00
                            </RICcontrolOutcome>
{"ts":1737231221835,"crit":"INFO","id":"nexran","mdc":{},"msg":"decoded successful outcome RICcontrol (4) "}
{"ts":1737231221835,"crit":"DEBUG","id":"nexran","mdc":{},"msg":"nexran ControlAck handler"}
                        </value>
                    </RICcontrolAcknowledge-IEs>
                </protocolIEs>
            </RICcontrolAcknowledge>
        </value>
    </successfulOutcome>
</E2AP-PDU>
<E2SM-NexRAN-ControlOutcome>
    <controlOutcomeFormat1>
        <sliceStatusReport>
            <sliceStatusList>
                <SliceStatus>
                    <sliceName>fast</sliceName>
                    <schedPolicy>
                        <proportionalAllocationPolicy>
                            <share>1024</share>
                        </proportionalAllocationPolicy>
                    </schedPolicy>
                    <ueList>
                    </ueList>
                </SliceStatus>
                <SliceStatus>
                    <sliceName>secure_slice</sliceName>
                    <schedPolicy>
                        <proportionalAllocationPolicy>
                            <share>1</share>
                        </proportionalAllocationPolicy>
                    </schedPolicy>
                    <ueList>
                    </ueList>
                </SliceStatus>
            </sliceStatusList>
        </sliceStatusReport>
    </controlOutcomeFormat1>
</E2SM-NexRAN-ControlOutcome>
{"ts":1737231222205,"crit":"DEBUG","id":"nexran","mdc":{},"msg":"RMR message (type 12050, source enB_macro_001_001_0019b0)"}
<E2AP-PDU>
    <initiatingMessage>
        <procedureCode>5</procedureCode>
        <criticality><reject/></criticality>
        <value>
            <RICindication>
                <protocolIEs>
                    <RICindication-IEs>
                        <id>29</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICrequestID>
                                <ricRequestorID>123</ricRequestorID>
                                <ricInstanceID>7</ricInstanceID>
                            </RICrequestID>
                        </value>
                    </RICindication-IEs>
                    <RICindication-IEs>
                        <id>5</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RANfunctionID>0</RANfunctionID>
                        </value>
                    </RICindication-IEs>
                    <RICindication-IEs>
                        <id>15</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICactionID>1</RICactionID>
                        </value>
                    </RICindication-IEs>
                    <RICindication-IEs>
                        <id>27</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICindicationSN>4</RICindicationSN>
                        </value>
                    </RICindication-IEs>
                    <RICindication-IEs>
                        <id>28</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICindicationType><report/></RICindicationType>
                        </value>
                    </RICindication-IEs>
                    <RICindication-IEs>
                        <id>26</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICindicationMessage>
                                01 04 00 00 02 40 00 00 60 00 F1 10 00 00 00 00 
                                10 00 64 00 64 02 00 F1 10 80 00 00 00 03 00 80 
                                8A 00 01 00 00 46 20 01 17 0C 10 04 B1 01 3E 01 
                                00 03 42 88 40 01 0A 01 00 03 00 92 10 03 80 00 
                                0F 00 00 03 80 01 0F 06 80 EF 00 D0 25 7D 00 06 
                                80 ED 00 AF 33 33 01 14 06 80 ED 00 DE 32 BD 01 
                                6F 06 00 EB 30 0C C1 0C 00 00 47 20 01 15 2C 10 
                                04 D4 01 2E 01 01 03 31 E8 28 01 0A 01 00 03 00 
                                C2 30 03 80 00 0F 00 00 03 80 01 0F 06 80 EF 00 
                                D1 0F 43 00 04 80 FC 01 65 01 10 06 80 EE 00 6F 
                                2C DD 01 61 06 00 EB 30 0C C1 15 4A 00 01 50 10 
                                08 00 F1 10 80 01 60 00 00 00 00 00 60 07 20 C9 
                                45 F2 20 01 AB C8 03 00 16 00 01 00 00 46 20 65 
                                AC 92 10 D4 44 00 00 47 20 63 99 60 10 D7 84
                            </RICindicationMessage>
                        </value>
                    </RICindication-IEs>
                    <RICindication-IEs>
                        <id>25</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICindicationHeader>08 00 F1 10</RICindicationHeader>
                        </value>
                    </RICindication-IEs>
                </protocolIEs>
            </RICindication>
{"ts":1737231222206,"crit":"INFO","id":"nexran","mdc":{},"msg":"decoded initiating RICindication (5) "}
        </value>
    </initiatingMessage>
</E2AP-PDU>
<E2SM-KPM-IndicationHeader>
    <indicationHeader-Format1>
        <pLMN-Identity>00 F1 10</pLMN-Identity>
    </indicationHeader-Format1>
</E2SM-KPM-IndicationHeader>
<E2SM-KPM-IndicationMessage>
    <ric-Style-Type>4</ric-Style-Type>
    <indicationMessage>
        <indicationMessage-Format1>
            <pm-Containers>
                <PM-Containers-List>
                    <performanceContainer>
                        <oDU>
                            <cellResourceReportList>
                                <CellResourceReportListItem>
                                    <nRCGI>
                                        <pLMN-Identity>00 F1 10</pLMN-Identity>
                                        <nRCellIdentity>
                                            000000000000000000000000000000000001
                                        </nRCellIdentity>
                                    </nRCGI>
                                    <dl-TotalofAvailablePRBs>100</dl-TotalofAvailablePRBs>
                                    <ul-TotalofAvailablePRBs>100</ul-TotalofAvailablePRBs>
                                    <servedPlmnPerCellList>
                                        <ServedPlmnPerCellListItem>
                                            <pLMN-Identity>00 F1 10</pLMN-Identity>
                                            <du-PM-EPC>
                                                <perQCIReportList>
                                                    <PerQCIReportListItem>
                                                        <qci>0</qci>
                                                    </PerQCIReportListItem>
                                                </perQCIReportList>
                                                <perUEReportList>
                                                    <PerUEReportListItem>
                                                        <rnti>70</rnti>
                                                        <dl-PRBUsage>71436</dl-PRBUsage>
                                                        <ul-PRBUsage>1201</ul-PRBUsage>
                                                        <tx-pkts>62</tx-pkts>
                                                        <tx-errors>0</tx-errors>
                                                        <tx-brate>4360256</tx-brate>
                                                        <rx-pkts>10</rx-pkts>
                                                        <rx-errors>0</rx-errors>
                                                        <rx-brate>37392</rx-brate>
                                                        <dl-cqi>15.0</dl-cqi>
                                                        <dl-ri>0</dl-ri>
                                                        <dl-pmi>0</dl-pmi>
                                                        <ul-phr>30.0</ul-phr>
                                                        <ul-sinr>104.073219299316406</ul-sinr>
                                                        <ul-rssi>0</ul-rssi>
                                                        <ul-mcs>21.899999618530273</ul-mcs>
                                                        <ul-samples>20</ul-samples>
                                                        <dl-mcs>27.774774551391602</dl-mcs>
                                                        <dl-samples>111</dl-samples>
                                                        <imsi>1010123456780</imsi>
                                                    </PerUEReportListItem>
                                                    <PerUEReportListItem>
                                                        <rnti>71</rnti>
                                                        <dl-PRBUsage>70956</dl-PRBUsage>
                                                        <ul-PRBUsage>1236</ul-PRBUsage>
                                                        <tx-pkts>46</tx-pkts>
                                                        <tx-errors>1</tx-errors>
                                                        <tx-brate>3270696</tx-brate>
                                                        <rx-pkts>10</rx-pkts>
                                                        <rx-errors>0</rx-errors>
                                                        <rx-brate>49712</rx-brate>
                                                        <dl-cqi>15.0</dl-cqi>
                                                        <dl-ri>0</dl-ri>
                                                        <dl-pmi>0</dl-pmi>
                                                        <ul-phr>30.0</ul-phr>
                                                        <ul-sinr>104.529808044433594</ul-sinr>
                                                        <ul-rssi>0</ul-rssi>
                                                        <ul-mcs>22.3125</ul-mcs>
                                                        <ul-samples>16</ul-samples>
                                                        <dl-mcs>27.793811798095703</dl-mcs>
                                                        <dl-samples>97</dl-samples>
                                                        <imsi>1010123456789</imsi>
                                                    </PerUEReportListItem>
                                                </perUEReportList>
                                            </du-PM-EPC>
                                        </ServedPlmnPerCellListItem>
                                    </servedPlmnPerCellList>
                                </CellResourceReportListItem>
                            </cellResourceReportList>
                        </oDU>
                    </performanceContainer>
                </PM-Containers-List>
                <PM-Containers-List>
                    <performanceContainer>
                        <oCU-CP>
                            <cu-CP-Resource-Status>
                                <numberOfActive-UEs>2</numberOfActive-UEs>
                            </cu-CP-Resource-Status>
                        </oCU-CP>
                    </performanceContainer>
                </PM-Containers-List>
                <PM-Containers-List>
                    <performanceContainer>
                        <oCU-UP>
                            <pf-ContainerList>
                                <PF-ContainerListItem>
                                    <interface-type><f1-u/></interface-type>
                                    <o-CU-UP-PM-Container>
                                        <plmnList>
                                            <PlmnID-List>
                                                <pLMN-Identity>00 F1 10</pLMN-Identity>
                                                <cu-UP-PM-EPC>
                                                    <perQCIReportList>
                                                        <PerQCIReportListItemFormat>
                                                            <qci>0</qci>
                                                            <pDCPBytesDL>0</pDCPBytesDL>
                                                            <pDCPBytesUL>0</pDCPBytesUL>
                                                        </PerQCIReportListItemFormat>
                                                        <PerQCIReportListItemFormat>
                                                            <qci>7</qci>
                                                            <pDCPBytesDL>13190642</pDCPBytesDL>
                                                            <pDCPBytesUL>109512</pDCPBytesUL>
                                                        </PerQCIReportListItemFormat>
                                                    </perQCIReportList>
                                                    <perUEReportList>
                                                        <PerUEReportListItemFormat>
                                                            <rnti>70</rnti>
                                                            <bytesDL>6663314</bytesDL>
                                                            <bytesUL>54340</bytesUL>
                                                        </PerUEReportListItemFormat>
                                                        <PerUEReportListItemFormat>
                                                            <rnti>71</rnti>
                                                            <bytesDL>6527328</bytesDL>
                                                            <bytesUL>55172</bytesUL>
                                                        </PerUEReportListItemFormat>
                                                    </perUEReportList>
                                                </cu-UP-PM-EPC>
                                            </PlmnID-List>
                                        </plmnList>
                                    </o-CU-UP-PM-Container>
                                </PF-ContainerListItem>
                            </pf-ContainerList>
                        </oCU-UP>
                    </performanceContainer>
                </PM-Containers-List>
            </pm-Containers>
        </indicationMessage-Format1>
    </indicationMessage>
</E2SM-KPM-IndicationMessage>
{"ts":1737231222209,"crit":"DEBUG","id":"nexran","mdc":{},"msg":"kpm indication report style 4 "}
{"ts":1737231222209,"crit":"DEBUG","id":"nexran","mdc":{},"msg":"nexran Indication handler"}
{"ts":1737231222209,"crit":"INFO","id":"nexran","mdc":{},"msg":"KpmIndication: KpmReport(period=5120 ms) available_dl_prbs=100 available_ul_prbs=100 ue[70]={dl_bytes=6663314,ul_bytes=54340,dl_prbs=71436,ul_prbs=1201,tx_pkts=62,tx_errors=0,tx_brate=4360256,rx_pkts=10,rx_errors=0,rx_brate=37392,dl_cqi=15,dl_ri=0,dl_pmi=0,ul_phr=30,ul_sinr=104.073,ul_mcs=21.9,ul_samples=20,dl_mcs=27.7748,dl_samples=111,imsi=1010123456780,} ue[71]={dl_bytes=6527328,ul_bytes=55172,dl_prbs=70956,ul_prbs=1236,tx_pkts=46,tx_errors=1,tx_brate=3270696,rx_pkts=10,rx_errors=0,rx_brate=49712,dl_cqi=15,dl_ri=0,dl_pmi=0,ul_phr=30,ul_sinr=104.53,ul_mcs=22.3125,ul_samples=16,dl_mcs=27.7938,dl_samples=97,imsi=1010123456789,} "}
{"ts":1737231222223,"crit":"DEBUG","id":"nexran","mdc":{},"msg":"no slices in KPM report; not autoequalizing"}
{"ts":1737231222224,"crit":"DEBUG","id":"nexran","mdc":{},"msg":"current shares: fast[share=1024] secure_slice[share=1] "}
{"ts":1737231226855,"crit":"DEBUG","id":"nexran","mdc":{},"msg":"added ue 001010123456789"}
<E2AP-PDU>
    <initiatingMessage>
{"ts":1737231227327,"crit":"DEBUG","id":"nexran","mdc":{},"msg":"RMR message (type 12050, source enB_macro_001_001_0019b0)"}
        <procedureCode>5</procedureCode>
        <criticality><reject/></criticality>
        <value>
            <RICindication>
                <protocolIEs>
                    <RICindication-IEs>
                        <id>29</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICrequestID>
                                <ricRequestorID>123</ricRequestorID>
                                <ricInstanceID>7</ricInstanceID>
                            </RICrequestID>
                        </value>
                    </RICindication-IEs>
                    <RICindication-IEs>
                        <id>5</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RANfunctionID>0</RANfunctionID>
                        </value>
                    </RICindication-IEs>
                    <RICindication-IEs>
                        <id>15</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICactionID>1</RICactionID>
                        </value>
                    </RICindication-IEs>
                    <RICindication-IEs>
                        <id>27</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICindicationSN>5</RICindicationSN>
                        </value>
                    </RICindication-IEs>
                    <RICindication-IEs>
                        <id>28</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICindicationType><report/></RICindicationType>
                        </value>
                    </RICindication-IEs>
                    <RICindication-IEs>
                        <id>26</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICindicationMessage>
                                01 04 00 00 02 40 00 00 60 00 F1 10 00 00 00 00 
                                10 00 64 00 64 02 00 F1 10 80 00 00 00 03 00 80 
                                8C 00 01 00 00 46 20 01 17 34 10 05 14 01 4B 01 
                                00 03 53 2D D8 01 0B 01 00 03 00 D1 98 03 80 00 
                                0F 00 00 03 80 01 0F 06 80 EF 00 D0 EC 77 00 06 
                                80 EF 00 2C A3 D7 01 19 06 80 ED 00 DF A0 6D 02 
                                00 96 06 00 EB 30 0C C1 0C 00 00 47 20 01 17 7C 
                                10 04 EB 01 4C 01 00 03 53 3B 58 01 0D 01 00 03 
                                00 E2 48 03 80 00 0F 00 00 03 80 01 0F 06 80 F1 
                                00 34 42 EB 00 06 80 ED 00 B2 D2 D3 01 22 04 80 
                                FD 00 DF 02 00 90 06 00 EB 30 0C C1 15 4A 00 01 
                                50 10 08 00 F1 10 80 01 60 00 00 00 00 00 60 07 
                                20 CB 59 24 20 01 B3 E8 03 00 16 00 01 00 00 46 
                                20 65 AC 92 10 D3 DC 00 00 47 20 65 AC 92 10 E0 
                                0C
                            </RICindicationMessage>
                        </value>
                    </RICindication-IEs>
                    <RICindication-IEs>
                        <id>25</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICindicationHeader>08 00 F1 10</RICindicationHeader>
                        </value>
                    </RICindication-IEs>
                </protocolIEs>
{"ts":1737231227328,"crit":"INFO","id":"nexran","mdc":{},"msg":"decoded initiating RICindication (5) "}
            </RICindication>
        </value>
    </initiatingMessage>
</E2AP-PDU>
<E2SM-KPM-IndicationHeader>
    <indicationHeader-Format1>
        <pLMN-Identity>00 F1 10</pLMN-Identity>
    </indicationHeader-Format1>
</E2SM-KPM-IndicationHeader>
<E2SM-KPM-IndicationMessage>
    <ric-Style-Type>4</ric-Style-Type>
    <indicationMessage>
        <indicationMessage-Format1>
            <pm-Containers>
                <PM-Containers-List>
                    <performanceContainer>
                        <oDU>
                            <cellResourceReportList>
                                <CellResourceReportListItem>
                                    <nRCGI>
                                        <pLMN-Identity>00 F1 10</pLMN-Identity>
                                        <nRCellIdentity>
                                            000000000000000000000000000000000001
                                        </nRCellIdentity>
                                    </nRCGI>
                                    <dl-TotalofAvailablePRBs>100</dl-TotalofAvailablePRBs>
                                    <ul-TotalofAvailablePRBs>100</ul-TotalofAvailablePRBs>
                                    <servedPlmnPerCellList>
                                        <ServedPlmnPerCellListItem>
                                            <pLMN-Identity>00 F1 10</pLMN-Identity>
                                            <du-PM-EPC>
                                                <perQCIReportList>
                                                    <PerQCIReportListItem>
                                                        <qci>0</qci>
                                                    </PerQCIReportListItem>
                                                </perQCIReportList>
                                                <perUEReportList>
                                                    <PerUEReportListItem>
                                                        <rnti>70</rnti>
                                                        <dl-PRBUsage>71476</dl-PRBUsage>
                                                        <ul-PRBUsage>1300</ul-PRBUsage>
                                                        <tx-pkts>75</tx-pkts>
                                                        <tx-errors>0</tx-errors>
                                                        <tx-brate>5451224</tx-brate>
                                                        <rx-pkts>11</rx-pkts>
                                                        <rx-errors>0</rx-errors>
                                                        <rx-brate>53656</rx-brate>
                                                        <dl-cqi>15.0</dl-cqi>
                                                        <dl-ri>0</dl-ri>
                                                        <dl-pmi>0</dl-pmi>
                                                        <ul-phr>30.0</ul-phr>
                                                        <ul-sinr>104.461845397949219</ul-sinr>
                                                        <ul-rssi>0</ul-rssi>
                                                        <ul-mcs>22.319999694824219</ul-mcs>
                                                        <ul-samples>25</ul-samples>
                                                        <dl-mcs>27.953332901000977</dl-mcs>
                                                        <dl-samples>150</dl-samples>
                                                        <imsi>1010123456780</imsi>
                                                    </PerUEReportListItem>
                                                    <PerUEReportListItem>
                                                        <rnti>71</rnti>
                                                        <dl-PRBUsage>71548</dl-PRBUsage>
                                                        <ul-PRBUsage>1259</ul-PRBUsage>
                                                        <tx-pkts>76</tx-pkts>
                                                        <tx-errors>0</tx-errors>
                                                        <tx-brate>5454680</tx-brate>
                                                        <rx-pkts>13</rx-pkts>
                                                        <rx-errors>0</rx-errors>
                                                        <rx-brate>57928</rx-brate>
                                                        <dl-cqi>15.0</dl-cqi>
                                                        <dl-ri>0</dl-ri>
                                                        <dl-pmi>0</dl-pmi>
                                                        <ul-phr>30.0</ul-phr>
                                                        <ul-sinr>104.522796630859375</ul-sinr>
                                                        <ul-rssi>0</ul-rssi>
                                                        <ul-mcs>22.352941513061523</ul-mcs>
                                                        <ul-samples>34</ul-samples>
                                                        <dl-mcs>27.875</dl-mcs>
                                                        <dl-samples>144</dl-samples>
                                                        <imsi>1010123456789</imsi>
                                                    </PerUEReportListItem>
                                                </perUEReportList>
                                            </du-PM-EPC>
                                        </ServedPlmnPerCellListItem>
                                    </servedPlmnPerCellList>
                                </CellResourceReportListItem>
                            </cellResourceReportList>
                        </oDU>
                    </performanceContainer>
                </PM-Containers-List>
                <PM-Containers-List>
                    <performanceContainer>
                        <oCU-CP>
                            <cu-CP-Resource-Status>
                                <numberOfActive-UEs>2</numberOfActive-UEs>
                            </cu-CP-Resource-Status>
                        </oCU-CP>
                    </performanceContainer>
                </PM-Containers-List>
                <PM-Containers-List>
                    <performanceContainer>
                        <oCU-UP>
                            <pf-ContainerList>
                                <PF-ContainerListItem>
                                    <interface-type><f1-u/></interface-type>
                                    <o-CU-UP-PM-Container>
                                        <plmnList>
                                            <PlmnID-List>
                                                <pLMN-Identity>00 F1 10</pLMN-Identity>
                                                <cu-UP-PM-EPC>
                                                    <perQCIReportList>
                                                        <PerQCIReportListItemFormat>
                                                            <qci>0</qci>
                                                            <pDCPBytesDL>0</pDCPBytesDL>
                                                            <pDCPBytesUL>0</pDCPBytesUL>
                                                        </PerQCIReportListItemFormat>
                                                        <PerQCIReportListItemFormat>
                                                            <qci>7</qci>
                                                            <pDCPBytesDL>13326628</pDCPBytesDL>
                                                            <pDCPBytesUL>111592</pDCPBytesUL>
                                                        </PerQCIReportListItemFormat>
                                                    </perQCIReportList>
                                                    <perUEReportList>
                                                        <PerUEReportListItemFormat>
                                                            <rnti>70</rnti>
                                                            <bytesDL>6663314</bytesDL>
                                                            <bytesUL>54236</bytesUL>
                                                        </PerUEReportListItemFormat>
                                                        <PerUEReportListItemFormat>
                                                            <rnti>71</rnti>
                                                            <bytesDL>6663314</bytesDL>
                                                            <bytesUL>57356</bytesUL>
                                                        </PerUEReportListItemFormat>
                                                    </perUEReportList>
                                                </cu-UP-PM-EPC>
                                            </PlmnID-List>
                                        </plmnList>
                                    </o-CU-UP-PM-Container>
                                </PF-ContainerListItem>
                            </pf-ContainerList>
                        </oCU-UP>
                    </performanceContainer>
                </PM-Containers-List>
            </pm-Containers>
        </indicationMessage-Format1>
    </indicationMessage>
</E2SM-KPM-IndicationMessage>
{"ts":1737231227331,"crit":"DEBUG","id":"nexran","mdc":{},"msg":"kpm indication report style 4 "}
{"ts":1737231227331,"crit":"DEBUG","id":"nexran","mdc":{},"msg":"nexran Indication handler"}
{"ts":1737231227331,"crit":"INFO","id":"nexran","mdc":{},"msg":"KpmIndication: KpmReport(period=5120 ms) available_dl_prbs=100 available_ul_prbs=100 ue[70]={dl_bytes=6663314,ul_bytes=54236,dl_prbs=71476,ul_prbs=1300,tx_pkts=75,tx_errors=0,tx_brate=5451224,rx_pkts=11,rx_errors=0,rx_brate=53656,dl_cqi=15,dl_ri=0,dl_pmi=0,ul_phr=30,ul_sinr=104.462,ul_mcs=22.32,ul_samples=25,dl_mcs=27.9533,dl_samples=150,imsi=1010123456780,} ue[71]={dl_bytes=6663314,ul_bytes=57356,dl_prbs=71548,ul_prbs=1259,tx_pkts=76,tx_errors=0,tx_brate=5454680,rx_pkts=13,rx_errors=0,rx_brate=57928,dl_cqi=15,dl_ri=0,dl_pmi=0,ul_phr=30,ul_sinr=104.523,ul_mcs=22.3529,ul_samples=34,dl_mcs=27.875,dl_samples=144,imsi=1010123456789,} "}
{"ts":1737231227344,"crit":"DEBUG","id":"nexran","mdc":{},"msg":"no slices in KPM report; not autoequalizing"}
{"ts":1737231227345,"crit":"DEBUG","id":"nexran","mdc":{},"msg":"current shares: fast[share=1024] secure_slice[share=1] "}
{"ts":1737231231884,"crit":"DEBUG","id":"nexran","mdc":{},"msg":"added ue 001010123456780"}
{"ts":1737231232447,"crit":"DEBUG","id":"nexran","mdc":{},"msg":"RMR message (type 12050, source enB_macro_001_001_0019b0)"}
<E2AP-PDU>
    <initiatingMessage>
        <procedureCode>5</procedureCode>
        <criticality><reject/></criticality>
        <value>
            <RICindication>
                <protocolIEs>
                    <RICindication-IEs>
                        <id>29</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICrequestID>
                                <ricRequestorID>123</ricRequestorID>
                                <ricInstanceID>7</ricInstanceID>
                            </RICrequestID>
                        </value>
                    </RICindication-IEs>
                    <RICindication-IEs>
                        <id>5</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RANfunctionID>0</RANfunctionID>
                        </value>
                    </RICindication-IEs>
                    <RICindication-IEs>
                        <id>15</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICactionID>1</RICactionID>
                        </value>
                    </RICindication-IEs>
                    <RICindication-IEs>
                        <id>27</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICindicationSN>6</RICindicationSN>
                        </value>
                    </RICindication-IEs>
                    <RICindication-IEs>
                        <id>28</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICindicationType><report/></RICindicationType>
                        </value>
                    </RICindication-IEs>
                    <RICindication-IEs>
                        <id>26</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICindicationMessage>
                                01 04 00 00 02 40 00 00 60 00 F1 10 00 00 00 00 
                                10 00 64 00 64 02 00 F1 10 80 00 00 00 03 00 80 
                                8E 00 01 00 00 46 20 01 16 FC 10 04 B6 01 57 01 
                                00 03 5E AA B0 01 0E 01 00 03 01 1B 70 03 80 00 
                                0F 00 00 03 80 01 0F 06 80 EF 00 D0 B1 11 00 06 
                                80 ED 00 AF 6D B7 01 1C 06 80 EE 00 6F 95 AF 02 
                                00 B7 06 00 EB 30 0C C1 0C 00 00 47 20 01 18 7C 
                                10 04 C3 01 5A 01 00 03 63 D4 90 01 0E 01 00 03 
                                01 1E E0 03 80 00 0F 00 00 03 80 01 0F 06 80 EF 
                                00 D1 11 99 00 06 80 EE 00 59 6D B7 01 1C 06 80 
                                ED 00 DF 77 77 02 00 B4 06 00 EB 30 0C C1 15 4A 
                                00 01 50 10 08 00 F1 10 80 01 60 00 00 00 00 00 
                                60 07 20 CB 59 24 20 01 A4 78 03 00 16 00 01 00 
                                00 46 20 65 AC 92 10 D2 D8 00 00 47 20 65 AC 92 
                                10 D1 A0
                            </RICindicationMessage>
                        </value>
                    </RICindication-IEs>
                    <RICindication-IEs>
                        <id>25</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICindicationHeader>08 00 F1 10</RICindicationHeader>
                        </value>
                    </RICindication-IEs>
                </protocolIEs>
            </RICindication>
        </value>
    </initiatingMessage>
</E2AP-PDU>
{"ts":1737231232448,"crit":"INFO","id":"nexran","mdc":{},"msg":"decoded initiating RICindication (5) "}
<E2SM-KPM-IndicationHeader>
    <indicationHeader-Format1>
        <pLMN-Identity>00 F1 10</pLMN-Identity>
    </indicationHeader-Format1>
</E2SM-KPM-IndicationHeader>
<E2SM-KPM-IndicationMessage>
    <ric-Style-Type>4</ric-Style-Type>
    <indicationMessage>
        <indicationMessage-Format1>
            <pm-Containers>
                <PM-Containers-List>
                    <performanceContainer>
                        <oDU>
                            <cellResourceReportList>
                                <CellResourceReportListItem>
                                    <nRCGI>
                                        <pLMN-Identity>00 F1 10</pLMN-Identity>
                                        <nRCellIdentity>
                                            000000000000000000000000000000000001
                                        </nRCellIdentity>
                                    </nRCGI>
                                    <dl-TotalofAvailablePRBs>100</dl-TotalofAvailablePRBs>
                                    <ul-TotalofAvailablePRBs>100</ul-TotalofAvailablePRBs>
                                    <servedPlmnPerCellList>
                                        <ServedPlmnPerCellListItem>
                                            <pLMN-Identity>00 F1 10</pLMN-Identity>
                                            <du-PM-EPC>
                                                <perQCIReportList>
                                                    <PerQCIReportListItem>
                                                        <qci>0</qci>
                                                    </PerQCIReportListItem>
                                                </perQCIReportList>
                                                <perUEReportList>
                                                    <PerUEReportListItem>
                                                        <rnti>70</rnti>
                                                        <dl-PRBUsage>71420</dl-PRBUsage>
                                                        <ul-PRBUsage>1206</ul-PRBUsage>
                                                        <tx-pkts>87</tx-pkts>
                                                        <tx-errors>0</tx-errors>
                                                        <tx-brate>6204080</tx-brate>
                                                        <rx-pkts>14</rx-pkts>
                                                        <rx-errors>0</rx-errors>
                                                        <rx-brate>72560</rx-brate>
                                                        <dl-cqi>15.0</dl-cqi>
                                                        <dl-ri>0</dl-ri>
                                                        <dl-pmi>0</dl-pmi>
                                                        <ul-phr>30.0</ul-phr>
                                                        <ul-sinr>104.345832824707031</ul-sinr>
                                                        <ul-rssi>0</ul-rssi>
                                                        <ul-mcs>21.928571701049805</ul-mcs>
                                                        <ul-samples>28</ul-samples>
                                                        <dl-mcs>27.896175384521484</dl-mcs>
                                                        <dl-samples>183</dl-samples>
                                                        <imsi>1010123456780</imsi>
                                                    </PerUEReportListItem>
                                                    <PerUEReportListItem>
                                                        <rnti>71</rnti>
                                                        <dl-PRBUsage>71804</dl-PRBUsage>
                                                        <ul-PRBUsage>1219</ul-PRBUsage>
                                                        <tx-pkts>90</tx-pkts>
                                                        <tx-errors>0</tx-errors>
                                                        <tx-brate>6542480</tx-brate>
                                                        <rx-pkts>14</rx-pkts>
                                                        <rx-errors>0</rx-errors>
                                                        <rx-brate>73440</rx-brate>
                                                        <dl-cqi>15.0</dl-cqi>
                                                        <dl-ri>0</dl-ri>
                                                        <dl-pmi>0</dl-pmi>
                                                        <ul-phr>30.0</ul-phr>
                                                        <ul-sinr>104.534370422363281</ul-sinr>
                                                        <ul-rssi>0</ul-rssi>
                                                        <ul-mcs>22.357143402099609</ul-mcs>
                                                        <ul-samples>28</ul-samples>
                                                        <dl-mcs>27.933332443237305</dl-mcs>
                                                        <dl-samples>180</dl-samples>
                                                        <imsi>1010123456789</imsi>
                                                    </PerUEReportListItem>
                                                </perUEReportList>
                                            </du-PM-EPC>
                                        </ServedPlmnPerCellListItem>
                                    </servedPlmnPerCellList>
                                </CellResourceReportListItem>
                            </cellResourceReportList>
                        </oDU>
                    </performanceContainer>
                </PM-Containers-List>
                <PM-Containers-List>
                    <performanceContainer>
                        <oCU-CP>
                            <cu-CP-Resource-Status>
                                <numberOfActive-UEs>2</numberOfActive-UEs>
                            </cu-CP-Resource-Status>
                        </oCU-CP>
                    </performanceContainer>
                </PM-Containers-List>
                <PM-Containers-List>
                    <performanceContainer>
                        <oCU-UP>
                            <pf-ContainerList>
                                <PF-ContainerListItem>
                                    <interface-type><f1-u/></interface-type>
                                    <o-CU-UP-PM-Container>
                                        <plmnList>
                                            <PlmnID-List>
                                                <pLMN-Identity>00 F1 10</pLMN-Identity>
                                                <cu-UP-PM-EPC>
                                                    <perQCIReportList>
                                                        <PerQCIReportListItemFormat>
                                                            <qci>0</qci>
                                                            <pDCPBytesDL>0</pDCPBytesDL>
                                                            <pDCPBytesUL>0</pDCPBytesUL>
                                                        </PerQCIReportListItemFormat>
                                                        <PerQCIReportListItemFormat>
                                                            <qci>7</qci>
                                                            <pDCPBytesDL>13326628</pDCPBytesDL>
                                                            <pDCPBytesUL>107640</pDCPBytesUL>
                                                        </PerQCIReportListItemFormat>
                                                    </perQCIReportList>
                                                    <perUEReportList>
                                                        <PerUEReportListItemFormat>
                                                            <rnti>70</rnti>
                                                            <bytesDL>6663314</bytesDL>
                                                            <bytesUL>53976</bytesUL>
                                                        </PerUEReportListItemFormat>
                                                        <PerUEReportListItemFormat>
                                                            <rnti>71</rnti>
                                                            <bytesDL>6663314</bytesDL>
                                                            <bytesUL>53664</bytesUL>
                                                        </PerUEReportListItemFormat>
                                                    </perUEReportList>
                                                </cu-UP-PM-EPC>
                                            </PlmnID-List>
                                        </plmnList>
                                    </o-CU-UP-PM-Container>
                                </PF-ContainerListItem>
                            </pf-ContainerList>
                        </oCU-UP>
                    </performanceContainer>
                </PM-Containers-List>
            </pm-Containers>
        </indicationMessage-Format1>
    </indicationMessage>
{"ts":1737231232451,"crit":"DEBUG","id":"nexran","mdc":{},"msg":"kpm indication report style 4 "}
</E2SM-KPM-IndicationMessage>
{"ts":1737231232451,"crit":"DEBUG","id":"nexran","mdc":{},"msg":"nexran Indication handler"}
{"ts":1737231232452,"crit":"INFO","id":"nexran","mdc":{},"msg":"KpmIndication: KpmReport(period=5120 ms) available_dl_prbs=100 available_ul_prbs=100 ue[70]={dl_bytes=6663314,ul_bytes=53976,dl_prbs=71420,ul_prbs=1206,tx_pkts=87,tx_errors=0,tx_brate=6204080,rx_pkts=14,rx_errors=0,rx_brate=72560,dl_cqi=15,dl_ri=0,dl_pmi=0,ul_phr=30,ul_sinr=104.346,ul_mcs=21.9286,ul_samples=28,dl_mcs=27.8962,dl_samples=183,imsi=1010123456780,} ue[71]={dl_bytes=6663314,ul_bytes=53664,dl_prbs=71804,ul_prbs=1219,tx_pkts=90,tx_errors=0,tx_brate=6542480,rx_pkts=14,rx_errors=0,rx_brate=73440,dl_cqi=15,dl_ri=0,dl_pmi=0,ul_phr=30,ul_sinr=104.534,ul_mcs=22.3571,ul_samples=28,dl_mcs=27.9333,dl_samples=180,imsi=1010123456789,} "}
{"ts":1737231232466,"crit":"DEBUG","id":"nexran","mdc":{},"msg":"no slices in KPM report; not autoequalizing"}
{"ts":1737231232466,"crit":"DEBUG","id":"nexran","mdc":{},"msg":"current shares: fast[share=1024] secure_slice[share=1] "}
<E2SM-NexRAN-ControlHeader>
    <controlHeaderFormat1>
        <controlMessageId><sliceUeBindRequest/></controlMessageId>
    </controlHeaderFormat1>
</E2SM-NexRAN-ControlHeader>
<E2SM-NexRAN-ControlMessage>
    <controlMessageFormat1>
        <sliceUeBindRequest>
            <sliceName>fast</sliceName>
            <imsiList>
                <IMSI>30 30 31 30 31 30 31 32 33 34 35 36 37 38 39</IMSI>
            </imsiList>
        </sliceUeBindRequest>
    </controlMessageFormat1>
</E2SM-NexRAN-ControlMessage>
<E2AP-PDU>
    <initiatingMessage>
        <procedureCode>4</procedureCode>
        <criticality><reject/></criticality>
        <value>
            <RICcontrolRequest>
                <protocolIEs>
                    <RICcontrolRequest-IEs>
                        <id>29</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICrequestID>
                                <ricRequestorID>50526</ricRequestorID>
                                <ricInstanceID>8</ricInstanceID>
                            </RICrequestID>
                        </value>
                    </RICcontrolRequest-IEs>
                    <RICcontrolRequest-IEs>
                        <id>5</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RANfunctionID>1</RANfunctionID>
                        </value>
                    </RICcontrolRequest-IEs>
                    <RICcontrolRequest-IEs>
                        <id>22</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICcontrolHeader>0C</RICcontrolHeader>
                        </value>
                    </RICcontrolRequest-IEs>
                    <RICcontrolRequest-IEs>
                        <id>23</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICcontrolMessage>
                                18 18 66 61 73 74 00 3C 30 30 31 30 31 30 31 32 
                                33 34 35 36 37 38 39
                            </RICcontrolMessage>
                        </value>
                    </RICcontrolRequest-IEs>
                    <RICcontrolRequest-IEs>
                        <id>21</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICcontrolAckRequest><ack/></RICcontrolAckRequest>
                        </value>
                    </RICcontrolRequest-IEs>
                </protocolIEs>
            </RICcontrolRequest>
        </value>
    </initiatingMessage>
</E2AP-PDU>
{"ts":1737231236912,"crit":"DEBUG","id":"nexran","mdc":{},"msg":"sent control request (subid=-2003346831,requestor_id=50526,instance_id=8,meid=enB_macro_001_001_0019b0) "}
{"ts":1737231236912,"crit":"DEBUG","id":"nexran","mdc":{},"msg":"bound ue 001010123456789 to slice fast"}
{"ts":1737231236918,"crit":"DEBUG","id":"nexran","mdc":{},"msg":"RMR message (type 12041, source enB_macro_001_001_0019b0)"}
<E2AP-PDU>
    <successfulOutcome>
        <procedureCode>4</procedureCode>
        <criticality><reject/></criticality>
        <value>
            <RICcontrolAcknowledge>
                <protocolIEs>
                    <RICcontrolAcknowledge-IEs>
                        <id>29</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICrequestID>
                                <ricRequestorID>50526</ricRequestorID>
                                <ricInstanceID>8</ricInstanceID>
                            </RICrequestID>
                        </value>
                    </RICcontrolAcknowledge-IEs>
                    <RICcontrolAcknowledge-IEs>
                        <id>5</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RANfunctionID>1</RANfunctionID>
                        </value>
                    </RICcontrolAcknowledge-IEs>
                    <RICcontrolAcknowledge-IEs>
                        <id>24</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICcontrolStatus><success/></RICcontrolStatus>
                        </value>
                    </RICcontrolAcknowledge-IEs>
                    <RICcontrolAcknowledge-IEs>
                        <id>32</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICcontrolOutcome>
                                02 03 66 61 73 74 00 04 00 00 01 0D 31 30 31 30 
{"ts":1737231236918,"crit":"INFO","id":"nexran","mdc":{},"msg":"decoded successful outcome RICcontrol (4) "}
                                31 32 33 34 35 36 37 38 39 85 80 73 65 63 75 72 
                                65 5F 73 6C 69 63 65 00 00 01 00 00
                            </RICcontrolOutcome>
                        </value>
                    </RICcontrolAcknowledge-IEs>
                </protocolIEs>
            </RICcontrolAcknowledge>
        </value>
    </successfulOutcome>
</E2AP-PDU>
<E2SM-NexRAN-ControlOutcome>
    <controlOutcomeFormat1>
        <sliceStatusReport>
            <sliceStatusList>
                <SliceStatus>
                    <sliceName>fast</sliceName>
                    <schedPolicy>
                        <proportionalAllocationPolicy>
{"ts":1737231236919,"crit":"DEBUG","id":"nexran","mdc":{},"msg":"nexran ControlAck handler"}
                            <share>1024</share>
                        </proportionalAllocationPolicy>
                    </schedPolicy>
                    <ueList>
                        <UeStatus>
                            <imsi>31 30 31 30 31 32 33 34 35 36 37 38 39</imsi>
                            <connected><true/></connected>
                        </UeStatus>
                    </ueList>
                </SliceStatus>
                <SliceStatus>
                    <sliceName>secure_slice</sliceName>
                    <schedPolicy>
                        <proportionalAllocationPolicy>
                            <share>1</share>
                        </proportionalAllocationPolicy>
                    </schedPolicy>
                    <ueList>
                    </ueList>
                </SliceStatus>
            </sliceStatusList>
        </sliceStatusReport>
    </controlOutcomeFormat1>
</E2SM-NexRAN-ControlOutcome>
<E2SM-NexRAN-ControlHeader>
    <controlHeaderFormat1>
        <controlMessageId><sliceUeBindRequest/></controlMessageId>
    </controlHeaderFormat1>
</E2SM-NexRAN-ControlHeader>
<E2SM-NexRAN-ControlMessage>
    <controlMessageFormat1>
        <sliceUeBindRequest>
            <sliceName>fast</sliceName>
            <imsiList>
                <IMSI>30 30 31 30 31 30 31 32 33 34 35 36 37 38 30</IMSI>
            </imsiList>
        </sliceUeBindRequest>
    </controlMessageFormat1>
</E2SM-NexRAN-ControlMessage>
<E2AP-PDU>
    <initiatingMessage>
        <procedureCode>4</procedureCode>
        <criticality><reject/></criticality>
        <value>
            <RICcontrolRequest>
                <protocolIEs>
                    <RICcontrolRequest-IEs>
                        <id>29</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICrequestID>
                                <ricRequestorID>50526</ricRequestorID>
                                <ricInstanceID>9</ricInstanceID>
                            </RICrequestID>
                        </value>
                    </RICcontrolRequest-IEs>
                    <RICcontrolRequest-IEs>
                        <id>5</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RANfunctionID>1</RANfunctionID>
                        </value>
                    </RICcontrolRequest-IEs>
                    <RICcontrolRequest-IEs>
                        <id>22</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICcontrolHeader>0C</RICcontrolHeader>
                        </value>
                    </RICcontrolRequest-IEs>
                    <RICcontrolRequest-IEs>
                        <id>23</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICcontrolMessage>
                                18 18 66 61 73 74 00 3C 30 30 31 30 31 30 31 32 
                                33 34 35 36 37 38 30
                            </RICcontrolMessage>
                        </value>
                    </RICcontrolRequest-IEs>
                    <RICcontrolRequest-IEs>
                        <id>21</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICcontrolAckRequest><ack/></RICcontrolAckRequest>
                        </value>
                    </RICcontrolRequest-IEs>
                </protocolIEs>
            </RICcontrolRequest>
        </value>
    </initiatingMessage>
</E2AP-PDU>
{"ts":1737231236939,"crit":"DEBUG","id":"nexran","mdc":{},"msg":"sent control request (subid=1584666705,requestor_id=50526,instance_id=9,meid=enB_macro_001_001_0019b0) "}
{"ts":1737231236939,"crit":"DEBUG","id":"nexran","mdc":{},"msg":"bound ue 001010123456780 to slice fast"}
<E2AP-PDU>
    <successfulOutcome>
        <procedureCode>4</procedureCode>
        <criticality><reject/></criticality>
        <value>
            <RICcontrolAcknowledge>
                <protocolIEs>
{"ts":1737231236946,"crit":"DEBUG","id":"nexran","mdc":{},"msg":"RMR message (type 12041, source enB_macro_001_001_0019b0)"}
                    <RICcontrolAcknowledge-IEs>
                        <id>29</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICrequestID>
                                <ricRequestorID>50526</ricRequestorID>
                                <ricInstanceID>9</ricInstanceID>
                            </RICrequestID>
                        </value>
                    </RICcontrolAcknowledge-IEs>
                    <RICcontrolAcknowledge-IEs>
                        <id>5</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RANfunctionID>1</RANfunctionID>
                        </value>
                    </RICcontrolAcknowledge-IEs>
                    <RICcontrolAcknowledge-IEs>
                        <id>24</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICcontrolStatus><success/></RICcontrolStatus>
                        </value>
                    </RICcontrolAcknowledge-IEs>
                    <RICcontrolAcknowledge-IEs>
                        <id>32</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICcontrolOutcome>
                                02 03 66 61 73 74 00 04 00 00 02 0D 31 30 31 30 
                                31 32 33 34 35 36 37 38 39 86 80 31 30 31 30 31 
                                32 33 34 35 36 37 38 30 85 80 73 65 63 75 72 65 
                                5F 73 6C 69 63 65 00 00 01 00 00
                            </RICcontrolOutcome>
                        </value>
                    </RICcontrolAcknowledge-IEs>
                </protocolIEs>
            </RICcontrolAcknowledge>
        </value>
    </successfulOutcome>
</E2AP-PDU>
<E2SM-NexRAN-ControlOutcome>
    <controlOutcomeFormat1>
        <sliceStatusReport>
            <sliceStatusList>
                <SliceStatus>
                    <sliceName>fast</sliceName>
                    <schedPolicy>
                        <proportionalAllocationPolicy>
                            <share>1024</share>
                        </proportionalAllocationPolicy>
                    </schedPolicy>
                    <ueList>
                        <UeStatus>
                            <imsi>31 30 31 30 31 32 33 34 35 36 37 38 39</imsi>
                            <connected><true/></connected>
                        </UeStatus>
                        <UeStatus>
                            <imsi>31 30 31 30 31 32 33 34 35 36 37 38 30</imsi>
                            <connected><true/></connected>
                        </UeStatus>
                    </ueList>
                </SliceStatus>
                <SliceStatus>
{"ts":1737231236946,"crit":"INFO","id":"nexran","mdc":{},"msg":"decoded successful outcome RICcontrol (4) "}
                    <sliceName>secure_slice</sliceName>
                    <schedPolicy>
                        <proportionalAllocationPolicy>
                            <share>1</share>
                        </proportionalAllocationPolicy>
                    </schedPolicy>
                    <ueList>
                    </ueList>
                </SliceStatus>
            </sliceStatusList>
        </sliceStatusReport>
    </controlOutcomeFormat1>
</E2SM-NexRAN-ControlOutcome>
{"ts":1737231236947,"crit":"DEBUG","id":"nexran","mdc":{},"msg":"nexran ControlAck handler"}
{"ts":1737231237569,"crit":"DEBUG","id":"nexran","mdc":{},"msg":"RMR message (type 12050, source enB_macro_001_001_0019b0)"}
<E2AP-PDU>
    <initiatingMessage>
        <procedureCode>5</procedureCode>
        <criticality><reject/></criticality>
        <value>
            <RICindication>
                <protocolIEs>
                    <RICindication-IEs>
                        <id>29</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICrequestID>
                                <ricRequestorID>123</ricRequestorID>
                                <ricInstanceID>7</ricInstanceID>
                            </RICrequestID>
                        </value>
                    </RICindication-IEs>
                    <RICindication-IEs>
                        <id>5</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RANfunctionID>0</RANfunctionID>
                        </value>
                    </RICindication-IEs>
                    <RICindication-IEs>
                        <id>15</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICactionID>1</RICactionID>
                        </value>
                    </RICindication-IEs>
                    <RICindication-IEs>
                        <id>27</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICindicationSN>7</RICindicationSN>
                        </value>
                    </RICindication-IEs>
                    <RICindication-IEs>
                        <id>28</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICindicationType><report/></RICindicationType>
                        </value>
                    </RICindication-IEs>
                    <RICindication-IEs>
                        <id>26</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICindicationMessage>
                                01 04 00 00 02 40 00 00 60 00 F1 10 00 00 00 00 
                                10 00 64 00 64 02 00 F1 10 80 00 00 00 03 80 80 
                                8B 00 01 00 00 46 20 01 14 C4 10 04 C0 01 6A 01 
                                00 03 72 99 28 01 13 01 00 03 01 5A 68 03 80 00 
                                0F 00 00 03 80 01 0F 06 80 EF 00 D0 E8 BD 00 06 
                                80 EE 00 58 53 07 01 25 05 80 F5 00 DF 75 02 00 
                                DD 06 00 EB 30 0C C1 0C 00 00 47 20 01 18 90 10 
                                04 B6 01 6A 01 01 03 74 74 88 01 11 01 00 03 01 
                                40 E8 03 80 00 0F 00 00 03 80 01 0F 06 80 F0 00 
                                68 84 89 00 04 80 FD 00 AF 01 20 06 80 ED 00 DF 
                                24 E9 02 00 D7 06 00 EB 30 0C C1 15 3F 00 00 03 
                                66 61 73 74 20 02 2D 54 10 09 76 02 00 D4 01 01 
                                04 00 E7 0D B0 01 24 01 00 03 02 9B 50 03 80 00 
                                0F 00 00 03 80 01 0F 00 00 06 80 ED 00 AF D3 07 
                                01 45 06 80 EF 00 37 D3 3D 02 01 B4 4A 00 01 50 
                                10 08 00 F1 10 80 01 60 00 00 00 00 00 60 07 20 
                                CB 59 24 20 01 A6 18 03 80 16 00 01 00 00 46 20 
                                65 AC 92 10 CC F4 00 00 47 20 65 AC 92 10 D9 24 
                                0F 00 00 03 66 61 73 74 20 CB 59 24 20 01 A6 18
                            </RICindicationMessage>
                        </value>
                    </RICindication-IEs>
                    <RICindication-IEs>
                        <id>25</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICindicationHeader>08 00 F1 10</RICindicationHeader>
                        </value>
                    </RICindication-IEs>
                </protocolIEs>
            </RICindication>
        </value>
    </initiatingMessage>
</E2AP-PDU>
<E2SM-KPM-IndicationHeader>
    <indicationHeader-Format1>
        <pLMN-Identity>00 F1 10</pLMN-Identity>
    </indicationHeader-Format1>
</E2SM-KPM-IndicationHeader>
<E2SM-KPM-IndicationMessage>
    <ric-Style-Type>4</ric-Style-Type>
    <indicationMessage>
        <indicationMessage-Format1>
            <pm-Containers>
                <PM-Containers-List>
                    <performanceContainer>
                        <oDU>
                            <cellResourceReportList>
                                <CellResourceReportListItem>
                                    <nRCGI>
                                        <pLMN-Identity>00 F1 10</pLMN-Identity>
{"ts":1737231237570,"crit":"INFO","id":"nexran","mdc":{},"msg":"decoded initiating RICindication (5) "}
                                        <nRCellIdentity>
                                            000000000000000000000000000000000001
                                        </nRCellIdentity>
                                    </nRCGI>
                                    <dl-TotalofAvailablePRBs>100</dl-TotalofAvailablePRBs>
                                    <ul-TotalofAvailablePRBs>100</ul-TotalofAvailablePRBs>
                                    <servedPlmnPerCellList>
                                        <ServedPlmnPerCellListItem>
                                            <pLMN-Identity>00 F1 10</pLMN-Identity>
                                            <du-PM-EPC>
                                                <perQCIReportList>
                                                    <PerQCIReportListItem>
                                                        <qci>0</qci>
                                                    </PerQCIReportListItem>
                                                </perQCIReportList>
                                                <perUEReportList>
                                                    <PerUEReportListItem>
                                                        <rnti>70</rnti>
                                                        <dl-PRBUsage>70852</dl-PRBUsage>
                                                        <ul-PRBUsage>1216</ul-PRBUsage>
                                                        <tx-pkts>106</tx-pkts>
                                                        <tx-errors>0</tx-errors>
                                                        <tx-brate>7510312</tx-brate>
                                                        <rx-pkts>19</rx-pkts>
                                                        <rx-errors>0</rx-errors>
                                                        <rx-brate>88680</rx-brate>
                                                        <dl-cqi>15.0</dl-cqi>
                                                        <dl-ri>0</dl-ri>
                                                        <dl-pmi>0</dl-pmi>
                                                        <ul-phr>30.0</ul-phr>
                                                        <ul-sinr>104.454566955566406</ul-sinr>
                                                        <ul-rssi>0</ul-rssi>
                                                        <ul-mcs>22.081081390380859</ul-mcs>
                                                        <ul-samples>37</ul-samples>
                                                        <dl-mcs>27.93212890625</dl-mcs>
                                                        <dl-samples>221</dl-samples>
                                                        <imsi>1010123456780</imsi>
                                                    </PerUEReportListItem>
                                                    <PerUEReportListItem>
                                                        <rnti>71</rnti>
                                                        <dl-PRBUsage>71824</dl-PRBUsage>
                                                        <ul-PRBUsage>1206</ul-PRBUsage>
                                                        <tx-pkts>106</tx-pkts>
                                                        <tx-errors>1</tx-errors>
                                                        <tx-brate>7632008</tx-brate>
                                                        <rx-pkts>17</rx-pkts>
                                                        <rx-errors>0</rx-errors>
                                                        <rx-brate>82152</rx-brate>
                                                        <dl-cqi>15.0</dl-cqi>
                                                        <dl-ri>0</dl-ri>
                                                        <dl-pmi>0</dl-pmi>
                                                        <ul-phr>30.0</ul-phr>
                                                        <ul-sinr>104.517715454101562</ul-sinr>
                                                        <ul-rssi>0</ul-rssi>
                                                        <ul-mcs>21.875</ul-mcs>
                                                        <ul-samples>32</ul-samples>
                                                        <dl-mcs>27.893022537231445</dl-mcs>
                                                        <dl-samples>215</dl-samples>
                                                        <imsi>1010123456789</imsi>
                                                    </PerUEReportListItem>
                                                </perUEReportList>
{"ts":1737231237573,"crit":"DEBUG","id":"nexran","mdc":{},"msg":"kpm indication report style 4 "}
{"ts":1737231237573,"crit":"DEBUG","id":"nexran","mdc":{},"msg":"nexran Indication handler"}
                                                <perSliceReportList>
                                                    <PerSliceReportListItem>
                                                        <sliceName>fast</sliceName>
                                                        <dl-PRBUsage>142676</dl-PRBUsage>
                                                        <ul-PRBUsage>2422</ul-PRBUsage>
                                                        <tx-pkts>212</tx-pkts>
                                                        <tx-errors>1</tx-errors>
                                                        <tx-brate>15142320</tx-brate>
                                                        <rx-pkts>36</rx-pkts>
                                                        <rx-errors>0</rx-errors>
                                                        <rx-brate>170832</rx-brate>
                                                        <dl-cqi>15.0</dl-cqi>
                                                        <dl-ri>0</dl-ri>
                                                        <dl-pmi>0</dl-pmi>
                                                        <ul-phr>30.0</ul-phr>
                                                        <ul-sinr>0</ul-sinr>
                                                        <ul-rssi>0</ul-rssi>
                                                        <ul-mcs>21.97804069519043</ul-mcs>
                                                        <ul-samples>69</ul-samples>
                                                        <dl-mcs>27.912574768066406</dl-mcs>
{"ts":1737231237573,"crit":"INFO","id":"nexran","mdc":{},"msg":"KpmIndication: KpmReport(period=5120 ms) available_dl_prbs=100 available_ul_prbs=100 ue[70]={dl_bytes=6663314,ul_bytes=52468,dl_prbs=70852,ul_prbs=1216,tx_pkts=106,tx_errors=0,tx_brate=7510312,rx_pkts=19,rx_errors=0,rx_brate=88680,dl_cqi=15,dl_ri=0,dl_pmi=0,ul_phr=30,ul_sinr=104.455,ul_mcs=22.0811,ul_samples=37,dl_mcs=27.9321,dl_samples=221,imsi=1010123456780,} ue[71]={dl_bytes=6663314,ul_bytes=55588,dl_prbs=71824,ul_prbs=1206,tx_pkts=106,tx_errors=1,tx_brate=7632008,rx_pkts=17,rx_errors=0,rx_brate=82152,dl_cqi=15,dl_ri=0,dl_pmi=0,ul_phr=30,ul_sinr=104.518,ul_mcs=21.875,ul_samples=32,dl_mcs=27.893,dl_samples=215,imsi=1010123456789,} slice[fast]={dl_bytes=13326628,ul_bytes=108056,dl_prbs=142676,ul_prbs=2422,tx_pkts=212,tx_errors=1,tx_brate=15142320,rx_pkts=36,rx_errors=0,rx_brate=170832,dl_cqi=15,dl_ri=0,dl_pmi=0,ul_phr=30,ul_sinr=0,ul_mcs=21.978,ul_samples=69,dl_mcs=27.9126,dl_samples=436,} "}
                                                        <dl-samples>436</dl-samples>
                                                    </PerSliceReportListItem>
                                                </perSliceReportList>
                                            </du-PM-EPC>
                                        </ServedPlmnPerCellListItem>
                                    </servedPlmnPerCellList>
                                </CellResourceReportListItem>
                            </cellResourceReportList>
                        </oDU>
                    </performanceContainer>
                </PM-Containers-List>
                <PM-Containers-List>
                    <performanceContainer>
                        <oCU-CP>
                            <cu-CP-Resource-Status>
                                <numberOfActive-UEs>2</numberOfActive-UEs>
                            </cu-CP-Resource-Status>
                        </oCU-CP>
                    </performanceContainer>
                </PM-Containers-List>
                <PM-Containers-List>
                    <performanceContainer>
                        <oCU-UP>
                            <pf-ContainerList>
                                <PF-ContainerListItem>
                                    <interface-type><f1-u/></interface-type>
                                    <o-CU-UP-PM-Container>
                                        <plmnList>
                                            <PlmnID-List>
                                                <pLMN-Identity>00 F1 10</pLMN-Identity>
                                                <cu-UP-PM-EPC>
                                                    <perQCIReportList>
                                                        <PerQCIReportListItemFormat>
                                                            <qci>0</qci>
                                                            <pDCPBytesDL>0</pDCPBytesDL>
                                                            <pDCPBytesUL>0</pDCPBytesUL>
                                                        </PerQCIReportListItemFormat>
                                                        <PerQCIReportListItemFormat>
                                                            <qci>7</qci>
                                                            <pDCPBytesDL>13326628</pDCPBytesDL>
                                                            <pDCPBytesUL>108056</pDCPBytesUL>
                                                        </PerQCIReportListItemFormat>
                                                    </perQCIReportList>
                                                    <perUEReportList>
                                                        <PerUEReportListItemFormat>
                                                            <rnti>70</rnti>
                                                            <bytesDL>6663314</bytesDL>
                                                            <bytesUL>52468</bytesUL>
                                                        </PerUEReportListItemFormat>
                                                        <PerUEReportListItemFormat>
                                                            <rnti>71</rnti>
                                                            <bytesDL>6663314</bytesDL>
                                                            <bytesUL>55588</bytesUL>
                                                        </PerUEReportListItemFormat>
                                                    </perUEReportList>
                                                    <perSliceReportList>
                                                        <PerSliceReportListItemFormat>
                                                            <sliceName>fast</sliceName>
                                                            <bytesDL>13326628</bytesDL>
                                                            <bytesUL>108056</bytesUL>
                                                        </PerSliceReportListItemFormat>
                                                    </perSliceReportList>
                                                </cu-UP-PM-EPC>
                                            </PlmnID-List>
                                        </plmnList>
                                    </o-CU-UP-PM-Container>
                                </PF-ContainerListItem>
                            </pf-ContainerList>
                        </oCU-UP>
                    </performanceContainer>
                </PM-Containers-List>
            </pm-Containers>
        </indicationMessage-Format1>
    </indicationMessage>
</E2SM-KPM-IndicationMessage>
{"ts":1737231237621,"crit":"INFO","id":"nexran","mdc":{},"msg":"# of UE Reports: 7"}
{"ts":1737231237621,"crit":"INFO","id":"nexran","mdc":{},"msg":"# of Slice Reports: 7"}
{"ts":1737231237635,"crit":"INFO","id":"nexran","mdc":{},"msg":"slice 'fast' share unchanged: 1024"}
{"ts":1737231237640,"crit":"INFO","id":"nexran","mdc":{},"msg":"slice 'secure_slice' share unchanged: 1"}
{"ts":1737231242691,"crit":"DEBUG","id":"nexran","mdc":{},"msg":"RMR message (type 12050, source enB_macro_001_001_0019b0)"}
<E2AP-PDU>
    <initiatingMessage>
        <procedureCode>5</procedureCode>
        <criticality><reject/></criticality>
        <value>
            <RICindication>
                <protocolIEs>
                    <RICindication-IEs>
                        <id>29</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICrequestID>
                                <ricRequestorID>123</ricRequestorID>
                                <ricInstanceID>7</ricInstanceID>
                            </RICrequestID>
                        </value>
                    </RICindication-IEs>
                    <RICindication-IEs>
                        <id>5</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RANfunctionID>0</RANfunctionID>
                        </value>
                    </RICindication-IEs>
                    <RICindication-IEs>
                        <id>15</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICactionID>1</RICactionID>
                        </value>
                    </RICindication-IEs>
                    <RICindication-IEs>
                        <id>27</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICindicationSN>8</RICindicationSN>
                        </value>
                    </RICindication-IEs>
                    <RICindication-IEs>
                        <id>28</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICindicationType><report/></RICindicationType>
                        </value>
                    </RICindication-IEs>
                    <RICindication-IEs>
                        <id>26</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICindicationMessage>
                                01 04 00 00 02 40 00 00 60 00 F1 10 00 00 00 00 
                                10 00 64 00 64 02 00 F1 10 80 00 00 00 03 80 80 
                                8B 00 01 00 00 46 20 01 13 C4 10 04 EE 01 79 01 
                                00 04 00 85 14 40 01 11 01 00 03 01 60 A8 03 80 
                                00 0F 00 00 03 80 01 0F 06 80 F1 00 34 40 9F 00 
                                04 80 FF 00 2D 01 22 05 80 F1 0D EF C1 02 01 04 
                                06 00 EB 30 0C C1 0C 00 00 47 20 01 17 90 10 04 
                                C5 01 7C 01 00 04 00 89 A2 D8 01 12 01 00 03 01 
                                55 10 03 80 00 0F 00 00 03 80 01 0F 06 80 F0 00 
                                68 86 79 00 04 80 FB 02 BD 01 20 06 80 EE 00 6F 
                                9A 61 02 01 06 06 00 EB 30 0C C1 15 3D 00 00 03 
                                66 61 73 74 20 02 2B 54 10 09 B3 02 00 F5 01 00 
                                04 01 0E B7 18 01 23 01 00 03 02 B5 B8 03 80 00 
                                0F 00 00 03 80 01 0F 00 00 04 80 FA 05 8D 01 42 
                                06 80 ED 00 DF 18 69 02 02 0A 4A 00 01 50 10 08 
                                00 F1 10 80 01 60 00 00 00 00 00 60 07 20 C9 45 
                                F2 20 01 AD 68 03 80 16 00 01 00 00 46 20 63 99 
                                60 10 D9 58 00 00 47 20 65 AC 92 10 D4 10 0F 00 
                                00 03 66 61 73 74 20 C9 45 F2 20 01 AD 68
                            </RICindicationMessage>
                        </value>
                    </RICindication-IEs>
                    <RICindication-IEs>
                        <id>25</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICindicationHeader>08 00 F1 10</RICindicationHeader>
                        </value>
                    </RICindication-IEs>
                </protocolIEs>
            </RICindication>
        </value>
    </initiatingMessage>
</E2AP-PDU>
{"ts":1737231242692,"crit":"INFO","id":"nexran","mdc":{},"msg":"decoded initiating RICindication (5) "}
<E2SM-KPM-IndicationHeader>
    <indicationHeader-Format1>
        <pLMN-Identity>00 F1 10</pLMN-Identity>
    </indicationHeader-Format1>
</E2SM-KPM-IndicationHeader>
<E2SM-KPM-IndicationMessage>
    <ric-Style-Type>4</ric-Style-Type>
    <indicationMessage>
        <indicationMessage-Format1>
            <pm-Containers>
                <PM-Containers-List>
                    <performanceContainer>
                        <oDU>
                            <cellResourceReportList>
                                <CellResourceReportListItem>
                                    <nRCGI>
                                        <pLMN-Identity>00 F1 10</pLMN-Identity>
                                        <nRCellIdentity>
                                            000000000000000000000000000000000001
                                        </nRCellIdentity>
                                    </nRCGI>
                                    <dl-TotalofAvailablePRBs>100</dl-TotalofAvailablePRBs>
                                    <ul-TotalofAvailablePRBs>100</ul-TotalofAvailablePRBs>
                                    <servedPlmnPerCellList>
                                        <ServedPlmnPerCellListItem>
                                            <pLMN-Identity>00 F1 10</pLMN-Identity>
                                            <du-PM-EPC>
                                                <perQCIReportList>
                                                    <PerQCIReportListItem>
                                                        <qci>0</qci>
                                                    </PerQCIReportListItem>
                                                </perQCIReportList>
                                                <perUEReportList>
                                                    <PerUEReportListItem>
                                                        <rnti>70</rnti>
                                                        <dl-PRBUsage>70596</dl-PRBUsage>
                                                        <ul-PRBUsage>1262</ul-PRBUsage>
                                                        <tx-pkts>121</tx-pkts>
                                                        <tx-errors>0</tx-errors>
                                                        <tx-brate>8721472</tx-brate>
                                                        <rx-pkts>17</rx-pkts>
                                                        <rx-errors>0</rx-errors>
                                                        <rx-brate>90280</rx-brate>
                                                        <dl-cqi>15.0</dl-cqi>
                                                        <dl-ri>0</dl-ri>
                                                        <dl-pmi>0</dl-pmi>
                                                        <ul-phr>30.0</ul-phr>
                                                        <ul-sinr>104.504852294921875</ul-sinr>
                                                        <ul-rssi>0</ul-rssi>
                                                        <ul-mcs>22.5</ul-mcs>
                                                        <ul-samples>34</ul-samples>
                                                        <dl-mcs>27.873077392578125</dl-mcs>
                                                        <dl-samples>260</dl-samples>
                                                        <imsi>1010123456780</imsi>
                                                    </PerUEReportListItem>
                                                    <PerUEReportListItem>
                                                        <rnti>71</rnti>
                                                        <dl-PRBUsage>71568</dl-PRBUsage>
                                                        <ul-PRBUsage>1221</ul-PRBUsage>
                                                        <tx-pkts>124</tx-pkts>
                                                        <tx-errors>0</tx-errors>
                                                        <tx-brate>9020120</tx-brate>
                                                        <rx-pkts>18</rx-pkts>
                                                        <rx-errors>0</rx-errors>
                                                        <rx-brate>87312</rx-brate>
                                                        <dl-cqi>15.0</dl-cqi>
                                                        <dl-ri>0</dl-ri>
                                                        <dl-pmi>0</dl-pmi>
                                                        <ul-phr>30.0</ul-phr>
                                                        <ul-sinr>104.525283813476562</ul-sinr>
                                                        <ul-rssi>0</ul-rssi>
                                                        <ul-mcs>21.90625</ul-mcs>
                                                        <ul-samples>32</ul-samples>
                                                        <dl-mcs>27.900760650634766</dl-mcs>
                                                        <dl-samples>262</dl-samples>
                                                        <imsi>1010123456789</imsi>
                                                    </PerUEReportListItem>
                                                </perUEReportList>
                                                <perSliceReportList>
                                                    <PerSliceReportListItem>
                                                        <sliceName>fast</sliceName>
                                                        <dl-PRBUsage>142164</dl-PRBUsage>
                                                        <ul-PRBUsage>2483</ul-PRBUsage>
                                                        <tx-pkts>245</tx-pkts>
                                                        <tx-errors>0</tx-errors>
                                                        <tx-brate>17741592</tx-brate>
                                                        <rx-pkts>35</rx-pkts>
                                                        <rx-errors>0</rx-errors>
                                                        <rx-brate>177592</rx-brate>
                                                        <dl-cqi>15.0</dl-cqi>
                                                        <dl-ri>0</dl-ri>
                                                        <dl-pmi>0</dl-pmi>
                                                        <ul-phr>30.0</ul-phr>
                                                        <ul-sinr>0</ul-sinr>
                                                        <ul-rssi>0</ul-rssi>
                                                        <ul-mcs>22.203125</ul-mcs>
                                                        <ul-samples>66</ul-samples>
                                                        <dl-mcs>27.886919021606445</dl-mcs>
                                                        <dl-samples>522</dl-samples>
                                                    </PerSliceReportListItem>
                                                </perSliceReportList>
                                            </du-PM-EPC>
                                        </ServedPlmnPerCellListItem>
                                    </servedPlmnPerCellList>
                                </CellResourceReportListItem>
                            </cellResourceReportList>
                        </oDU>
                    </performanceContainer>
                </PM-Containers-List>
                <PM-Containers-List>
                    <performanceContainer>
                        <oCU-CP>
                            <cu-CP-Resource-Status>
                                <numberOfActive-UEs>2</numberOfActive-UEs>
                            </cu-CP-Resource-Status>
                        </oCU-CP>
                    </performanceContainer>
                </PM-Containers-List>
                <PM-Containers-List>
                    <performanceContainer>
                        <oCU-UP>
                            <pf-ContainerList>
                                <PF-ContainerListItem>
                                    <interface-type><f1-u/></interface-type>
                                    <o-CU-UP-PM-Container>
                                        <plmnList>
                                            <PlmnID-List>
                                                <pLMN-Identity>00 F1 10</pLMN-Identity>
                                                <cu-UP-PM-EPC>
                                                    <perQCIReportList>
                                                        <PerQCIReportListItemFormat>
                                                            <qci>0</qci>
                                                            <pDCPBytesDL>0</pDCPBytesDL>
                                                            <pDCPBytesUL>0</pDCPBytesUL>
                                                        </PerQCIReportListItemFormat>
                                                        <PerQCIReportListItemFormat>
                                                            <qci>7</qci>
                                                            <pDCPBytesDL>13190642</pDCPBytesDL>
                                                            <pDCPBytesUL>109928</pDCPBytesUL>
                                                        </PerQCIReportListItemFormat>
                                                    </perQCIReportList>
                                                    <perUEReportList>
                                                        <PerUEReportListItemFormat>
                                                            <rnti>70</rnti>
                                                            <bytesDL>6527328</bytesDL>
                                                            <bytesUL>55640</bytesUL>
                                                        </PerUEReportListItemFormat>
                                                        <PerUEReportListItemFormat>
                                                            <rnti>71</rnti>
                                                            <bytesDL>6663314</bytesDL>
                                                            <bytesUL>54288</bytesUL>
                                                        </PerUEReportListItemFormat>
                                                    </perUEReportList>
                                                    <perSliceReportList>
                                                        <PerSliceReportListItemFormat>
                                                            <sliceName>fast</sliceName>
                                                            <bytesDL>13190642</bytesDL>
                                                            <bytesUL>109928</bytesUL>
                                                        </PerSliceReportListItemFormat>
                                                    </perSliceReportList>
                                                </cu-UP-PM-EPC>
                                            </PlmnID-List>
                                        </plmnList>
                                    </o-CU-UP-PM-Container>
                                </PF-ContainerListItem>
                            </pf-ContainerList>
                        </oCU-UP>
                    </performanceContainer>
                </PM-Containers-List>
            </pm-Containers>
        </indicationMessage-Format1>
    </indicationMessage>
</E2SM-KPM-IndicationMessage>
{"ts":1737231242695,"crit":"DEBUG","id":"nexran","mdc":{},"msg":"kpm indication report style 4 "}
{"ts":1737231242695,"crit":"DEBUG","id":"nexran","mdc":{},"msg":"nexran Indication handler"}
{"ts":1737231242695,"crit":"INFO","id":"nexran","mdc":{},"msg":"KpmIndication: KpmReport(period=5120 ms) available_dl_prbs=100 available_ul_prbs=100 ue[70]={dl_bytes=6527328,ul_bytes=55640,dl_prbs=70596,ul_prbs=1262,tx_pkts=121,tx_errors=0,tx_brate=8721472,rx_pkts=17,rx_errors=0,rx_brate=90280,dl_cqi=15,dl_ri=0,dl_pmi=0,ul_phr=30,ul_sinr=104.505,ul_mcs=22.5,ul_samples=34,dl_mcs=27.8731,dl_samples=260,imsi=1010123456780,} ue[71]={dl_bytes=6663314,ul_bytes=54288,dl_prbs=71568,ul_prbs=1221,tx_pkts=124,tx_errors=0,tx_brate=9020120,rx_pkts=18,rx_errors=0,rx_brate=87312,dl_cqi=15,dl_ri=0,dl_pmi=0,ul_phr=30,ul_sinr=104.525,ul_mcs=21.9062,ul_samples=32,dl_mcs=27.9008,dl_samples=262,imsi=1010123456789,} slice[fast]={dl_bytes=13190642,ul_bytes=109928,dl_prbs=142164,ul_prbs=2483,tx_pkts=245,tx_errors=0,tx_brate=17741592,rx_pkts=35,rx_errors=0,rx_brate=177592,dl_cqi=15,dl_ri=0,dl_pmi=0,ul_phr=30,ul_sinr=0,ul_mcs=22.2031,ul_samples=66,dl_mcs=27.8869,dl_samples=522,} "}
{"ts":1737231242718,"crit":"INFO","id":"nexran","mdc":{},"msg":"# of UE Reports: 8"}
{"ts":1737231242718,"crit":"INFO","id":"nexran","mdc":{},"msg":"# of Slice Reports: 8"}
{"ts":1737231242723,"crit":"INFO","id":"nexran","mdc":{},"msg":"slice 'fast' share unchanged: 1024"}
{"ts":1737231242729,"crit":"INFO","id":"nexran","mdc":{},"msg":"slice 'secure_slice' share unchanged: 1"}
{"ts":1737231247808,"crit":"DEBUG","id":"nexran","mdc":{},"msg":"RMR message (type 12050, source enB_macro_001_001_0019b0)"}
<E2AP-PDU>
    <initiatingMessage>
        <procedureCode>5</procedureCode>
        <criticality><reject/></criticality>
        <value>
            <RICindication>
                <protocolIEs>
                    <RICindication-IEs>
                        <id>29</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICrequestID>
                                <ricRequestorID>123</ricRequestorID>
                                <ricInstanceID>7</ricInstanceID>
                            </RICrequestID>
                        </value>
                    </RICindication-IEs>
                    <RICindication-IEs>
                        <id>5</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RANfunctionID>0</RANfunctionID>
                        </value>
                    </RICindication-IEs>
                    <RICindication-IEs>
                        <id>15</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICactionID>1</RICactionID>
                        </value>
                    </RICindication-IEs>
                    <RICindication-IEs>
                        <id>27</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICindicationSN>9</RICindicationSN>
                        </value>
                    </RICindication-IEs>
                    <RICindication-IEs>
                        <id>28</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICindicationType><report/></RICindicationType>
                        </value>
                    </RICindication-IEs>
                    <RICindication-IEs>
                        <id>26</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICindicationMessage>
                                01 04 00 00 02 40 00 00 60 00 F1 10 00 00 00 00 
                                10 00 64 00 64 02 00 F1 10 80 00 00 00 03 80 80 
                                8F 00 01 00 00 46 20 01 16 DC 10 04 F1 02 00 8C 
                                01 00 04 00 95 B5 28 01 17 01 00 03 01 BA 98 03 
                                80 00 0F 00 00 03 80 01 0F 06 80 EF 00 D0 9D 21 
                                00 06 80 ED 00 B2 8B A3 01 2C 06 80 EE 00 6F 48 
                                4B 02 01 2D 06 00 EB 30 0C C1 0C 00 00 47 20 01 
                                15 34 10 04 B1 02 00 88 01 01 04 00 95 BA B8 01 
                                16 01 00 03 01 BA 60 03 80 00 0F 00 00 03 80 01 
                                0F 06 80 F1 00 34 43 D5 00 04 80 FC 01 63 01 30 
                                05 80 F0 1B E5 B9 02 01 2E 06 00 EB 30 0C C1 15 
                                3F 00 00 03 66 61 73 74 20 02 2C 10 10 09 A2 02 
                                01 14 01 01 04 01 2B 6F E0 01 2D 01 00 03 03 74 
                                F8 03 80 00 0F 00 00 03 80 01 0F 00 00 06 80 EE 
                                00 59 02 E9 01 5C 06 80 ED 00 DE DF 2F 02 02 5B 
                                4A 00 01 50 10 08 00 F1 10 80 01 60 00 00 00 00 
                                00 60 07 20 CB 59 24 20 01 A5 B0 03 80 16 00 01 
                                00 00 46 20 65 AC 92 10 D6 E8 00 00 47 20 65 AC 
                                92 10 CE C8 0F 00 00 03 66 61 73 74 20 CB 59 24 
                                20 01 A5 B0
                            </RICindicationMessage>
                        </value>
                    </RICindication-IEs>
                    <RICindication-IEs>
                        <id>25</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICindicationHeader>08 00 F1 10</RICindicationHeader>
                        </value>
                    </RICindication-IEs>
                </protocolIEs>
            </RICindication>
        </value>
    </initiatingMessage>
</E2AP-PDU>
<E2SM-KPM-IndicationHeader>
    <indicationHeader-Format1>
        <pLMN-Identity>00 F1 10</pLMN-Identity>
    </indicationHeader-Format1>
</E2SM-KPM-IndicationHeader>
<E2SM-KPM-IndicationMessage>
    <ric-Style-Type>4</ric-Style-Type>
    <indicationMessage>
        <indicationMessage-Format1>
            <pm-Containers>
{"ts":1737231247809,"crit":"INFO","id":"nexran","mdc":{},"msg":"decoded initiating RICindication (5) "}
                <PM-Containers-List>
                    <performanceContainer>
                        <oDU>
                            <cellResourceReportList>
                                <CellResourceReportListItem>
                                    <nRCGI>
                                        <pLMN-Identity>00 F1 10</pLMN-Identity>
                                        <nRCellIdentity>
                                            000000000000000000000000000000000001
                                        </nRCellIdentity>
                                    </nRCGI>
                                    <dl-TotalofAvailablePRBs>100</dl-TotalofAvailablePRBs>
                                    <ul-TotalofAvailablePRBs>100</ul-TotalofAvailablePRBs>
                                    <servedPlmnPerCellList>
                                        <ServedPlmnPerCellListItem>
                                            <pLMN-Identity>00 F1 10</pLMN-Identity>
                                            <du-PM-EPC>
                                                <perQCIReportList>
                                                    <PerQCIReportListItem>
                                                        <qci>0</qci>
                                                    </PerQCIReportListItem>
                                                </perQCIReportList>
                                                <perUEReportList>
                                                    <PerUEReportListItem>
                                                        <rnti>70</rnti>
                                                        <dl-PRBUsage>71388</dl-PRBUsage>
                                                        <ul-PRBUsage>1265</ul-PRBUsage>
                                                        <tx-pkts>140</tx-pkts>
                                                        <tx-errors>0</tx-errors>
                                                        <tx-brate>9811240</tx-brate>
                                                        <rx-pkts>23</rx-pkts>
                                                        <rx-errors>0</rx-errors>
                                                        <rx-brate>113304</rx-brate>
                                                        <dl-cqi>15.0</dl-cqi>
                                                        <dl-ri>0</dl-ri>
                                                        <dl-pmi>0</dl-pmi>
                                                        <ul-phr>30.0</ul-phr>
                                                        <ul-sinr>104.306892395019531</ul-sinr>
                                                        <ul-rssi>0</ul-rssi>
                                                        <ul-mcs>22.318181991577148</ul-mcs>
                                                        <ul-samples>44</ul-samples>
                                                        <dl-mcs>27.820598602294922</dl-mcs>
                                                        <dl-samples>301</dl-samples>
                                                        <imsi>1010123456780</imsi>
                                                    </PerUEReportListItem>
                                                    <PerUEReportListItem>
                                                        <rnti>71</rnti>
                                                        <dl-PRBUsage>70964</dl-PRBUsage>
                                                        <ul-PRBUsage>1201</ul-PRBUsage>
                                                        <tx-pkts>136</tx-pkts>
                                                        <tx-errors>1</tx-errors>
                                                        <tx-brate>9812664</tx-brate>
                                                        <rx-pkts>22</rx-pkts>
                                                        <rx-errors>0</rx-errors>
                                                        <rx-brate>113248</rx-brate>
                                                        <dl-cqi>15.0</dl-cqi>
                                                        <dl-ri>0</dl-ri>
                                                        <dl-pmi>0</dl-pmi>
                                                        <ul-phr>30.0</ul-phr>
                                                        <ul-sinr>104.529937744140625</ul-sinr>
                                                        <ul-rssi>0</ul-rssi>
                                                        <ul-mcs>22.1875</ul-mcs>
                                                        <ul-samples>48</ul-samples>
                                                        <dl-mcs>27.897354125976562</dl-mcs>
                                                        <dl-samples>302</dl-samples>
                                                        <imsi>1010123456789</imsi>
                                                    </PerUEReportListItem>
                                                </perUEReportList>
                                                <perSliceReportList>
                                                    <PerSliceReportListItem>
                                                        <sliceName>fast</sliceName>
                                                        <dl-PRBUsage>142352</dl-PRBUsage>
                                                        <ul-PRBUsage>2466</ul-PRBUsage>
                                                        <tx-pkts>276</tx-pkts>
                                                        <tx-errors>1</tx-errors>
                                                        <tx-brate>19623904</tx-brate>
                                                        <rx-pkts>45</rx-pkts>
                                                        <rx-errors>0</rx-errors>
                                                        <rx-brate>226552</rx-brate>
                                                        <dl-cqi>15.0</dl-cqi>
                                                        <dl-ri>0</dl-ri>
                                                        <dl-pmi>0</dl-pmi>
                                                        <ul-phr>30.0</ul-phr>
                                                        <ul-sinr>0</ul-sinr>
                                                        <ul-rssi>0</ul-rssi>
                                                        <ul-mcs>22.252841949462891</ul-mcs>
                                                        <ul-samples>92</ul-samples>
                                                        <dl-mcs>27.858976364135742</dl-mcs>
                                                        <dl-samples>603</dl-samples>
                                                    </PerSliceReportListItem>
                                                </perSliceReportList>
                                            </du-PM-EPC>
                                        </ServedPlmnPerCellListItem>
                                    </servedPlmnPerCellList>
                                </CellResourceReportListItem>
                            </cellResourceReportList>
                        </oDU>
                    </performanceContainer>
                </PM-Containers-List>
                <PM-Containers-List>
                    <performanceContainer>
                        <oCU-CP>
                            <cu-CP-Resource-Status>
                                <numberOfActive-UEs>2</numberOfActive-UEs>
                            </cu-CP-Resource-Status>
                        </oCU-CP>
                    </performanceContainer>
                </PM-Containers-List>
                <PM-Containers-List>
                    <performanceContainer>
                        <oCU-UP>
                            <pf-ContainerList>
                                <PF-ContainerListItem>
                                    <interface-type><f1-u/></interface-type>
                                    <o-CU-UP-PM-Container>
                                        <plmnList>
                                            <PlmnID-List>
                                                <pLMN-Identity>00 F1 10</pLMN-Identity>
                                                <cu-UP-PM-EPC>
                                                    <perQCIReportList>
                                                        <PerQCIReportListItemFormat>
                                                            <qci>0</qci>
                                                            <pDCPBytesDL>0</pDCPBytesDL>
                                                            <pDCPBytesUL>0</pDCPBytesUL>
                                                        </PerQCIReportListItemFormat>
                                                        <PerQCIReportListItemFormat>
                                                            <qci>7</qci>
                                                            <pDCPBytesDL>13326628</pDCPBytesDL>
                                                            <pDCPBytesUL>107952</pDCPBytesUL>
                                                        </PerQCIReportListItemFormat>
                                                    </perQCIReportList>
                                                    <perUEReportList>
                                                        <PerUEReportListItemFormat>
                                                            <rnti>70</rnti>
                                                            <bytesDL>6663314</bytesDL>
                                                            <bytesUL>55016</bytesUL>
                                                        </PerUEReportListItemFormat>
                                                        <PerUEReportListItemFormat>
                                                            <rnti>71</rnti>
                                                            <bytesDL>6663314</bytesDL>
                                                            <bytesUL>52936</bytesUL>
                                                        </PerUEReportListItemFormat>
                                                    </perUEReportList>
                                                    <perSliceReportList>
                                                        <PerSliceReportListItemFormat>
                                                            <sliceName>fast</sliceName>
                                                            <bytesDL>13326628</bytesDL>
                                                            <bytesUL>107952</bytesUL>
                                                        </PerSliceReportListItemFormat>
                                                    </perSliceReportList>
                                                </cu-UP-PM-EPC>
                                            </PlmnID-List>
                                        </plmnList>
                                    </o-CU-UP-PM-Container>
                                </PF-ContainerListItem>
                            </pf-ContainerList>
                        </oCU-UP>
                    </performanceContainer>
                </PM-Containers-List>
            </pm-Containers>
        </indicationMessage-Format1>
    </indicationMessage>
</E2SM-KPM-IndicationMessage>
{"ts":1737231247813,"crit":"DEBUG","id":"nexran","mdc":{},"msg":"kpm indication report style 4 "}
{"ts":1737231247813,"crit":"DEBUG","id":"nexran","mdc":{},"msg":"nexran Indication handler"}
{"ts":1737231247813,"crit":"INFO","id":"nexran","mdc":{},"msg":"KpmIndication: KpmReport(period=5120 ms) available_dl_prbs=100 available_ul_prbs=100 ue[70]={dl_bytes=6663314,ul_bytes=55016,dl_prbs=71388,ul_prbs=1265,tx_pkts=140,tx_errors=0,tx_brate=9811240,rx_pkts=23,rx_errors=0,rx_brate=113304,dl_cqi=15,dl_ri=0,dl_pmi=0,ul_phr=30,ul_sinr=104.307,ul_mcs=22.3182,ul_samples=44,dl_mcs=27.8206,dl_samples=301,imsi=1010123456780,} ue[71]={dl_bytes=6663314,ul_bytes=52936,dl_prbs=70964,ul_prbs=1201,tx_pkts=136,tx_errors=1,tx_brate=9812664,rx_pkts=22,rx_errors=0,rx_brate=113248,dl_cqi=15,dl_ri=0,dl_pmi=0,ul_phr=30,ul_sinr=104.53,ul_mcs=22.1875,ul_samples=48,dl_mcs=27.8974,dl_samples=302,imsi=1010123456789,} slice[fast]={dl_bytes=13326628,ul_bytes=107952,dl_prbs=142352,ul_prbs=2466,tx_pkts=276,tx_errors=1,tx_brate=19623904,rx_pkts=45,rx_errors=0,rx_brate=226552,dl_cqi=15,dl_ri=0,dl_pmi=0,ul_phr=30,ul_sinr=0,ul_mcs=22.2528,ul_samples=92,dl_mcs=27.859,dl_samples=603,} "}
{"ts":1737231247827,"crit":"INFO","id":"nexran","mdc":{},"msg":"# of UE Reports: 9"}
{"ts":1737231247827,"crit":"INFO","id":"nexran","mdc":{},"msg":"# of Slice Reports: 9"}
{"ts":1737231247832,"crit":"INFO","id":"nexran","mdc":{},"msg":"slice 'fast' share unchanged: 1024"}
{"ts":1737231247838,"crit":"INFO","id":"nexran","mdc":{},"msg":"slice 'secure_slice' share unchanged: 1"}
1737231250963 1/RMR [INFO] sends: ts=1737231250 src=service-ricxapp-dc-rmr.ricxapp:4560 target=10.106.64.163:38000 open=1 succ=7 fail=0 (hard=0 soft=0)
1737231250963 1/RMR [INFO] sends: ts=1737231250 src=service-ricxapp-dc-rmr.ricxapp:4560 target=service-ricplt-e2term-rmr-alpha.ricplt:38000 open=0 succ=0 fail=0 (hard=0 soft=0)
1737231250963 1/RMR [INFO] sends: ts=1737231250 src=service-ricxapp-dc-rmr.ricxapp:4560 target=service-ricplt-submgr-rmr.ricplt:4560 open=1 succ=2 fail=0 (hard=0 soft=0)
1737231250963 1/RMR [INFO] sends: ts=1737231250 src=service-ricxapp-dc-rmr.ricxapp:4560 target=service-ricplt-e2mgr-rmr.ricplt:3801 open=0 succ=0 fail=0 (hard=0 soft=0)
1737231250963 1/RMR [INFO] sends: ts=1737231250 src=service-ricxapp-dc-rmr.ricxapp:4560 target=service-ricplt-a1mediator-rmr.ricplt:4562 open=0 succ=0 fail=0 (hard=0 soft=0)
{"ts":1737231252928,"crit":"DEBUG","id":"nexran","mdc":{},"msg":"RMR message (type 12050, source enB_macro_001_001_0019b0)"}
<E2AP-PDU>
    <initiatingMessage>
        <procedureCode>5</procedureCode>
        <criticality><reject/></criticality>
        <value>
            <RICindication>
                <protocolIEs>
                    <RICindication-IEs>
                        <id>29</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICrequestID>
                                <ricRequestorID>123</ricRequestorID>
                                <ricInstanceID>7</ricInstanceID>
                            </RICrequestID>
                        </value>
                    </RICindication-IEs>
                    <RICindication-IEs>
                        <id>5</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RANfunctionID>0</RANfunctionID>
                        </value>
                    </RICindication-IEs>
                    <RICindication-IEs>
                        <id>15</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICactionID>1</RICactionID>
                        </value>
                    </RICindication-IEs>
                    <RICindication-IEs>
                        <id>27</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICindicationSN>10</RICindicationSN>
                        </value>
                    </RICindication-IEs>
                    <RICindication-IEs>
                        <id>28</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICindicationType><report/></RICindicationType>
                        </value>
                    </RICindication-IEs>
                    <RICindication-IEs>
                        <id>26</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICindicationMessage>
                                01 04 00 00 02 40 00 00 60 00 F1 10 00 00 00 00 
                                10 00 64 00 64 02 00 F1 10 80 00 00 00 03 80 80 
                                87 00 01 00 00 46 20 01 16 F0 10 05 26 01 0F 01 
                                00 03 10 A2 B8 01 04 01 00 02 5D 40 03 80 00 0F 
                                00 00 03 80 01 0F 06 80 F0 00 68 79 13 00 04 80 
                                FF 00 2D 01 08 06 80 EE 00 6F 33 33 01 1E 06 00 
                                EB 30 0C C1 0C 00 00 47 20 01 17 60 10 04 8A 01 
                                0F 01 00 03 10 A2 B8 01 03 01 00 02 27 98 03 80 
                                00 0F 00 00 03 80 01 0F 05 80 F2 1A 20 45 00 06 
                                80 ED 00 B5 55 55 01 09 06 80 ED 00 DF 45 D1 01 
                                16 06 00 EB 30 0C C1 15 3C 00 00 03 66 61 73 74 
                                20 02 2E 50 10 09 B0 01 1E 01 00 03 21 45 70 01 
                                07 01 00 03 00 84 D8 03 80 00 0F 00 00 03 80 01 
                                0F 00 00 06 80 EE 00 5A 55 55 01 11 06 80 EF 00 
                                37 B5 87 01 34 4A 00 01 50 10 08 00 F1 10 80 01 
                                60 00 00 00 00 00 60 07 20 C9 45 F2 20 01 AB FC 
                                03 80 16 00 01 00 00 46 20 65 AC 92 10 DB 94 00 
                                00 47 20 63 99 60 10 D0 68 0F 00 00 03 66 61 73 
                                74 20 C9 45 F2 20 01 AB FC
                            </RICindicationMessage>
                        </value>
                    </RICindication-IEs>
                    <RICindication-IEs>
                        <id>25</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICindicationHeader>08 00 F1 10</RICindicationHeader>
                        </value>
                    </RICindication-IEs>
                </protocolIEs>
            </RICindication>
        </value>
    </initiatingMessage>
</E2AP-PDU>
<E2SM-KPM-IndicationHeader>
    <indicationHeader-Format1>
        <pLMN-Identity>00 F1 10</pLMN-Identity>
    </indicationHeader-Format1>
</E2SM-KPM-IndicationHeader>
<E2SM-KPM-IndicationMessage>
    <ric-Style-Type>4</ric-Style-Type>
    <indicationMessage>
        <indicationMessage-Format1>
            <pm-Containers>
                <PM-Containers-List>
                    <performanceContainer>
                        <oDU>
                            <cellResourceReportList>
                                <CellResourceReportListItem>
                                    <nRCGI>
                                        <pLMN-Identity>00 F1 10</pLMN-Identity>
                                        <nRCellIdentity>
                                            000000000000000000000000000000000001
                                        </nRCellIdentity>
                                    </nRCGI>
                                    <dl-TotalofAvailablePRBs>100</dl-TotalofAvailablePRBs>
                                    <ul-TotalofAvailablePRBs>100</ul-TotalofAvailablePRBs>
                                    <servedPlmnPerCellList>
                                        <ServedPlmnPerCellListItem>
                                            <pLMN-Identity>00 F1 10</pLMN-Identity>
                                            <du-PM-EPC>
                                                <perQCIReportList>
                                                    <PerQCIReportListItem>
                                                        <qci>0</qci>
                                                    </PerQCIReportListItem>
                                                </perQCIReportList>
                                                <perUEReportList>
                                                    <PerUEReportListItem>
                                                        <rnti>70</rnti>
                                                        <dl-PRBUsage>71408</dl-PRBUsage>
                                                        <ul-PRBUsage>1318</ul-PRBUsage>
                                                        <tx-pkts>15</tx-pkts>
                                                        <tx-errors>0</tx-errors>
{"ts":1737231252930,"crit":"INFO","id":"nexran","mdc":{},"msg":"decoded initiating RICindication (5) "}
                                                        <tx-brate>1090232</tx-brate>
                                                        <rx-pkts>4</rx-pkts>
                                                        <rx-errors>0</rx-errors>
                                                        <rx-brate>23872</rx-brate>
                                                        <dl-cqi>15.0</dl-cqi>
                                                        <dl-ri>0</dl-ri>
                                                        <dl-pmi>0</dl-pmi>
                                                        <ul-phr>30.0</ul-phr>
                                                        <ul-sinr>104.472946166992188</ul-sinr>
                                                        <ul-rssi>0</ul-rssi>
                                                        <ul-mcs>22.5</ul-mcs>
                                                        <ul-samples>8</ul-samples>
                                                        <dl-mcs>27.799999237060547</dl-mcs>
                                                        <dl-samples>30</dl-samples>
                                                        <imsi>1010123456780</imsi>
                                                    </PerUEReportListItem>
                                                    <PerUEReportListItem>
                                                        <rnti>71</rnti>
                                                        <dl-PRBUsage>71520</dl-PRBUsage>
                                                        <ul-PRBUsage>1162</ul-PRBUsage>
                                                        <tx-pkts>15</tx-pkts>
                                                        <tx-errors>0</tx-errors>
                                                        <tx-brate>1090232</tx-brate>
                                                        <rx-pkts>3</rx-pkts>
                                                        <rx-errors>0</rx-errors>
                                                        <rx-brate>10136</rx-brate>
                                                        <dl-cqi>15.0</dl-cqi>
                                                        <dl-ri>0</dl-ri>
                                                        <dl-pmi>0</dl-pmi>
                                                        <ul-phr>30.0</ul-phr>
                                                        <ul-sinr>104.50421142578125</ul-sinr>
                                                        <ul-rssi>0</ul-rssi>
                                                        <ul-mcs>22.666666030883789</ul-mcs>
                                                        <ul-samples>9</ul-samples>
                                                        <dl-mcs>27.909090042114258</dl-mcs>
                                                        <dl-samples>22</dl-samples>
                                                        <imsi>1010123456789</imsi>
                                                    </PerUEReportListItem>
                                                </perUEReportList>
                                                <perSliceReportList>
                                                    <PerSliceReportListItem>
                                                        <sliceName>fast</sliceName>
                                                        <dl-PRBUsage>142928</dl-PRBUsage>
                                                        <ul-PRBUsage>2480</ul-PRBUsage>
                                                        <tx-pkts>30</tx-pkts>
                                                        <tx-errors>0</tx-errors>
                                                        <tx-brate>2180464</tx-brate>
                                                        <rx-pkts>7</rx-pkts>
                                                        <rx-errors>0</rx-errors>
                                                        <rx-brate>34008</rx-brate>
                                                        <dl-cqi>15.0</dl-cqi>
                                                        <dl-ri>0</dl-ri>
                                                        <dl-pmi>0</dl-pmi>
                                                        <ul-phr>30.0</ul-phr>
                                                        <ul-sinr>0</ul-sinr>
                                                        <ul-rssi>0</ul-rssi>
                                                        <ul-mcs>22.583332061767578</ul-mcs>
                                                        <ul-samples>17</ul-samples>
                                                        <dl-mcs>27.854545593261719</dl-mcs>
                                                        <dl-samples>52</dl-samples>
                                                    </PerSliceReportListItem>
                                                </perSliceReportList>
                                            </du-PM-EPC>
                                        </ServedPlmnPerCellListItem>
                                    </servedPlmnPerCellList>
                                </CellResourceReportListItem>
                            </cellResourceReportList>
                        </oDU>
                    </performanceContainer>
                </PM-Containers-List>
                <PM-Containers-List>
                    <performanceContainer>
                        <oCU-CP>
                            <cu-CP-Resource-Status>
                                <numberOfActive-UEs>2</numberOfActive-UEs>
                            </cu-CP-Resource-Status>
                        </oCU-CP>
                    </performanceContainer>
                </PM-Containers-List>
                <PM-Containers-List>
                    <performanceContainer>
                        <oCU-UP>
                            <pf-ContainerList>
                                <PF-ContainerListItem>
                                    <interface-type><f1-u/></interface-type>
                                    <o-CU-UP-PM-Container>
                                        <plmnList>
                                            <PlmnID-List>
                                                <pLMN-Identity>00 F1 10</pLMN-Identity>
                                                <cu-UP-PM-EPC>
                                                    <perQCIReportList>
                                                        <PerQCIReportListItemFormat>
                                                            <qci>0</qci>
                                                            <pDCPBytesDL>0</pDCPBytesDL>
                                                            <pDCPBytesUL>0</pDCPBytesUL>
                                                        </PerQCIReportListItemFormat>
                                                        <PerQCIReportListItemFormat>
                                                            <qci>7</qci>
                                                            <pDCPBytesDL>13190642</pDCPBytesDL>
                                                            <pDCPBytesUL>109564</pDCPBytesUL>
                                                        </PerQCIReportListItemFormat>
                                                    </perQCIReportList>
                                                    <perUEReportList>
                                                        <PerUEReportListItemFormat>
                                                            <rnti>70</rnti>
                                                            <bytesDL>6663314</bytesDL>
                                                            <bytesUL>56212</bytesUL>
                                                        </PerUEReportListItemFormat>
                                                        <PerUEReportListItemFormat>
                                                            <rnti>71</rnti>
                                                            <bytesDL>6527328</bytesDL>
                                                            <bytesUL>53352</bytesUL>
                                                        </PerUEReportListItemFormat>
                                                    </perUEReportList>
                                                    <perSliceReportList>
                                                        <PerSliceReportListItemFormat>
                                                            <sliceName>fast</sliceName>
                                                            <bytesDL>13190642</bytesDL>
                                                            <bytesUL>109564</bytesUL>
                                                        </PerSliceReportListItemFormat>
                                                    </perSliceReportList>
                                                </cu-UP-PM-EPC>
                                            </PlmnID-List>
                                        </plmnList>
                                    </o-CU-UP-PM-Container>
                                </PF-ContainerListItem>
                            </pf-ContainerList>
                        </oCU-UP>
                    </performanceContainer>
                </PM-Containers-List>
            </pm-Containers>
        </indicationMessage-Format1>
    </indicationMessage>
</E2SM-KPM-IndicationMessage>
{"ts":1737231252933,"crit":"DEBUG","id":"nexran","mdc":{},"msg":"kpm indication report style 4 "}
{"ts":1737231252933,"crit":"DEBUG","id":"nexran","mdc":{},"msg":"nexran Indication handler"}
{"ts":1737231252934,"crit":"INFO","id":"nexran","mdc":{},"msg":"KpmIndication: KpmReport(period=5120 ms) available_dl_prbs=100 available_ul_prbs=100 ue[70]={dl_bytes=6663314,ul_bytes=56212,dl_prbs=71408,ul_prbs=1318,tx_pkts=15,tx_errors=0,tx_brate=1090232,rx_pkts=4,rx_errors=0,rx_brate=23872,dl_cqi=15,dl_ri=0,dl_pmi=0,ul_phr=30,ul_sinr=104.473,ul_mcs=22.5,ul_samples=8,dl_mcs=27.8,dl_samples=30,imsi=1010123456780,} ue[71]={dl_bytes=6527328,ul_bytes=53352,dl_prbs=71520,ul_prbs=1162,tx_pkts=15,tx_errors=0,tx_brate=1090232,rx_pkts=3,rx_errors=0,rx_brate=10136,dl_cqi=15,dl_ri=0,dl_pmi=0,ul_phr=30,ul_sinr=104.504,ul_mcs=22.6667,ul_samples=9,dl_mcs=27.9091,dl_samples=22,imsi=1010123456789,} slice[fast]={dl_bytes=13190642,ul_bytes=109564,dl_prbs=142928,ul_prbs=2480,tx_pkts=30,tx_errors=0,tx_brate=2180464,rx_pkts=7,rx_errors=0,rx_brate=34008,dl_cqi=15,dl_ri=0,dl_pmi=0,ul_phr=30,ul_sinr=0,ul_mcs=22.5833,ul_samples=17,dl_mcs=27.8545,dl_samples=52,} "}
{"ts":1737231252955,"crit":"INFO","id":"nexran","mdc":{},"msg":"# of UE Reports: 10"}
{"ts":1737231252955,"crit":"INFO","id":"nexran","mdc":{},"msg":"# of Slice Reports: 10"}
{"ts":1737231252960,"crit":"INFO","id":"nexran","mdc":{},"msg":"slice 'fast' share unchanged: 1024"}
{"ts":1737231252964,"crit":"INFO","id":"nexran","mdc":{},"msg":"slice 'secure_slice' share unchanged: 1"}
{"ts":1737231258048,"crit":"DEBUG","id":"nexran","mdc":{},"msg":"RMR message (type 12050, source enB_macro_001_001_0019b0)"}
<E2AP-PDU>
    <initiatingMessage>
        <procedureCode>5</procedureCode>
        <criticality><reject/></criticality>
        <value>
            <RICindication>
                <protocolIEs>
                    <RICindication-IEs>
                        <id>29</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICrequestID>
                                <ricRequestorID>123</ricRequestorID>
                                <ricInstanceID>7</ricInstanceID>
                            </RICrequestID>
                        </value>
                    </RICindication-IEs>
                    <RICindication-IEs>
                        <id>5</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RANfunctionID>0</RANfunctionID>
                        </value>
                    </RICindication-IEs>
                    <RICindication-IEs>
                        <id>15</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICactionID>1</RICactionID>
                        </value>
                    </RICindication-IEs>
                    <RICindication-IEs>
                        <id>27</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICindicationSN>11</RICindicationSN>
                        </value>
                    </RICindication-IEs>
                    <RICindication-IEs>
                        <id>28</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICindicationType><report/></RICindicationType>
                        </value>
                    </RICindication-IEs>
                    <RICindication-IEs>
                        <id>26</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICindicationMessage>
                                01 04 00 00 02 40 00 00 60 00 F1 10 00 00 00 00 
                                10 00 64 00 64 02 00 F1 10 80 00 00 00 03 80 80 
                                88 00 01 00 00 46 20 01 16 EC 10 04 FC 01 22 01 
                                00 03 23 98 C8 01 07 01 00 02 60 08 03 80 00 0F 
                                00 00 03 80 01 0F 06 80 EF 00 D0 F4 FB 00 06 80 
                                ED 00 B1 55 55 01 0C 06 80 EE 00 6F 52 B5 01 41 
                                06 00 EB 30 0C C1 0C 00 00 47 20 01 19 08 10 04 
                                D5 01 1E 01 00 03 21 47 70 01 07 01 00 02 6B 68 
                                03 80 00 0F 00 00 03 80 01 0F 06 80 EF 00 D1 08 
                                77 00 04 80 FF 00 2B 01 10 06 80 ED 00 DF 33 33 
                                01 3C 06 00 EB 30 0C C1 15 3C 00 00 03 66 61 73 
                                74 20 02 2F F4 10 09 D1 01 40 01 00 03 44 E0 38 
                                01 0E 01 00 03 00 CB 70 03 80 00 0F 00 00 03 80 
                                01 0F 00 00 06 80 EE 00 57 55 55 01 1C 06 80 EE 
                                00 6F 76 27 01 7D 4A 00 01 50 10 08 00 F1 10 80 
                                01 60 00 00 00 00 00 60 07 20 CB 59 24 20 01 A4 
                                E0 03 80 16 00 01 00 00 46 20 65 AC 92 10 D1 6C 
                                00 00 47 20 65 AC 92 10 D3 74 0F 00 00 03 66 61 
                                73 74 20 CB 59 24 20 01 A4 E0
                            </RICindicationMessage>
                        </value>
                    </RICindication-IEs>
                    <RICindication-IEs>
                        <id>25</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICindicationHeader>08 00 F1 10</RICindicationHeader>
                        </value>
                    </RICindication-IEs>
                </protocolIEs>
            </RICindication>
        </value>
    </initiatingMessage>
</E2AP-PDU>
{"ts":1737231258049,"crit":"INFO","id":"nexran","mdc":{},"msg":"decoded initiating RICindication (5) "}
<E2SM-KPM-IndicationHeader>
    <indicationHeader-Format1>
        <pLMN-Identity>00 F1 10</pLMN-Identity>
    </indicationHeader-Format1>
</E2SM-KPM-IndicationHeader>
<E2SM-KPM-IndicationMessage>
    <ric-Style-Type>4</ric-Style-Type>
    <indicationMessage>
        <indicationMessage-Format1>
            <pm-Containers>
                <PM-Containers-List>
                    <performanceContainer>
                        <oDU>
                            <cellResourceReportList>
                                <CellResourceReportListItem>
                                    <nRCGI>
                                        <pLMN-Identity>00 F1 10</pLMN-Identity>
                                        <nRCellIdentity>
                                            000000000000000000000000000000000001
                                        </nRCellIdentity>
                                    </nRCGI>
                                    <dl-TotalofAvailablePRBs>100</dl-TotalofAvailablePRBs>
                                    <ul-TotalofAvailablePRBs>100</ul-TotalofAvailablePRBs>
                                    <servedPlmnPerCellList>
                                        <ServedPlmnPerCellListItem>
                                            <pLMN-Identity>00 F1 10</pLMN-Identity>
                                            <du-PM-EPC>
                                                <perQCIReportList>
                                                    <PerQCIReportListItem>
                                                        <qci>0</qci>
                                                    </PerQCIReportListItem>
                                                </perQCIReportList>
                                                <perUEReportList>
                                                    <PerUEReportListItem>
                                                        <rnti>70</rnti>
                                                        <dl-PRBUsage>71404</dl-PRBUsage>
                                                        <ul-PRBUsage>1276</ul-PRBUsage>
                                                        <tx-pkts>34</tx-pkts>
                                                        <tx-errors>0</tx-errors>
                                                        <tx-brate>2332872</tx-brate>
                                                        <rx-pkts>7</rx-pkts>
                                                        <rx-errors>0</rx-errors>
                                                        <rx-brate>24584</rx-brate>
                                                        <dl-cqi>15.0</dl-cqi>
                                                        <dl-ri>0</dl-ri>
                                                        <dl-pmi>0</dl-pmi>
                                                        <ul-phr>30.0</ul-phr>
                                                        <ul-sinr>104.478477478027344</ul-sinr>
                                                        <ul-rssi>0</ul-rssi>
                                                        <ul-mcs>22.166666030883789</ul-mcs>
                                                        <ul-samples>12</ul-samples>
                                                        <dl-mcs>27.830768585205078</dl-mcs>
                                                        <dl-samples>65</dl-samples>
                                                        <imsi>1010123456780</imsi>
                                                    </PerUEReportListItem>
                                                    <PerUEReportListItem>
                                                        <rnti>71</rnti>
                                                        <dl-PRBUsage>71944</dl-PRBUsage>
                                                        <ul-PRBUsage>1237</ul-PRBUsage>
                                                        <tx-pkts>30</tx-pkts>
                                                        <tx-errors>0</tx-errors>
                                                        <tx-brate>2180976</tx-brate>
                                                        <rx-pkts>7</rx-pkts>
                                                        <rx-errors>0</rx-errors>
                                                        <rx-brate>27496</rx-brate>
                                                        <dl-cqi>15.0</dl-cqi>
                                                        <dl-ri>0</dl-ri>
                                                        <dl-pmi>0</dl-pmi>
                                                        <ul-phr>30.0</ul-phr>
                                                        <ul-sinr>104.516532897949219</ul-sinr>
                                                        <ul-rssi>0</ul-rssi>
                                                        <ul-mcs>21.5</ul-mcs>
                                                        <ul-samples>16</ul-samples>
                                                        <dl-mcs>27.899999618530273</dl-mcs>
                                                        <dl-samples>60</dl-samples>
                                                        <imsi>1010123456789</imsi>
                                                    </PerUEReportListItem>
                                                </perUEReportList>
                                                <perSliceReportList>
                                                    <PerSliceReportListItem>
                                                        <sliceName>fast</sliceName>
                                                        <dl-PRBUsage>143348</dl-PRBUsage>
                                                        <ul-PRBUsage>2513</ul-PRBUsage>
                                                        <tx-pkts>64</tx-pkts>
                                                        <tx-errors>0</tx-errors>
                                                        <tx-brate>4513848</tx-brate>
                                                        <rx-pkts>14</rx-pkts>
                                                        <rx-errors>0</rx-errors>
                                                        <rx-brate>52080</rx-brate>
                                                        <dl-cqi>15.0</dl-cqi>
                                                        <dl-ri>0</dl-ri>
                                                        <dl-pmi>0</dl-pmi>
                                                        <ul-phr>30.0</ul-phr>
                                                        <ul-sinr>0</ul-sinr>
                                                        <ul-rssi>0</ul-rssi>
                                                        <ul-mcs>21.833332061767578</ul-mcs>
                                                        <ul-samples>28</ul-samples>
                                                        <dl-mcs>27.865383148193359</dl-mcs>
                                                        <dl-samples>125</dl-samples>
                                                    </PerSliceReportListItem>
                                                </perSliceReportList>
                                            </du-PM-EPC>
                                        </ServedPlmnPerCellListItem>
                                    </servedPlmnPerCellList>
                                </CellResourceReportListItem>
                            </cellResourceReportList>
                        </oDU>
                    </performanceContainer>
                </PM-Containers-List>
                <PM-Containers-List>
                    <performanceContainer>
                        <oCU-CP>
                            <cu-CP-Resource-Status>
                                <numberOfActive-UEs>2</numberOfActive-UEs>
                            </cu-CP-Resource-Status>
                        </oCU-CP>
                    </performanceContainer>
                </PM-Containers-List>
                <PM-Containers-List>
                    <performanceContainer>
                        <oCU-UP>
                            <pf-ContainerList>
                                <PF-ContainerListItem>
                                    <interface-type><f1-u/></interface-type>
                                    <o-CU-UP-PM-Container>
                                        <plmnList>
                                            <PlmnID-List>
                                                <pLMN-Identity>00 F1 10</pLMN-Identity>
                                                <cu-UP-PM-EPC>
                                                    <perQCIReportList>
                                                        <PerQCIReportListItemFormat>
                                                            <qci>0</qci>
                                                            <pDCPBytesDL>0</pDCPBytesDL>
                                                            <pDCPBytesUL>0</pDCPBytesUL>
                                                        </PerQCIReportListItemFormat>
                                                        <PerQCIReportListItemFormat>
                                                            <qci>7</qci>
                                                            <pDCPBytesDL>13326628</pDCPBytesDL>
                                                            <pDCPBytesUL>107744</pDCPBytesUL>
                                                        </PerQCIReportListItemFormat>
                                                    </perQCIReportList>
                                                    <perUEReportList>
                                                        <PerUEReportListItemFormat>
                                                            <rnti>70</rnti>
                                                            <bytesDL>6663314</bytesDL>
                                                            <bytesUL>53612</bytesUL>
                                                        </PerUEReportListItemFormat>
                                                        <PerUEReportListItemFormat>
                                                            <rnti>71</rnti>
                                                            <bytesDL>6663314</bytesDL>
                                                            <bytesUL>54132</bytesUL>
                                                        </PerUEReportListItemFormat>
                                                    </perUEReportList>
                                                    <perSliceReportList>
                                                        <PerSliceReportListItemFormat>
                                                            <sliceName>fast</sliceName>
                                                            <bytesDL>13326628</bytesDL>
                                                            <bytesUL>107744</bytesUL>
                                                        </PerSliceReportListItemFormat>
                                                    </perSliceReportList>
                                                </cu-UP-PM-EPC>
                                            </PlmnID-List>
                                        </plmnList>
                                    </o-CU-UP-PM-Container>
                                </PF-ContainerListItem>
                            </pf-ContainerList>
                        </oCU-UP>
                    </performanceContainer>
                </PM-Containers-List>
            </pm-Containers>
        </indicationMessage-Format1>
    </indicationMessage>
</E2SM-KPM-IndicationMessage>
{"ts":1737231258053,"crit":"DEBUG","id":"nexran","mdc":{},"msg":"kpm indication report style 4 "}
{"ts":1737231258053,"crit":"DEBUG","id":"nexran","mdc":{},"msg":"nexran Indication handler"}
{"ts":1737231258054,"crit":"INFO","id":"nexran","mdc":{},"msg":"KpmIndication: KpmReport(period=5120 ms) available_dl_prbs=100 available_ul_prbs=100 ue[70]={dl_bytes=6663314,ul_bytes=53612,dl_prbs=71404,ul_prbs=1276,tx_pkts=34,tx_errors=0,tx_brate=2332872,rx_pkts=7,rx_errors=0,rx_brate=24584,dl_cqi=15,dl_ri=0,dl_pmi=0,ul_phr=30,ul_sinr=104.478,ul_mcs=22.1667,ul_samples=12,dl_mcs=27.8308,dl_samples=65,imsi=1010123456780,} ue[71]={dl_bytes=6663314,ul_bytes=54132,dl_prbs=71944,ul_prbs=1237,tx_pkts=30,tx_errors=0,tx_brate=2180976,rx_pkts=7,rx_errors=0,rx_brate=27496,dl_cqi=15,dl_ri=0,dl_pmi=0,ul_phr=30,ul_sinr=104.517,ul_mcs=21.5,ul_samples=16,dl_mcs=27.9,dl_samples=60,imsi=1010123456789,} slice[fast]={dl_bytes=13326628,ul_bytes=107744,dl_prbs=143348,ul_prbs=2513,tx_pkts=64,tx_errors=0,tx_brate=4513848,rx_pkts=14,rx_errors=0,rx_brate=52080,dl_cqi=15,dl_ri=0,dl_pmi=0,ul_phr=30,ul_sinr=0,ul_mcs=21.8333,ul_samples=28,dl_mcs=27.8654,dl_samples=125,} "}
{"ts":1737231258079,"crit":"INFO","id":"nexran","mdc":{},"msg":"# of UE Reports: 11"}
{"ts":1737231258079,"crit":"INFO","id":"nexran","mdc":{},"msg":"# of Slice Reports: 11"}
{"ts":1737231258085,"crit":"INFO","id":"nexran","mdc":{},"msg":"slice 'fast' share unchanged: 1024"}
{"ts":1737231258089,"crit":"INFO","id":"nexran","mdc":{},"msg":"slice 'secure_slice' share unchanged: 1"}
{"ts":1737231263170,"crit":"DEBUG","id":"nexran","mdc":{},"msg":"RMR message (type 12050, source enB_macro_001_001_0019b0)"}
<E2AP-PDU>
    <initiatingMessage>
        <procedureCode>5</procedureCode>
        <criticality><reject/></criticality>
        <value>
            <RICindication>
                <protocolIEs>
                    <RICindication-IEs>
                        <id>29</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICrequestID>
                                <ricRequestorID>123</ricRequestorID>
                                <ricInstanceID>7</ricInstanceID>
                            </RICrequestID>
                        </value>
                    </RICindication-IEs>
                    <RICindication-IEs>
                        <id>5</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RANfunctionID>0</RANfunctionID>
                        </value>
                    </RICindication-IEs>
                    <RICindication-IEs>
                        <id>15</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICactionID>1</RICactionID>
                        </value>
                    </RICindication-IEs>
                    <RICindication-IEs>
                        <id>27</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICindicationSN>12</RICindicationSN>
                        </value>
                    </RICindication-IEs>
                    <RICindication-IEs>
                        <id>28</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICindicationType><report/></RICindicationType>
                        </value>
                    </RICindication-IEs>
                    <RICindication-IEs>
                        <id>26</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICindicationMessage>
                                01 04 00 00 02 40 00 00 60 00 F1 10 00 00 00 00 
                                10 00 64 00 64 02 00 F1 10 80 00 00 00 03 80 80 
                                8B 00 01 00 00 46 20 01 14 50 10 04 C4 01 2F 01 
                                00 03 33 0C 68 01 0B 01 00 03 00 A6 C8 03 80 00 
                                0F 00 00 03 80 01 0F 06 80 F1 00 34 30 D1 00 06 
                                80 ED 00 B0 5D 17 01 16 06 80 ED 00 DE FA FB 01 
                                66 06 00 EB 30 0C C1 0C 00 00 47 20 01 18 30 10 
                                04 CC 01 31 01 00 03 36 81 E8 01 08 01 00 02 7B 
                                C0 03 80 00 0F 00 00 03 80 01 0F 06 80 EF 00 D1 
                                06 91 00 06 80 EE 00 59 2D 2D 01 11 06 80 EE 00 
                                6F 8F 79 01 5B 06 00 EB 30 0C C1 15 3C 00 00 03 
                                66 61 73 74 20 02 2C 80 10 09 90 01 60 01 00 03 
                                69 8E 50 01 13 01 00 03 01 22 88 03 80 00 0F 00 
                                00 03 80 01 0F 00 00 05 80 F0 16 2B 77 01 27 06 
                                80 EE 00 6F 86 7B 02 00 C1 4A 00 01 50 10 08 00 
                                F1 10 80 01 60 00 00 00 00 00 60 07 20 CB 59 24 
                                20 01 8E 88 03 80 16 00 01 00 00 46 20 65 AC 92 
                                10 CF 98 00 00 47 20 65 AC 92 10 BE F0 0F 00 00 
                                03 66 61 73 74 20 CB 59 24 20 01 8E 88
                            </RICindicationMessage>
                        </value>
                    </RICindication-IEs>
                    <RICindication-IEs>
                        <id>25</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICindicationHeader>08 00 F1 10</RICindicationHeader>
                        </value>
                    </RICindication-IEs>
                </protocolIEs>
            </RICindication>
        </value>
    </initiatingMessage>
</E2AP-PDU>
{"ts":1737231263171,"crit":"INFO","id":"nexran","mdc":{},"msg":"decoded initiating RICindication (5) "}
<E2SM-KPM-IndicationHeader>
    <indicationHeader-Format1>
        <pLMN-Identity>00 F1 10</pLMN-Identity>
    </indicationHeader-Format1>
</E2SM-KPM-IndicationHeader>
<E2SM-KPM-IndicationMessage>
    <ric-Style-Type>4</ric-Style-Type>
    <indicationMessage>
        <indicationMessage-Format1>
            <pm-Containers>
                <PM-Containers-List>
                    <performanceContainer>
                        <oDU>
                            <cellResourceReportList>
                                <CellResourceReportListItem>
                                    <nRCGI>
                                        <pLMN-Identity>00 F1 10</pLMN-Identity>
                                        <nRCellIdentity>
                                            000000000000000000000000000000000001
                                        </nRCellIdentity>
                                    </nRCGI>
                                    <dl-TotalofAvailablePRBs>100</dl-TotalofAvailablePRBs>
                                    <ul-TotalofAvailablePRBs>100</ul-TotalofAvailablePRBs>
                                    <servedPlmnPerCellList>
                                        <ServedPlmnPerCellListItem>
                                            <pLMN-Identity>00 F1 10</pLMN-Identity>
                                            <du-PM-EPC>
                                                <perQCIReportList>
                                                    <PerQCIReportListItem>
                                                        <qci>0</qci>
                                                    </PerQCIReportListItem>
                                                </perQCIReportList>
                                                <perUEReportList>
                                                    <PerUEReportListItem>
                                                        <rnti>70</rnti>
                                                        <dl-PRBUsage>70736</dl-PRBUsage>
                                                        <ul-PRBUsage>1220</ul-PRBUsage>
                                                        <tx-pkts>47</tx-pkts>
                                                        <tx-errors>0</tx-errors>
                                                        <tx-brate>3345512</tx-brate>
                                                        <rx-pkts>11</rx-pkts>
                                                        <rx-errors>0</rx-errors>
                                                        <rx-brate>42696</rx-brate>
                                                        <dl-cqi>15.0</dl-cqi>
                                                        <dl-ri>0</dl-ri>
                                                        <dl-pmi>0</dl-pmi>
                                                        <ul-phr>30.0</ul-phr>
                                                        <ul-sinr>104.381378173828125</ul-sinr>
                                                        <ul-rssi>0</ul-rssi>
                                                        <ul-mcs>22.045454025268555</ul-mcs>
                                                        <ul-samples>22</ul-samples>
                                                        <dl-mcs>27.872549057006836</dl-mcs>
                                                        <dl-samples>102</dl-samples>
                                                        <imsi>1010123456780</imsi>
                                                    </PerUEReportListItem>
                                                    <PerUEReportListItem>
                                                        <rnti>71</rnti>
                                                        <dl-PRBUsage>71728</dl-PRBUsage>
                                                        <ul-PRBUsage>1228</ul-PRBUsage>
                                                        <tx-pkts>49</tx-pkts>
                                                        <tx-errors>0</tx-errors>
                                                        <tx-brate>3572200</tx-brate>
                                                        <rx-pkts>8</rx-pkts>
                                                        <rx-errors>0</rx-errors>
                                                        <rx-brate>31680</rx-brate>
                                                        <dl-cqi>15.0</dl-cqi>
                                                        <dl-ri>0</dl-ri>
                                                        <dl-pmi>0</dl-pmi>
                                                        <ul-phr>30.0</ul-phr>
                                                        <ul-sinr>104.512825012207031</ul-sinr>
                                                        <ul-rssi>0</ul-rssi>
                                                        <ul-mcs>22.294116973876953</ul-mcs>
                                                        <ul-samples>17</ul-samples>
                                                        <dl-mcs>27.890110015869141</dl-mcs>
                                                        <dl-samples>91</dl-samples>
                                                        <imsi>1010123456789</imsi>
{"ts":1737231263175,"crit":"DEBUG","id":"nexran","mdc":{},"msg":"kpm indication report style 4 "}
{"ts":1737231263175,"crit":"DEBUG","id":"nexran","mdc":{},"msg":"nexran Indication handler"}
                                                    </PerUEReportListItem>
                                                </perUEReportList>
                                                <perSliceReportList>
                                                    <PerSliceReportListItem>
                                                        <sliceName>fast</sliceName>
                                                        <dl-PRBUsage>142464</dl-PRBUsage>
                                                        <ul-PRBUsage>2448</ul-PRBUsage>
                                                        <tx-pkts>96</tx-pkts>
                                                        <tx-errors>0</tx-errors>
                                                        <tx-brate>6917712</tx-brate>
                                                        <rx-pkts>19</rx-pkts>
                                                        <rx-errors>0</rx-errors>
                                                        <rx-brate>74376</rx-brate>
                                                        <dl-cqi>15.0</dl-cqi>
                                                        <dl-ri>0</dl-ri>
                                                        <dl-pmi>0</dl-pmi>
                                                        <ul-phr>30.0</ul-phr>
                                                        <ul-sinr>0</ul-sinr>
                                                        <ul-rssi>0</ul-rssi>
                                                        <ul-mcs>22.169784545898438</ul-mcs>
                                                        <ul-samples>39</ul-samples>
                                                        <dl-mcs>27.881328582763672</dl-mcs>
                                                        <dl-samples>193</dl-samples>
                                                    </PerSliceReportListItem>
                                                </perSliceReportList>
                                            </du-PM-EPC>
                                        </ServedPlmnPerCellListItem>
                                    </servedPlmnPerCellList>
                                </CellResourceReportListItem>
                            </cellResourceReportList>
                        </oDU>
                    </performanceContainer>
                </PM-Containers-List>
                <PM-Containers-List>
                    <performanceContainer>
                        <oCU-CP>
                            <cu-CP-Resource-Status>
                                <numberOfActive-UEs>2</numberOfActive-UEs>
                            </cu-CP-Resource-Status>
                        </oCU-CP>
                    </performanceContainer>
                </PM-Containers-List>
                <PM-Containers-List>
                    <performanceContainer>
                        <oCU-UP>
                            <pf-ContainerList>
                                <PF-ContainerListItem>
                                    <interface-type><f1-u/></interface-type>
                                    <o-CU-UP-PM-Container>
                                        <plmnList>
                                            <PlmnID-List>
                                                <pLMN-Identity>00 F1 10</pLMN-Identity>
                                                <cu-UP-PM-EPC>
                                                    <perQCIReportList>
{"ts":1737231263175,"crit":"INFO","id":"nexran","mdc":{},"msg":"KpmIndication: KpmReport(period=5120 ms) available_dl_prbs=100 available_ul_prbs=100 ue[70]={dl_bytes=6663314,ul_bytes=53144,dl_prbs=70736,ul_prbs=1220,tx_pkts=47,tx_errors=0,tx_brate=3345512,rx_pkts=11,rx_errors=0,rx_brate=42696,dl_cqi=15,dl_ri=0,dl_pmi=0,ul_phr=30,ul_sinr=104.381,ul_mcs=22.0455,ul_samples=22,dl_mcs=27.8725,dl_samples=102,imsi=1010123456780,} ue[71]={dl_bytes=6663314,ul_bytes=48880,dl_prbs=71728,ul_prbs=1228,tx_pkts=49,tx_errors=0,tx_brate=3572200,rx_pkts=8,rx_errors=0,rx_brate=31680,dl_cqi=15,dl_ri=0,dl_pmi=0,ul_phr=30,ul_sinr=104.513,ul_mcs=22.2941,ul_samples=17,dl_mcs=27.8901,dl_samples=91,imsi=1010123456789,} slice[fast]={dl_bytes=13326628,ul_bytes=102024,dl_prbs=142464,ul_prbs=2448,tx_pkts=96,tx_errors=0,tx_brate=6917712,rx_pkts=19,rx_errors=0,rx_brate=74376,dl_cqi=15,dl_ri=0,dl_pmi=0,ul_phr=30,ul_sinr=0,ul_mcs=22.1698,ul_samples=39,dl_mcs=27.8813,dl_samples=193,} "}
                                                        <PerQCIReportListItemFormat>
                                                            <qci>0</qci>
                                                            <pDCPBytesDL>0</pDCPBytesDL>
                                                            <pDCPBytesUL>0</pDCPBytesUL>
                                                        </PerQCIReportListItemFormat>
                                                        <PerQCIReportListItemFormat>
                                                            <qci>7</qci>
                                                            <pDCPBytesDL>13326628</pDCPBytesDL>
                                                            <pDCPBytesUL>102024</pDCPBytesUL>
                                                        </PerQCIReportListItemFormat>
                                                    </perQCIReportList>
                                                    <perUEReportList>
                                                        <PerUEReportListItemFormat>
                                                            <rnti>70</rnti>
                                                            <bytesDL>6663314</bytesDL>
                                                            <bytesUL>53144</bytesUL>
                                                        </PerUEReportListItemFormat>
                                                        <PerUEReportListItemFormat>
                                                            <rnti>71</rnti>
                                                            <bytesDL>6663314</bytesDL>
                                                            <bytesUL>48880</bytesUL>
                                                        </PerUEReportListItemFormat>
                                                    </perUEReportList>
                                                    <perSliceReportList>
                                                        <PerSliceReportListItemFormat>
                                                            <sliceName>fast</sliceName>
                                                            <bytesDL>13326628</bytesDL>
                                                            <bytesUL>102024</bytesUL>
                                                        </PerSliceReportListItemFormat>
                                                    </perSliceReportList>
                                                </cu-UP-PM-EPC>
                                            </PlmnID-List>
                                        </plmnList>
                                    </o-CU-UP-PM-Container>
                                </PF-ContainerListItem>
                            </pf-ContainerList>
                        </oCU-UP>
                    </performanceContainer>
                </PM-Containers-List>
            </pm-Containers>
        </indicationMessage-Format1>
    </indicationMessage>
</E2SM-KPM-IndicationMessage>
{"ts":1737231263193,"crit":"INFO","id":"nexran","mdc":{},"msg":"# of UE Reports: 12"}
{"ts":1737231263193,"crit":"INFO","id":"nexran","mdc":{},"msg":"# of Slice Reports: 12"}
{"ts":1737231263198,"crit":"INFO","id":"nexran","mdc":{},"msg":"slice 'fast' share unchanged: 1024"}
{"ts":1737231263203,"crit":"INFO","id":"nexran","mdc":{},"msg":"slice 'secure_slice' share unchanged: 1"}
{"ts":1737231268289,"crit":"DEBUG","id":"nexran","mdc":{},"msg":"RMR message (type 12050, source enB_macro_001_001_0019b0)"}
<E2AP-PDU>
    <initiatingMessage>
        <procedureCode>5</procedureCode>
        <criticality><reject/></criticality>
        <value>
            <RICindication>
                <protocolIEs>
                    <RICindication-IEs>
                        <id>29</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICrequestID>
                                <ricRequestorID>123</ricRequestorID>
                                <ricInstanceID>7</ricInstanceID>
                            </RICrequestID>
                        </value>
                    </RICindication-IEs>
                    <RICindication-IEs>
                        <id>5</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RANfunctionID>0</RANfunctionID>
                        </value>
                    </RICindication-IEs>
                    <RICindication-IEs>
                        <id>15</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICactionID>1</RICactionID>
                        </value>
                    </RICindication-IEs>
                    <RICindication-IEs>
                        <id>27</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICindicationSN>13</RICindicationSN>
                        </value>
                    </RICindication-IEs>
                    <RICindication-IEs>
                        <id>28</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICindicationType><report/></RICindicationType>
                        </value>
                    </RICindication-IEs>
                    <RICindication-IEs>
                        <id>26</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICindicationMessage>
                                01 04 00 00 02 40 00 00 60 00 F1 10 00 00 00 00 
                                10 00 64 00 64 02 00 F1 10 80 00 00 00 03 80 80 
                                8D 00 01 00 00 46 20 01 14 FC 10 04 94 01 40 01 
                                00 03 42 89 30 01 0B 01 00 03 00 DE 28 03 80 00 
                                0F 00 00 03 80 01 0F 06 80 EF 00 D0 E7 31 00 06 
                                80 ED 00 B0 AA AB 01 18 05 80 F0 1B AF 0F 02 00 
                                88 06 00 EB 30 0C C1 0C 00 00 47 20 01 1A 88 10 
                                04 8A 01 47 01 00 03 4F 47 30 01 0B 01 00 03 00 
                                A3 D8 03 80 00 0F 00 00 03 80 01 0F 06 80 EF 00 
                                D1 06 75 00 06 80 ED 00 B1 AA AB 01 18 06 80 ED 
                                00 DE 99 F5 02 00 8F 06 00 EB 30 0C C1 15 3F 00 
                                00 03 66 61 73 74 20 02 2F 84 10 09 1E 02 00 87 
                                01 00 04 00 91 D0 60 01 16 01 00 03 01 82 00 03 
                                80 00 0F 00 00 03 80 01 0F 00 00 06 80 ED 00 B1 
                                2A AB 01 30 06 80 EE 00 6F 04 9B 02 01 17 4A 00 
                                01 50 10 08 00 F1 10 80 01 60 00 00 00 00 00 60 
                                07 20 CB 59 24 20 01 93 9C 03 80 16 00 01 00 00 
                                46 20 65 AC 92 10 C8 14 00 00 47 20 65 AC 92 10 
                                CB 88 0F 00 00 03 66 61 73 74 20 CB 59 24 20 01 
                                93 9C
                            </RICindicationMessage>
                        </value>
                    </RICindication-IEs>
                    <RICindication-IEs>
                        <id>25</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICindicationHeader>08 00 F1 10</RICindicationHeader>
                        </value>
                    </RICindication-IEs>
                </protocolIEs>
            </RICindication>
        </value>
    </initiatingMessage>
</E2AP-PDU>
<E2SM-KPM-IndicationHeader>
    <indicationHeader-Format1>
        <pLMN-Identity>00 F1 10</pLMN-Identity>
{"ts":1737231268290,"crit":"INFO","id":"nexran","mdc":{},"msg":"decoded initiating RICindication (5) "}
    </indicationHeader-Format1>
</E2SM-KPM-IndicationHeader>
<E2SM-KPM-IndicationMessage>
    <ric-Style-Type>4</ric-Style-Type>
    <indicationMessage>
        <indicationMessage-Format1>
            <pm-Containers>
                <PM-Containers-List>
                    <performanceContainer>
                        <oDU>
                            <cellResourceReportList>
                                <CellResourceReportListItem>
                                    <nRCGI>
                                        <pLMN-Identity>00 F1 10</pLMN-Identity>
                                        <nRCellIdentity>
                                            000000000000000000000000000000000001
                                        </nRCellIdentity>
                                    </nRCGI>
                                    <dl-TotalofAvailablePRBs>100</dl-TotalofAvailablePRBs>
                                    <ul-TotalofAvailablePRBs>100</ul-TotalofAvailablePRBs>
                                    <servedPlmnPerCellList>
                                        <ServedPlmnPerCellListItem>
                                            <pLMN-Identity>00 F1 10</pLMN-Identity>
                                            <du-PM-EPC>
                                                <perQCIReportList>
                                                    <PerQCIReportListItem>
                                                        <qci>0</qci>
                                                    </PerQCIReportListItem>
                                                </perQCIReportList>
                                                <perUEReportList>
                                                    <PerUEReportListItem>
                                                        <rnti>70</rnti>
                                                        <dl-PRBUsage>70908</dl-PRBUsage>
                                                        <ul-PRBUsage>1172</ul-PRBUsage>
                                                        <tx-pkts>64</tx-pkts>
                                                        <tx-errors>0</tx-errors>
                                                        <tx-brate>4360496</tx-brate>
                                                        <rx-pkts>11</rx-pkts>
                                                        <rx-errors>0</rx-errors>
                                                        <rx-brate>56872</rx-brate>
                                                        <dl-cqi>15.0</dl-cqi>
                                                        <dl-ri>0</dl-ri>
                                                        <dl-pmi>0</dl-pmi>
                                                        <ul-phr>30.0</ul-phr>
                                                        <ul-sinr>104.451545715332031</ul-sinr>
                                                        <ul-rssi>0</ul-rssi>
                                                        <ul-mcs>22.083333969116211</ul-mcs>
                                                        <ul-samples>24</ul-samples>
                                                        <dl-mcs>27.683822631835938</dl-mcs>
                                                        <dl-samples>136</dl-samples>
                                                        <imsi>1010123456780</imsi>
                                                    </PerUEReportListItem>
                                                    <PerUEReportListItem>
                                                        <rnti>71</rnti>
                                                        <dl-PRBUsage>72328</dl-PRBUsage>
                                                        <ul-PRBUsage>1162</ul-PRBUsage>
                                                        <tx-pkts>71</tx-pkts>
                                                        <tx-errors>0</tx-errors>
                                                        <tx-brate>5195568</tx-brate>
                                                        <rx-pkts>11</rx-pkts>
                                                        <rx-errors>0</rx-errors>
                                                        <rx-brate>41944</rx-brate>
                                                        <dl-cqi>15.0</dl-cqi>
                                                        <dl-ri>0</dl-ri>
                                                        <dl-pmi>0</dl-pmi>
                                                        <ul-phr>30.0</ul-phr>
                                                        <ul-sinr>104.512611389160156</ul-sinr>
                                                        <ul-rssi>0</ul-rssi>
                                                        <ul-mcs>22.208333969116211</ul-mcs>
                                                        <ul-samples>24</ul-samples>
                                                        <dl-mcs>27.825174331665039</dl-mcs>
                                                        <dl-samples>143</dl-samples>
                                                        <imsi>1010123456789</imsi>
                                                    </PerUEReportListItem>
                                                </perUEReportList>
                                                <perSliceReportList>
                                                    <PerSliceReportListItem>
                                                        <sliceName>fast</sliceName>
                                                        <dl-PRBUsage>143236</dl-PRBUsage>
                                                        <ul-PRBUsage>2334</ul-PRBUsage>
                                                        <tx-pkts>135</tx-pkts>
                                                        <tx-errors>0</tx-errors>
                                                        <tx-brate>9556064</tx-brate>
                                                        <rx-pkts>22</rx-pkts>
                                                        <rx-errors>0</rx-errors>
                                                        <rx-brate>98816</rx-brate>
                                                        <dl-cqi>15.0</dl-cqi>
                                                        <dl-ri>0</dl-ri>
                                                        <dl-pmi>0</dl-pmi>
                                                        <ul-phr>30.0</ul-phr>
                                                        <ul-sinr>0</ul-sinr>
                                                        <ul-rssi>0</ul-rssi>
                                                        <ul-mcs>22.145833969116211</ul-mcs>
                                                        <ul-samples>48</ul-samples>
                                                        <dl-mcs>27.754497528076172</dl-mcs>
                                                        <dl-samples>279</dl-samples>
                                                    </PerSliceReportListItem>
                                                </perSliceReportList>
                                            </du-PM-EPC>
                                        </ServedPlmnPerCellListItem>
                                    </servedPlmnPerCellList>
                                </CellResourceReportListItem>
                            </cellResourceReportList>
                        </oDU>
                    </performanceContainer>
                </PM-Containers-List>
                <PM-Containers-List>
                    <performanceContainer>
                        <oCU-CP>
                            <cu-CP-Resource-Status>
                                <numberOfActive-UEs>2</numberOfActive-UEs>
                            </cu-CP-Resource-Status>
                        </oCU-CP>
                    </performanceContainer>
                </PM-Containers-List>
                <PM-Containers-List>
                    <performanceContainer>
                        <oCU-UP>
                            <pf-ContainerList>
                                <PF-ContainerListItem>
                                    <interface-type><f1-u/></interface-type>
                                    <o-CU-UP-PM-Container>
                                        <plmnList>
                                            <PlmnID-List>
                                                <pLMN-Identity>00 F1 10</pLMN-Identity>
                                                <cu-UP-PM-EPC>
                                                    <perQCIReportList>
                                                        <PerQCIReportListItemFormat>
                                                            <qci>0</qci>
                                                            <pDCPBytesDL>0</pDCPBytesDL>
                                                            <pDCPBytesUL>0</pDCPBytesUL>
                                                        </PerQCIReportListItemFormat>
                                                        <PerQCIReportListItemFormat>
                                                            <qci>7</qci>
                                                            <pDCPBytesDL>13326628</pDCPBytesDL>
                                                            <pDCPBytesUL>103324</pDCPBytesUL>
                                                        </PerQCIReportListItemFormat>
                                                    </perQCIReportList>
                                                    <perUEReportList>
                                                        <PerUEReportListItemFormat>
                                                            <rnti>70</rnti>
                                                            <bytesDL>6663314</bytesDL>
                                                            <bytesUL>51220</bytesUL>
                                                        </PerUEReportListItemFormat>
                                                        <PerUEReportListItemFormat>
                                                            <rnti>71</rnti>
                                                            <bytesDL>6663314</bytesDL>
                                                            <bytesUL>52104</bytesUL>
                                                        </PerUEReportListItemFormat>
                                                    </perUEReportList>
                                                    <perSliceReportList>
                                                        <PerSliceReportListItemFormat>
                                                            <sliceName>fast</sliceName>
                                                            <bytesDL>13326628</bytesDL>
                                                            <bytesUL>103324</bytesUL>
                                                        </PerSliceReportListItemFormat>
                                                    </perSliceReportList>
                                                </cu-UP-PM-EPC>
                                            </PlmnID-List>
                                        </plmnList>
                                    </o-CU-UP-PM-Container>
                                </PF-ContainerListItem>
                            </pf-ContainerList>
                        </oCU-UP>
                    </performanceContainer>
                </PM-Containers-List>
            </pm-Containers>
        </indicationMessage-Format1>
    </indicationMessage>
</E2SM-KPM-IndicationMessage>
{"ts":1737231268294,"crit":"DEBUG","id":"nexran","mdc":{},"msg":"kpm indication report style 4 "}
{"ts":1737231268294,"crit":"DEBUG","id":"nexran","mdc":{},"msg":"nexran Indication handler"}
{"ts":1737231268295,"crit":"INFO","id":"nexran","mdc":{},"msg":"KpmIndication: KpmReport(period=5120 ms) available_dl_prbs=100 available_ul_prbs=100 ue[70]={dl_bytes=6663314,ul_bytes=51220,dl_prbs=70908,ul_prbs=1172,tx_pkts=64,tx_errors=0,tx_brate=4360496,rx_pkts=11,rx_errors=0,rx_brate=56872,dl_cqi=15,dl_ri=0,dl_pmi=0,ul_phr=30,ul_sinr=104.452,ul_mcs=22.0833,ul_samples=24,dl_mcs=27.6838,dl_samples=136,imsi=1010123456780,} ue[71]={dl_bytes=6663314,ul_bytes=52104,dl_prbs=72328,ul_prbs=1162,tx_pkts=71,tx_errors=0,tx_brate=5195568,rx_pkts=11,rx_errors=0,rx_brate=41944,dl_cqi=15,dl_ri=0,dl_pmi=0,ul_phr=30,ul_sinr=104.513,ul_mcs=22.2083,ul_samples=24,dl_mcs=27.8252,dl_samples=143,imsi=1010123456789,} slice[fast]={dl_bytes=13326628,ul_bytes=103324,dl_prbs=143236,ul_prbs=2334,tx_pkts=135,tx_errors=0,tx_brate=9556064,rx_pkts=22,rx_errors=0,rx_brate=98816,dl_cqi=15,dl_ri=0,dl_pmi=0,ul_phr=30,ul_sinr=0,ul_mcs=22.1458,ul_samples=48,dl_mcs=27.7545,dl_samples=279,} "}
{"ts":1737231268333,"crit":"INFO","id":"nexran","mdc":{},"msg":"# of UE Reports: 13"}
{"ts":1737231268333,"crit":"INFO","id":"nexran","mdc":{},"msg":"# of Slice Reports: 13"}
{"ts":1737231268338,"crit":"INFO","id":"nexran","mdc":{},"msg":"slice 'fast' share unchanged: 1024"}
{"ts":1737231268343,"crit":"INFO","id":"nexran","mdc":{},"msg":"slice 'secure_slice' share unchanged: 1"}
{"ts":1737231273411,"crit":"DEBUG","id":"nexran","mdc":{},"msg":"RMR message (type 12050, source enB_macro_001_001_0019b0)"}
<E2AP-PDU>
    <initiatingMessage>
        <procedureCode>5</procedureCode>
        <criticality><reject/></criticality>
        <value>
            <RICindication>
                <protocolIEs>
                    <RICindication-IEs>
                        <id>29</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICrequestID>
                                <ricRequestorID>123</ricRequestorID>
                                <ricInstanceID>7</ricInstanceID>
                            </RICrequestID>
                        </value>
                    </RICindication-IEs>
                    <RICindication-IEs>
                        <id>5</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RANfunctionID>0</RANfunctionID>
                        </value>
                    </RICindication-IEs>
                    <RICindication-IEs>
                        <id>15</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICactionID>1</RICactionID>
                        </value>
                    </RICindication-IEs>
                    <RICindication-IEs>
                        <id>27</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICindicationSN>14</RICindicationSN>
                        </value>
                    </RICindication-IEs>
                    <RICindication-IEs>
                        <id>28</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICindicationType><report/></RICindicationType>
                        </value>
                    </RICindication-IEs>
                    <RICindication-IEs>
                        <id>26</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICindicationMessage>
                                01 04 00 00 02 40 00 00 60 00 F1 10 00 00 00 00 
                                10 00 64 00 64 02 00 F1 10 80 00 00 00 03 80 80 
                                8C 00 01 00 00 46 20 01 15 3C 10 04 9C 01 55 01 
                                00 03 59 18 88 01 0F 01 00 03 00 D7 58 03 80 00 
                                0F 00 00 03 80 01 0F 06 80 F0 00 68 6E 57 00 06 
                                80 EE 00 54 EE EF 01 1E 04 80 FB 03 79 02 00 A0 
                                06 00 EB 30 0C C1 0C 00 00 47 20 01 19 18 10 04 
                                76 01 51 01 00 03 5A 3A E0 01 0E 01 00 03 00 D4 
                                D0 03 80 00 0F 00 00 03 80 01 0F 06 80 EF 00 D0 
                                FC BF 00 06 80 EE 00 59 6D B7 01 1C 06 80 EE 00 
                                6F 84 39 02 00 B6 06 00 EB 30 0C C1 15 3F 00 00 
                                03 66 61 73 74 20 02 2E 54 10 09 12 02 00 A6 01 
                                00 04 00 B3 53 68 01 1D 01 00 03 01 AC 28 03 80 
                                00 0F 00 00 03 80 01 0F 00 00 06 80 EE 00 57 2E 
                                53 01 3A 06 80 ED 00 DE A4 39 02 01 56 4A 00 01 
                                50 10 08 00 F1 10 80 01 60 00 00 00 00 00 60 07 
                                20 C9 45 F2 20 01 86 34 03 80 16 00 01 00 00 46 
                                20 63 99 60 10 C8 14 00 00 47 20 65 AC 92 10 BE 
                                20 0F 00 00 03 66 61 73 74 20 C9 45 F2 20 01 86 
                                34
                            </RICindicationMessage>
                        </value>
                    </RICindication-IEs>
                    <RICindication-IEs>
                        <id>25</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICindicationHeader>08 00 F1 10</RICindicationHeader>
                        </value>
                    </RICindication-IEs>
                </protocolIEs>
            </RICindication>
        </value>
    </initiatingMessage>
</E2AP-PDU>
{"ts":1737231273412,"crit":"INFO","id":"nexran","mdc":{},"msg":"decoded initiating RICindication (5) "}
<E2SM-KPM-IndicationHeader>
    <indicationHeader-Format1>
        <pLMN-Identity>00 F1 10</pLMN-Identity>
    </indicationHeader-Format1>
</E2SM-KPM-IndicationHeader>
<E2SM-KPM-IndicationMessage>
    <ric-Style-Type>4</ric-Style-Type>
    <indicationMessage>
        <indicationMessage-Format1>
            <pm-Containers>
                <PM-Containers-List>
                    <performanceContainer>
                        <oDU>
                            <cellResourceReportList>
                                <CellResourceReportListItem>
                                    <nRCGI>
                                        <pLMN-Identity>00 F1 10</pLMN-Identity>
                                        <nRCellIdentity>
                                            000000000000000000000000000000000001
                                        </nRCellIdentity>
                                    </nRCGI>
                                    <dl-TotalofAvailablePRBs>100</dl-TotalofAvailablePRBs>
                                    <ul-TotalofAvailablePRBs>100</ul-TotalofAvailablePRBs>
                                    <servedPlmnPerCellList>
                                        <ServedPlmnPerCellListItem>
                                            <pLMN-Identity>00 F1 10</pLMN-Identity>
                                            <du-PM-EPC>
                                                <perQCIReportList>
                                                    <PerQCIReportListItem>
                                                        <qci>0</qci>
                                                    </PerQCIReportListItem>
                                                </perQCIReportList>
                                                <perUEReportList>
                                                    <PerUEReportListItem>
                                                        <rnti>70</rnti>
                                                        <dl-PRBUsage>70972</dl-PRBUsage>
                                                        <ul-PRBUsage>1180</ul-PRBUsage>
                                                        <tx-pkts>85</tx-pkts>
                                                        <tx-errors>0</tx-errors>
                                                        <tx-brate>5838984</tx-brate>
                                                        <rx-pkts>15</rx-pkts>
                                                        <rx-errors>0</rx-errors>
                                                        <rx-brate>55128</rx-brate>
                                                        <dl-cqi>15.0</dl-cqi>
                                                        <dl-ri>0</dl-ri>
                                                        <dl-pmi>0</dl-pmi>
                                                        <ul-phr>30.0</ul-phr>
                                                        <ul-sinr>104.431015014648438</ul-sinr>
                                                        <ul-rssi>0</ul-rssi>
                                                        <ul-mcs>21.233333587646484</ul-mcs>
                                                        <ul-samples>30</ul-samples>
                                                        <dl-mcs>27.78125</dl-mcs>
                                                        <dl-samples>160</dl-samples>
                                                        <imsi>1010123456780</imsi>
                                                    </PerUEReportListItem>
                                                    <PerUEReportListItem>
                                                        <rnti>71</rnti>
                                                        <dl-PRBUsage>71960</dl-PRBUsage>
                                                        <ul-PRBUsage>1142</ul-PRBUsage>
                                                        <tx-pkts>81</tx-pkts>
                                                        <tx-errors>0</tx-errors>
                                                        <tx-brate>5913312</tx-brate>
                                                        <rx-pkts>14</rx-pkts>
                                                        <rx-errors>0</rx-errors>
                                                        <rx-brate>54480</rx-brate>
                                                        <dl-cqi>15.0</dl-cqi>
                                                        <dl-ri>0</dl-ri>
                                                        <dl-pmi>0</dl-pmi>
                                                        <ul-phr>30.0</ul-phr>
                                                        <ul-sinr>104.493644714355469</ul-sinr>
                                                        <ul-rssi>0</ul-rssi>
                                                        <ul-mcs>22.357143402099609</ul-mcs>
                                                        <ul-samples>28</ul-samples>
                                                        <dl-mcs>27.879123687744141</dl-mcs>
                                                        <dl-samples>182</dl-samples>
                                                        <imsi>1010123456789</imsi>
                                                    </PerUEReportListItem>
                                                </perUEReportList>
                                                <perSliceReportList>
                                                    <PerSliceReportListItem>
                                                        <sliceName>fast</sliceName>
                                                        <dl-PRBUsage>142932</dl-PRBUsage>
                                                        <ul-PRBUsage>2322</ul-PRBUsage>
                                                        <tx-pkts>166</tx-pkts>
                                                        <tx-errors>0</tx-errors>
                                                        <tx-brate>11752296</tx-brate>
                                                        <rx-pkts>29</rx-pkts>
                                                        <rx-errors>0</rx-errors>
                                                        <rx-brate>109608</rx-brate>
                                                        <dl-cqi>15.0</dl-cqi>
                                                        <dl-ri>0</dl-ri>
                                                        <dl-pmi>0</dl-pmi>
                                                        <ul-phr>30.0</ul-phr>
                                                        <ul-sinr>0</ul-sinr>
                                                        <ul-rssi>0</ul-rssi>
                                                        <ul-mcs>21.795238494873047</ul-mcs>
                                                        <ul-samples>58</ul-samples>
                                                        <dl-mcs>27.83018684387207</dl-mcs>
                                                        <dl-samples>342</dl-samples>
                                                    </PerSliceReportListItem>
                                                </perSliceReportList>
                                            </du-PM-EPC>
                                        </ServedPlmnPerCellListItem>
                                    </servedPlmnPerCellList>
                                </CellResourceReportListItem>
                            </cellResourceReportList>
                        </oDU>
                    </performanceContainer>
                </PM-Containers-List>
                <PM-Containers-List>
                    <performanceContainer>
                        <oCU-CP>
                            <cu-CP-Resource-Status>
                                <numberOfActive-UEs>2</numberOfActive-UEs>
{"ts":1737231273416,"crit":"DEBUG","id":"nexran","mdc":{},"msg":"kpm indication report style 4 "}
{"ts":1737231273416,"crit":"DEBUG","id":"nexran","mdc":{},"msg":"nexran Indication handler"}
{"ts":1737231273416,"crit":"INFO","id":"nexran","mdc":{},"msg":"KpmIndication: KpmReport(period=5120 ms) available_dl_prbs=100 available_ul_prbs=100 ue[70]={dl_bytes=6527328,ul_bytes=51220,dl_prbs=70972,ul_prbs=1180,tx_pkts=85,tx_errors=0,tx_brate=5838984,rx_pkts=15,rx_errors=0,rx_brate=55128,dl_cqi=15,dl_ri=0,dl_pmi=0,ul_phr=30,ul_sinr=104.431,ul_mcs=21.2333,ul_samples=30,dl_mcs=27.7812,dl_samples=160,imsi=1010123456780,} ue[71]={dl_bytes=6663314,ul_bytes=48672,dl_prbs=71960,ul_prbs=1142,tx_pkts=81,tx_errors=0,tx_brate=5913312,rx_pkts=14,rx_errors=0,rx_brate=54480,dl_cqi=15,dl_ri=0,dl_pmi=0,ul_phr=30,ul_sinr=104.494,ul_mcs=22.3571,ul_samples=28,dl_mcs=27.8791,dl_samples=182,imsi=1010123456789,} slice[fast]={dl_bytes=13190642,ul_bytes=99892,dl_prbs=142932,ul_prbs=2322,tx_pkts=166,tx_errors=0,tx_brate=11752296,rx_pkts=29,rx_errors=0,rx_brate=109608,dl_cqi=15,dl_ri=0,dl_pmi=0,ul_phr=30,ul_sinr=0,ul_mcs=21.7952,ul_samples=58,dl_mcs=27.8302,dl_samples=342,} "}
                            </cu-CP-Resource-Status>
                        </oCU-CP>
                    </performanceContainer>
                </PM-Containers-List>
                <PM-Containers-List>
                    <performanceContainer>
                        <oCU-UP>
                            <pf-ContainerList>
                                <PF-ContainerListItem>
                                    <interface-type><f1-u/></interface-type>
                                    <o-CU-UP-PM-Container>
                                        <plmnList>
                                            <PlmnID-List>
                                                <pLMN-Identity>00 F1 10</pLMN-Identity>
                                                <cu-UP-PM-EPC>
                                                    <perQCIReportList>
                                                        <PerQCIReportListItemFormat>
                                                            <qci>0</qci>
                                                            <pDCPBytesDL>0</pDCPBytesDL>
                                                            <pDCPBytesUL>0</pDCPBytesUL>
                                                        </PerQCIReportListItemFormat>
                                                        <PerQCIReportListItemFormat>
                                                            <qci>7</qci>
                                                            <pDCPBytesDL>13190642</pDCPBytesDL>
                                                            <pDCPBytesUL>99892</pDCPBytesUL>
                                                        </PerQCIReportListItemFormat>
                                                    </perQCIReportList>
                                                    <perUEReportList>
                                                        <PerUEReportListItemFormat>
                                                            <rnti>70</rnti>
                                                            <bytesDL>6527328</bytesDL>
                                                            <bytesUL>51220</bytesUL>
                                                        </PerUEReportListItemFormat>
                                                        <PerUEReportListItemFormat>
                                                            <rnti>71</rnti>
                                                            <bytesDL>6663314</bytesDL>
                                                            <bytesUL>48672</bytesUL>
                                                        </PerUEReportListItemFormat>
                                                    </perUEReportList>
                                                    <perSliceReportList>
                                                        <PerSliceReportListItemFormat>
                                                            <sliceName>fast</sliceName>
                                                            <bytesDL>13190642</bytesDL>
                                                            <bytesUL>99892</bytesUL>
                                                        </PerSliceReportListItemFormat>
                                                    </perSliceReportList>
                                                </cu-UP-PM-EPC>
                                            </PlmnID-List>
                                        </plmnList>
                                    </o-CU-UP-PM-Container>
                                </PF-ContainerListItem>
                            </pf-ContainerList>
                        </oCU-UP>
                    </performanceContainer>
                </PM-Containers-List>
            </pm-Containers>
        </indicationMessage-Format1>
    </indicationMessage>
</E2SM-KPM-IndicationMessage>
{"ts":1737231273456,"crit":"INFO","id":"nexran","mdc":{},"msg":"# of UE Reports: 14"}
{"ts":1737231273456,"crit":"INFO","id":"nexran","mdc":{},"msg":"# of Slice Reports: 14"}
{"ts":1737231273460,"crit":"INFO","id":"nexran","mdc":{},"msg":"slice 'fast' share unchanged: 1024"}
{"ts":1737231273465,"crit":"INFO","id":"nexran","mdc":{},"msg":"slice 'secure_slice' share unchanged: 1"}
{"ts":1737231278527,"crit":"DEBUG","id":"nexran","mdc":{},"msg":"RMR message (type 12050, source enB_macro_001_001_0019b0)"}
<E2AP-PDU>
    <initiatingMessage>
        <procedureCode>5</procedureCode>
        <criticality><reject/></criticality>
        <value>
            <RICindication>
                <protocolIEs>
                    <RICindication-IEs>
                        <id>29</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICrequestID>
                                <ricRequestorID>123</ricRequestorID>
                                <ricInstanceID>7</ricInstanceID>
                            </RICrequestID>
                        </value>
                    </RICindication-IEs>
                    <RICindication-IEs>
                        <id>5</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RANfunctionID>0</RANfunctionID>
                        </value>
                    </RICindication-IEs>
                    <RICindication-IEs>
                        <id>15</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICactionID>1</RICactionID>
                        </value>
                    </RICindication-IEs>
                    <RICindication-IEs>
                        <id>27</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICindicationSN>15</RICindicationSN>
                        </value>
                    </RICindication-IEs>
                    <RICindication-IEs>
                        <id>28</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICindicationType><report/></RICindicationType>
                        </value>
                    </RICindication-IEs>
                    <RICindication-IEs>
                        <id>26</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICindicationMessage>
                                01 04 00 00 02 40 00 00 60 00 F1 10 00 00 00 00 
                                10 00 64 00 64 02 00 F1 10 80 00 00 00 03 80 80 
                                8E 00 01 00 00 46 20 01 17 0C 10 04 E1 01 6A 01 
                                00 03 73 4C 90 01 10 01 00 03 01 2B 10 03 80 00 
                                0F 00 00 03 80 01 0F 06 80 EF 00 D0 84 B1 00 06 
                                80 ED 00 B3 77 77 01 1E 06 80 ED 00 DF 2D F3 02 
                                00 C3 06 00 EB 30 0C C1 0C 00 00 47 20 01 14 88 
                                10 04 8A 01 5A 01 00 03 63 D1 10 01 12 01 00 03 
                                01 58 80 03 80 00 0F 00 00 03 80 01 0F 06 80 EF 
                                00 D1 09 41 00 06 80 ED 00 B2 49 25 01 1C 06 80 
                                EE 00 6F 7C B7 02 00 C3 06 00 EB 30 0C C1 15 3E 
                                00 00 03 66 61 73 74 20 02 2B 94 10 09 6B 02 00 
                                C4 01 00 04 00 D7 1D A0 01 22 01 00 03 02 83 90 
                                03 80 00 0F 00 00 03 80 01 0F 00 00 06 80 EE 00 
                                59 70 27 01 3A 05 80 F1 0D F1 3B 02 01 86 4A 00 
                                01 50 10 08 00 F1 10 80 01 60 00 00 00 00 00 60 
                                07 20 CB 59 24 20 01 97 10 03 80 16 00 01 00 00 
                                46 20 65 AC 92 10 CE C8 00 00 47 20 65 AC 92 10 
                                C8 48 0F 00 00 03 66 61 73 74 20 CB 59 24 20 01 
                                97 10
                            </RICindicationMessage>
                        </value>
                    </RICindication-IEs>
                    <RICindication-IEs>
                        <id>25</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICindicationHeader>08 00 F1 10</RICindicationHeader>
                        </value>
                    </RICindication-IEs>
                </protocolIEs>
            </RICindication>
        </value>
    </initiatingMessage>
</E2AP-PDU>
{"ts":1737231278528,"crit":"INFO","id":"nexran","mdc":{},"msg":"decoded initiating RICindication (5) "}
<E2SM-KPM-IndicationHeader>
    <indicationHeader-Format1>
        <pLMN-Identity>00 F1 10</pLMN-Identity>
    </indicationHeader-Format1>
</E2SM-KPM-IndicationHeader>
<E2SM-KPM-IndicationMessage>
    <ric-Style-Type>4</ric-Style-Type>
    <indicationMessage>
        <indicationMessage-Format1>
            <pm-Containers>
                <PM-Containers-List>
                    <performanceContainer>
                        <oDU>
                            <cellResourceReportList>
                                <CellResourceReportListItem>
                                    <nRCGI>
                                        <pLMN-Identity>00 F1 10</pLMN-Identity>
                                        <nRCellIdentity>
                                            000000000000000000000000000000000001
                                        </nRCellIdentity>
                                    </nRCGI>
                                    <dl-TotalofAvailablePRBs>100</dl-TotalofAvailablePRBs>
                                    <ul-TotalofAvailablePRBs>100</ul-TotalofAvailablePRBs>
                                    <servedPlmnPerCellList>
                                        <ServedPlmnPerCellListItem>
                                            <pLMN-Identity>00 F1 10</pLMN-Identity>
                                            <du-PM-EPC>
                                                <perQCIReportList>
                                                    <PerQCIReportListItem>
                                                        <qci>0</qci>
                                                    </PerQCIReportListItem>
                                                </perQCIReportList>
                                                <perUEReportList>
                                                    <PerUEReportListItem>
                                                        <rnti>70</rnti>
                                                        <dl-PRBUsage>71436</dl-PRBUsage>
                                                        <ul-PRBUsage>1249</ul-PRBUsage>
                                                        <tx-pkts>106</tx-pkts>
                                                        <tx-errors>0</tx-errors>
                                                        <tx-brate>7556240</tx-brate>
                                                        <rx-pkts>16</rx-pkts>
                                                        <rx-errors>0</rx-errors>
                                                        <rx-brate>76560</rx-brate>
                                                        <dl-cqi>15.0</dl-cqi>
                                                        <dl-ri>0</dl-ri>
                                                        <dl-pmi>0</dl-pmi>
                                                        <ul-phr>30.0</ul-phr>
                                                        <ul-sinr>104.259162902832031</ul-sinr>
                                                        <ul-rssi>0</ul-rssi>
                                                        <ul-mcs>22.433332443237305</ul-mcs>
                                                        <ul-samples>30</ul-samples>
                                                        <dl-mcs>27.897436141967773</dl-mcs>
                                                        <dl-samples>195</dl-samples>
                                                        <imsi>1010123456780</imsi>
                                                    </PerUEReportListItem>
                                                    <PerUEReportListItem>
                                                        <rnti>71</rnti>
                                                        <dl-PRBUsage>70792</dl-PRBUsage>
                                                        <ul-PRBUsage>1162</ul-PRBUsage>
                                                        <tx-pkts>90</tx-pkts>
                                                        <tx-errors>0</tx-errors>
                                                        <tx-brate>6541584</tx-brate>
                                                        <rx-pkts>18</rx-pkts>
                                                        <rx-errors>0</rx-errors>
                                                        <rx-brate>88192</rx-brate>
                                                        <dl-cqi>15.0</dl-cqi>
                                                        <dl-ri>0</dl-ri>
                                                        <dl-pmi>0</dl-pmi>
                                                        <ul-phr>30.0</ul-phr>
                                                        <ul-sinr>104.518074035644531</ul-sinr>
                                                        <ul-rssi>0</ul-rssi>
                                                        <ul-mcs>22.285715103149414</ul-mcs>
                                                        <ul-samples>28</ul-samples>
                                                        <dl-mcs>27.871791839599609</dl-mcs>
                                                        <dl-samples>195</dl-samples>
                                                        <imsi>1010123456789</imsi>
                                                    </PerUEReportListItem>
                                                </perUEReportList>
                                                <perSliceReportList>
                                                    <PerSliceReportListItem>
                                                        <sliceName>fast</sliceName>
                                                        <dl-PRBUsage>142228</dl-PRBUsage>
                                                        <ul-PRBUsage>2411</ul-PRBUsage>
                                                        <tx-pkts>196</tx-pkts>
                                                        <tx-errors>0</tx-errors>
                                                        <tx-brate>14097824</tx-brate>
                                                        <rx-pkts>34</rx-pkts>
                                                        <rx-errors>0</rx-errors>
                                                        <rx-brate>164752</rx-brate>
                                                        <dl-cqi>15.0</dl-cqi>
                                                        <dl-ri>0</dl-ri>
                                                        <dl-pmi>0</dl-pmi>
                                                        <ul-phr>30.0</ul-phr>
                                                        <ul-sinr>0</ul-sinr>
                                                        <ul-rssi>0</ul-rssi>
                                                        <ul-mcs>22.359523773193359</ul-mcs>
                                                        <ul-samples>58</ul-samples>
                                                        <dl-mcs>27.884613037109375</dl-mcs>
                                                        <dl-samples>390</dl-samples>
                                                    </PerSliceReportListItem>
                                                </perSliceReportList>
                                            </du-PM-EPC>
                                        </ServedPlmnPerCellListItem>
                                    </servedPlmnPerCellList>
                                </CellResourceReportListItem>
                            </cellResourceReportList>
                        </oDU>
                    </performanceContainer>
                </PM-Containers-List>
                <PM-Containers-List>
                    <performanceContainer>
                        <oCU-CP>
                            <cu-CP-Resource-Status>
                                <numberOfActive-UEs>2</numberOfActive-UEs>
                            </cu-CP-Resource-Status>
                        </oCU-CP>
                    </performanceContainer>
                </PM-Containers-List>
                <PM-Containers-List>
                    <performanceContainer>
                        <oCU-UP>
                            <pf-ContainerList>
                                <PF-ContainerListItem>
                                    <interface-type><f1-u/></interface-type>
                                    <o-CU-UP-PM-Container>
                                        <plmnList>
                                            <PlmnID-List>
                                                <pLMN-Identity>00 F1 10</pLMN-Identity>
                                                <cu-UP-PM-EPC>
                                                    <perQCIReportList>
                                                        <PerQCIReportListItemFormat>
                                                            <qci>0</qci>
                                                            <pDCPBytesDL>0</pDCPBytesDL>
                                                            <pDCPBytesUL>0</pDCPBytesUL>
                                                        </PerQCIReportListItemFormat>
                                                        <PerQCIReportListItemFormat>
                                                            <qci>7</qci>
                                                            <pDCPBytesDL>13326628</pDCPBytesDL>
                                                            <pDCPBytesUL>104208</pDCPBytesUL>
                                                        </PerQCIReportListItemFormat>
                                                    </perQCIReportList>
                                                    <perUEReportList>
                                                        <PerUEReportListItemFormat>
                                                            <rnti>70</rnti>
                                                            <bytesDL>6663314</bytesDL>
                                                            <bytesUL>52936</bytesUL>
                                                        </PerUEReportListItemFormat>
                                                        <PerUEReportListItemFormat>
                                                            <rnti>71</rnti>
                                                            <bytesDL>6663314</bytesDL>
                                                            <bytesUL>51272</bytesUL>
                                                        </PerUEReportListItemFormat>
                                                    </perUEReportList>
                                                    <perSliceReportList>
                                                        <PerSliceReportListItemFormat>
                                                            <sliceName>fast</sliceName>
                                                            <bytesDL>13326628</bytesDL>
                                                            <bytesUL>104208</bytesUL>
                                                        </PerSliceReportListItemFormat>
                                                    </perSliceReportList>
                                                </cu-UP-PM-EPC>
                                            </PlmnID-List>
                                        </plmnList>
                                    </o-CU-UP-PM-Container>
                                </PF-ContainerListItem>
                            </pf-ContainerList>
                        </oCU-UP>
                    </performanceContainer>
                </PM-Containers-List>
            </pm-Containers>
        </indicationMessage-Format1>
    </indicationMessage>
</E2SM-KPM-IndicationMessage>
{"ts":1737231278532,"crit":"DEBUG","id":"nexran","mdc":{},"msg":"kpm indication report style 4 "}
{"ts":1737231278532,"crit":"DEBUG","id":"nexran","mdc":{},"msg":"nexran Indication handler"}
{"ts":1737231278532,"crit":"INFO","id":"nexran","mdc":{},"msg":"KpmIndication: KpmReport(period=5120 ms) available_dl_prbs=100 available_ul_prbs=100 ue[70]={dl_bytes=6663314,ul_bytes=52936,dl_prbs=71436,ul_prbs=1249,tx_pkts=106,tx_errors=0,tx_brate=7556240,rx_pkts=16,rx_errors=0,rx_brate=76560,dl_cqi=15,dl_ri=0,dl_pmi=0,ul_phr=30,ul_sinr=104.259,ul_mcs=22.4333,ul_samples=30,dl_mcs=27.8974,dl_samples=195,imsi=1010123456780,} ue[71]={dl_bytes=6663314,ul_bytes=51272,dl_prbs=70792,ul_prbs=1162,tx_pkts=90,tx_errors=0,tx_brate=6541584,rx_pkts=18,rx_errors=0,rx_brate=88192,dl_cqi=15,dl_ri=0,dl_pmi=0,ul_phr=30,ul_sinr=104.518,ul_mcs=22.2857,ul_samples=28,dl_mcs=27.8718,dl_samples=195,imsi=1010123456789,} slice[fast]={dl_bytes=13326628,ul_bytes=104208,dl_prbs=142228,ul_prbs=2411,tx_pkts=196,tx_errors=0,tx_brate=14097824,rx_pkts=34,rx_errors=0,rx_brate=164752,dl_cqi=15,dl_ri=0,dl_pmi=0,ul_phr=30,ul_sinr=0,ul_mcs=22.3595,ul_samples=58,dl_mcs=27.8846,dl_samples=390,} "}
{"ts":1737231278551,"crit":"INFO","id":"nexran","mdc":{},"msg":"# of UE Reports: 15"}
{"ts":1737231278551,"crit":"INFO","id":"nexran","mdc":{},"msg":"# of Slice Reports: 15"}
{"ts":1737231278556,"crit":"INFO","id":"nexran","mdc":{},"msg":"slice 'fast' share unchanged: 1024"}
{"ts":1737231278565,"crit":"INFO","id":"nexran","mdc":{},"msg":"slice 'secure_slice' share unchanged: 1"}
1737231281961 1/RMR [INFO] sends: ts=1737231281 src=service-ricxapp-dc-rmr.ricxapp:4560 target=10.106.64.163:38000 open=1 succ=7 fail=0 (hard=0 soft=0)
1737231281961 1/RMR [INFO] sends: ts=1737231281 src=service-ricxapp-dc-rmr.ricxapp:4560 target=service-ricplt-e2term-rmr-alpha.ricplt:38000 open=0 succ=0 fail=0 (hard=0 soft=0)
1737231281961 1/RMR [INFO] sends: ts=1737231281 src=service-ricxapp-dc-rmr.ricxapp:4560 target=service-ricplt-submgr-rmr.ricplt:4560 open=1 succ=2 fail=0 (hard=0 soft=0)
1737231281961 1/RMR [INFO] sends: ts=1737231281 src=service-ricxapp-dc-rmr.ricxapp:4560 target=service-ricplt-e2mgr-rmr.ricplt:3801 open=0 succ=0 fail=0 (hard=0 soft=0)
1737231281961 1/RMR [INFO] sends: ts=1737231281 src=service-ricxapp-dc-rmr.ricxapp:4560 target=service-ricplt-a1mediator-rmr.ricplt:4562 open=0 succ=0 fail=0 (hard=0 soft=0)
{"ts":1737231283649,"crit":"DEBUG","id":"nexran","mdc":{},"msg":"RMR message (type 12050, source enB_macro_001_001_0019b0)"}
<E2AP-PDU>
    <initiatingMessage>
        <procedureCode>5</procedureCode>
        <criticality><reject/></criticality>
        <value>
            <RICindication>
                <protocolIEs>
                    <RICindication-IEs>
                        <id>29</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICrequestID>
                                <ricRequestorID>123</ricRequestorID>
                                <ricInstanceID>7</ricInstanceID>
                            </RICrequestID>
                        </value>
                    </RICindication-IEs>
                    <RICindication-IEs>
                        <id>5</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RANfunctionID>0</RANfunctionID>
                        </value>
                    </RICindication-IEs>
                    <RICindication-IEs>
                        <id>15</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICactionID>1</RICactionID>
                        </value>
                    </RICindication-IEs>
                    <RICindication-IEs>
                        <id>27</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICindicationSN>16</RICindicationSN>
                        </value>
                    </RICindication-IEs>
                    <RICindication-IEs>
                        <id>28</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICindicationType><report/></RICindicationType>
                        </value>
                    </RICindication-IEs>
                    <RICindication-IEs>
                        <id>26</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICindicationMessage>
                                01 04 00 00 02 40 00 00 60 00 F1 10 00 00 00 00 
                                10 00 64 00 64 02 00 F1 10 80 00 00 00 03 80 80 
                                90 00 01 00 00 46 20 01 17 0C 10 04 F5 01 7B 01 
                                00 04 00 85 15 08 01 14 01 00 03 01 6D 20 03 80 
                                00 0F 00 00 03 80 01 0F 06 80 EF 00 D0 D3 67 00 
                                06 80 ED 00 B2 49 25 01 23 06 80 EF 00 37 BD 7B 
                                02 00 FE 06 00 EB 30 0C C1 0C 00 00 47 20 01 17 
                                FC 10 04 73 01 79 01 01 04 00 85 93 08 01 17 01 
                                00 03 01 7F 48 03 80 00 0F 00 00 03 80 01 0F 06 
                                80 F0 00 68 85 0D 00 06 80 ED 00 B2 F4 DF 01 2E 
                                06 80 EF 00 37 C7 9D 02 00 E3 06 00 EB 30 0C C1 
                                15 3E 00 00 03 66 61 73 74 20 02 2F 08 10 09 68 
                                02 00 F4 01 01 04 01 0A A8 10 01 2B 01 00 03 02 
                                EC 68 03 80 00 0F 00 00 03 80 01 0F 00 00 06 80 
                                EE 00 59 4F 81 01 51 05 80 F1 0D F0 A3 02 01 E1 
                                4A 00 01 50 10 08 00 F1 10 80 01 60 00 00 00 00 
                                00 60 07 20 C9 45 F2 20 01 98 48 03 80 16 00 01 
                                00 00 46 20 65 AC 92 10 D4 E0 00 00 47 20 63 99 
                                60 10 C3 68 0F 00 00 03 66 61 73 74 20 C9 45 F2 
                                20 01 98 48
                            </RICindicationMessage>
                        </value>
                    </RICindication-IEs>
                    <RICindication-IEs>
                        <id>25</id>
                        <criticality><reject/></criticality>
                        <value>
                            <RICindicationHeader>08 00 F1 10</RICindicationHeader>
                        </value>
                    </RICindication-IEs>
{"ts":1737231283650,"crit":"INFO","id":"nexran","mdc":{},"msg":"decoded initiating RICindication (5) "}
                </protocolIEs>
            </RICindication>
        </value>
    </initiatingMessage>
</E2AP-PDU>
<E2SM-KPM-IndicationHeader>
    <indicationHeader-Format1>
        <pLMN-Identity>00 F1 10</pLMN-Identity>
    </indicationHeader-Format1>
</E2SM-KPM-IndicationHeader>
<E2SM-KPM-IndicationMessage>
    <ric-Style-Type>4</ric-Style-Type>
    <indicationMessage>
        <indicationMessage-Format1>
            <pm-Containers>
                <PM-Containers-List>
                    <performanceContainer>
                        <oDU>
                            <cellResourceReportList>
                                <CellResourceReportListItem>
                                    <nRCGI>
                                        <pLMN-Identity>00 F1 10</pLMN-Identity>
                                        <nRCellIdentity>
                                            000000000000000000000000000000000001
                                        </nRCellIdentity>
                                    </nRCGI>
                                    <dl-TotalofAvailablePRBs>100</dl-TotalofAvailablePRBs>
                                    <ul-TotalofAvailablePRBs>100</ul-TotalofAvailablePRBs>
                                    <servedPlmnPerCellList>
                                        <ServedPlmnPerCellListItem>
                                            <pLMN-Identity>00 F1 10</pLMN-Identity>
                                            <du-PM-EPC>
                                                <perQCIReportList>
                                                    <PerQCIReportListItem>
                                                        <qci>0</qci>
                                                    </PerQCIReportListItem>
                                                </perQCIReportList>
                                                <perUEReportList>
                                                    <PerUEReportListItem>
                                                        <rnti>70</rnti>
                                                        <dl-PRBUsage>71436</dl-PRBUsage>
                                                        <ul-PRBUsage>1269</ul-PRBUsage>
                                                        <tx-pkts>123</tx-pkts>
                                                        <tx-errors>0</tx-errors>
                                                        <tx-brate>8721672</tx-brate>
                                                        <rx-pkts>20</rx-pkts>
                                                        <rx-errors>0</rx-errors>
                                                        <rx-brate>93472</rx-brate>
                                                        <dl-cqi>15.0</dl-cqi>
                                                        <dl-ri>0</dl-ri>
                                                        <dl-pmi>0</dl-pmi>
                                                        <ul-phr>30.0</ul-phr>
                                                        <ul-sinr>104.412895202636719</ul-sinr>
                                                        <ul-rssi>0</ul-rssi>
                                                        <ul-mcs>22.285715103149414</ul-mcs>
                                                        <ul-samples>35</ul-samples>
                                                        <dl-mcs>27.870079040527344</dl-mcs>
                                                        <dl-samples>254</dl-samples>
                                                        <imsi>1010123456780</imsi>
                                                    </PerUEReportListItem>
                                                    <PerUEReportListItem>
                                                        <rnti>71</rnti>
                                                        <dl-PRBUsage>71676</dl-PRBUsage>
                                                        <ul-PRBUsage>1139</ul-PRBUsage>
                                                        <tx-pkts>121</tx-pkts>
                                                        <tx-errors>1</tx-errors>
                                                        <tx-brate>8753928</tx-brate>
                                                        <rx-pkts>23</rx-pkts>
                                                        <rx-errors>0</rx-errors>
                                                        <rx-brate>98120</rx-brate>
                                                        <dl-cqi>15.0</dl-cqi>
                                                        <dl-ri>0</dl-ri>
                                                        <dl-pmi>0</dl-pmi>
                                                        <ul-phr>30.0</ul-phr>
                                                        <ul-sinr>104.519729614257812</ul-sinr>
                                                        <ul-rssi>0</ul-rssi>
                                                        <ul-mcs>22.369565963745117</ul-mcs>
                                                        <ul-samples>46</ul-samples>
                                                        <dl-mcs>27.889869689941406</dl-mcs>
                                                        <dl-samples>227</dl-samples>
                                                        <imsi>1010123456789</imsi>
                                                    </PerUEReportListItem>
                                                </perUEReportList>
                                                <perSliceReportList>
                                                    <PerSliceReportListItem>
                                                        <sliceName>fast</sliceName>
                                                        <dl-PRBUsage>143112</dl-PRBUsage>
                                                        <ul-PRBUsage>2408</ul-PRBUsage>
                                                        <tx-pkts>244</tx-pkts>
                                                        <tx-errors>1</tx-errors>
                                                        <tx-brate>17475600</tx-brate>
                                                        <rx-pkts>43</rx-pkts>
                                                        <rx-errors>0</rx-errors>
                                                        <rx-brate>191592</rx-brate>
                                                        <dl-cqi>15.0</dl-cqi>
                                                        <dl-ri>0</dl-ri>
                                                        <dl-pmi>0</dl-pmi>
                                                        <ul-phr>30.0</ul-phr>
                                                        <ul-sinr>0</ul-sinr>
                                                        <ul-rssi>0</ul-rssi>
                                                        <ul-mcs>22.327640533447266</ul-mcs>
                                                        <ul-samples>81</ul-samples>
                                                        <dl-mcs>27.879974365234375</dl-mcs>
                                                        <dl-samples>481</dl-samples>
                                                    </PerSliceReportListItem>
                                                </perSliceReportList>
                                            </du-PM-EPC>
                                        </ServedPlmnPerCellListItem>
                                    </servedPlmnPerCellList>
                                </CellResourceReportListItem>
                            </cellResourceReportList>
                        </oDU>
                    </performanceContainer>
                </PM-Containers-List>
                <PM-Containers-List>
                    <performanceContainer>
                        <oCU-CP>
                            <cu-CP-Resource-Status>
                                <numberOfActive-UEs>2</numberOfActive-UEs>
                            </cu-CP-Resource-Status>
                        </oCU-CP>
                    </performanceContainer>
                </PM-Containers-List>
                <PM-Containers-List>
                    <performanceContainer>
                        <oCU-UP>
                            <pf-ContainerList>
                                <PF-ContainerListItem>
                                    <interface-type><f1-u/></interface-type>
                                    <o-CU-UP-PM-Container>
                                        <plmnList>
                                            <PlmnID-List>
                                                <pLMN-Identity>00 F1 10</pLMN-Identity>
                                                <cu-UP-PM-EPC>
                                                    <perQCIReportList>
                                                        <PerQCIReportListItemFormat>
                                                            <qci>0</qci>
                                                            <pDCPBytesDL>0</pDCPBytesDL>
                                                            <pDCPBytesUL>0</pDCPBytesUL>
                                                        </PerQCIReportListItemFormat>
                                                        <PerQCIReportListItemFormat>
                                                            <qci>7</qci>
                                                            <pDCPBytesDL>13190642</pDCPBytesDL>
                                                            <pDCPBytesUL>104520</pDCPBytesUL>
                                                        </PerQCIReportListItemFormat>
                                                    </perQCIReportList>
                                                    <perUEReportList>
                                                        <PerUEReportListItemFormat>
                                                            <rnti>70</rnti>
                                                            <bytesDL>6663314</bytesDL>
                                                            <bytesUL>54496</bytesUL>
                                                        </PerUEReportListItemFormat>
                                                        <PerUEReportListItemFormat>
                                                            <rnti>71</rnti>
                                                            <bytesDL>6527328</bytesDL>
                                                            <bytesUL>50024</bytesUL>
                                                        </PerUEReportListItemFormat>
                                                    </perUEReportList>
                                                    <perSliceReportList>
                                                        <PerSliceReportListItemFormat>
                                                            <sliceName>fast</sliceName>
                                                            <bytesDL>13190642</bytesDL>
                                                            <bytesUL>104520</bytesUL>
                                                        </PerSliceReportListItemFormat>
                                                    </perSliceReportList>
                                                </cu-UP-PM-EPC>
                                            </PlmnID-List>
                                        </plmnList>
                                    </o-CU-UP-PM-Container>
                                </PF-ContainerListItem>
                            </pf-ContainerList>
                        </oCU-UP>
                    </performanceContainer>
                </PM-Containers-List>
            </pm-Containers>
        </indicationMessage-Format1>
    </indicationMessage>
</E2SM-KPM-IndicationMessage>
{"ts":1737231283655,"crit":"DEBUG","id":"nexran","mdc":{},"msg":"kpm indication report style 4 "}
{"ts":1737231283655,"crit":"DEBUG","id":"nexran","mdc":{},"msg":"nexran Indication handler"}
{"ts":1737231283655,"crit":"INFO","id":"nexran","mdc":{},"msg":"KpmIndication: KpmReport(period=5120 ms) available_dl_prbs=100 available_ul_prbs=100 ue[70]={dl_bytes=6663314,ul_bytes=54496,dl_prbs=71436,ul_prbs=1269,tx_pkts=123,tx_errors=0,tx_brate=8721672,rx_pkts=20,rx_errors=0,rx_brate=93472,dl_cqi=15,dl_ri=0,dl_pmi=0,ul_phr=30,ul_sinr=104.413,ul_mcs=22.2857,ul_samples=35,dl_mcs=27.8701,dl_samples=254,imsi=1010123456780,} ue[71]={dl_bytes=6527328,ul_bytes=50024,dl_prbs=71676,ul_prbs=1139,tx_pkts=121,tx_errors=1,tx_brate=8753928,rx_pkts=23,rx_errors=0,rx_brate=98120,dl_cqi=15,dl_ri=0,dl_pmi=0,ul_phr=30,ul_sinr=104.52,ul_mcs=22.3696,ul_samples=46,dl_mcs=27.8899,dl_samples=227,imsi=1010123456789,} slice[fast]={dl_bytes=13190642,ul_bytes=104520,dl_prbs=143112,ul_prbs=2408,tx_pkts=244,tx_errors=1,tx_brate=17475600,rx_pkts=43,rx_errors=0,rx_brate=191592,dl_cqi=15,dl_ri=0,dl_pmi=0,ul_phr=30,ul_sinr=0,ul_mcs=22.3276,ul_samples=81,dl_mcs=27.88,dl_samples=481,} "}
{"ts":1737231283679,"crit":"INFO","id":"nexran","mdc":{},"msg":"# of UE Reports: 16"}
{"ts":1737231283679,"crit":"INFO","id":"nexran","mdc":{},"msg":"# of Slice Reports: 16"}
-- FETCHING DATA FROM INFLUXDB --
Data normalized with Min-Max Scaling. Min: [3. 0. 0.], Max: [140.   1.  15.]
Data array shape before reshaping: (32, 3)
Data array dtype: float32
Reshaped data array shape: (3, 10, 3)
Sample data (first sequence):
[[0.         0.         0.        ]
 [0.         0.         0.        ]
 [0.08759124 0.         1.        ]
 [0.15328467 0.         1.        ]
 [0.20437956 0.         1.        ]
 [0.1970803  0.         1.        ]
 [0.43065694 0.         1.        ]
 [0.3138686  1.         1.        ]
 [0.52554744 0.         1.        ]
 [0.5328467  0.         1.        ]]
inside the try -------
Data tensor created with shape: torch.Size([3, 10, 3])
labels: tensor([0., 0., 0.])
Starting initial training phase first 32 kpm reports...
Training the model
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 2.0607
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 2.0335
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 2.0061
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 1.9769
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 1.9503
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 1.9167
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 1.8863
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 1.8394
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 1.7978
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 1.7619
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 1.7262
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 1.6906
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 1.6500
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 1.6215
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 1.5885
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 1.5460
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 1.5147
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 1.4931
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 1.4661
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 1.4484
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 1.4298
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 1.4137
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 1.4004
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 1.3892
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 1.3758
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 1.3636
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 1.3530
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 1.3412
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 1.3292
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 1.3184
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 1.3067
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 1.2954
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 1.2846
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 1.2727
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 1.2615
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 1.2493
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 1.2381
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 1.2262
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 1.2137
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 1.2016
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 1.1895
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 1.1773
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 1.1648
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 1.1513
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 1.1384
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 1.1254
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 1.1120
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 1.0989
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 1.0847
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 1.0705
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 1.0558
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 1.0412
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 1.0263
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 1.0111
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.9956
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.9803
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.9636
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.9476
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.9304
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.9139
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.8960
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.8791
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.8607
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.8427
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.8241
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.8050
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.7862
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.7659
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.7471
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.7283
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.7090
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.6885
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.6701
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.6503
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.6311
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.6122
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.5926
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.5759
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.5569
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.5394
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.5231
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.5069
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.4924
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.4772
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.4627
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.4485
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.4345
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.4235
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.4121
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.3995
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.3904
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.3798
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.3704
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.3630
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.3542
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.3477
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.3403
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.3337
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.3280
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.3224
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.3163
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.3123
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.3082
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.3041
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.3000
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2975
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2940
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2911
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2886
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2865
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2847
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2825
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2812
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2793
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2778
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2763
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2756
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2742
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2730
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2722
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2715
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2707
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2697
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2690
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2684
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2677
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2673
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2668
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2663
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2657
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2652
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2649
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2645
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2641
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2637
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2633
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2631
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2628
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2624
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2622
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2619
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2615
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2613
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2610
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2608
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2605
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2602
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2600
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2598
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2596
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2594
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2591
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2590
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2588
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2586
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2584
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2582
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2581
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2579
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2578
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2576
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2575
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2573
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2572
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2570
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2569
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2567
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2566
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2564
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2563
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2562
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2561
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2559
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2558
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2556
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2556
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2555
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2553
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2552
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2551
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2550
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2548
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2548
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2546
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2545
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2544
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2543
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2542
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2541
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2540
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2539
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2538
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2537
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2536
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2535
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2534
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2533
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2532
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2531
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2531
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2529
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2528
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2527
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2527
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2526
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2525
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2525
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2523
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2522
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2522
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2521
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2520
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2519
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2518
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2518
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
1737231312972 1/RMR [INFO] sends: ts=1737231312 src=service-ricxapp-dc-rmr.ricxapp:4560 target=10.106.64.163:38000 open=1 succ=7 fail=0 (hard=0 soft=0)
1737231312972 1/RMR [INFO] sends: ts=1737231312 src=service-ricxapp-dc-rmr.ricxapp:4560 target=service-ricplt-e2term-rmr-alpha.ricplt:38000 open=0 succ=0 fail=0 (hard=0 soft=0)
1737231312972 1/RMR [INFO] sends: ts=1737231312 src=service-ricxapp-dc-rmr.ricxapp:4560 target=service-ricplt-submgr-rmr.ricplt:4560 open=1 succ=2 fail=0 (hard=0 soft=0)
1737231312972 1/RMR [INFO] sends: ts=1737231312 src=service-ricxapp-dc-rmr.ricxapp:4560 target=service-ricplt-e2mgr-rmr.ricplt:3801 open=0 succ=0 fail=0 (hard=0 soft=0)
1737231312972 1/RMR [INFO] sends: ts=1737231312 src=service-ricxapp-dc-rmr.ricxapp:4560 target=service-ricplt-a1mediator-rmr.ricplt:4562 open=0 succ=0 fail=0 (hard=0 soft=0)
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2517
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2516
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2515
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2515
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2514
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2513
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2512
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2512
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2511
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2510
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2509
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2509
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2508
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2508
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2507
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2506
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2505
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2505
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2505
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2504
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2503
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2503
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2502
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2501
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2500
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2500
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2499
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2499
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2499
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2498
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2497
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2496
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2496
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2495
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2495
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2494
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2493
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2493
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2493
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2492
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2491
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2491
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2490
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2489
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2489
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2489
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2488
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2488
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2487
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2487
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2486
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2485
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2486
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2485
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2484
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2484
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2483
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2483
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2483
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2482
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2482
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2481
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2481
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2480
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2480
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2479
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2479
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2478
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2478
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2477
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2477
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2476
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2476
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2475
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2475
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2475
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2474
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2474
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2474
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2473
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2473
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2473
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2472
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2472
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2472
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2471
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2471
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2470
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2470
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2469
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2469
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2469
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2468
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2468
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2468
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2468
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2467
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2466
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2466
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2466
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2465
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2465
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2465
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2464
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2464
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2464
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2463
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2463
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2463
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2462
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2462
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2462
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2462
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2461
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2461
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2461
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2460
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2459
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2459
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2460
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2459
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2458
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2459
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2458
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2457
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2458
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2457
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2457
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2457
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2456
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2456
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2455
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2455
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2455
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2455
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2454
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2455
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2454
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2454
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2453
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2453
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2453
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2452
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2452
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2452
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2452
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2451
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2451
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2451
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2451
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2450
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2450
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2450
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2450
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2450
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2449
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2449
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2448
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2449
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2448
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2448
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2447
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2447
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2447
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2447
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2446
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2447
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2446
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2446
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2445
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2445
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2445
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2445
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2445
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2444
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2444
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2444
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2444
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2444
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2443
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2443
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2443
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2442
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2442
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2442
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2442
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2442
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2441
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2441
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2441
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2441
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2441
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2440
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2440
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2440
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2440
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2439
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2439
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2439
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2439
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2438
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2438
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2438
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2438
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2438
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2438
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2438
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2437
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2437
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2437
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2436
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2436
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2436
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2436
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2436
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2436
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2435
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2435
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2435
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2435
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2435
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2434
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2434
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2434
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
1737231343971 1/RMR [INFO] sends: ts=1737231343 src=service-ricxapp-dc-rmr.ricxapp:4560 target=10.106.64.163:38000 open=1 succ=7 fail=0 (hard=0 soft=0)
1737231343971 1/RMR [INFO] sends: ts=1737231343 src=service-ricxapp-dc-rmr.ricxapp:4560 target=service-ricplt-e2term-rmr-alpha.ricplt:38000 open=0 succ=0 fail=0 (hard=0 soft=0)
1737231343971 1/RMR [INFO] sends: ts=1737231343 src=service-ricxapp-dc-rmr.ricxapp:4560 target=service-ricplt-submgr-rmr.ricplt:4560 open=1 succ=2 fail=0 (hard=0 soft=0)
1737231343971 1/RMR [INFO] sends: ts=1737231343 src=service-ricxapp-dc-rmr.ricxapp:4560 target=service-ricplt-e2mgr-rmr.ricplt:3801 open=0 succ=0 fail=0 (hard=0 soft=0)
1737231343971 1/RMR [INFO] sends: ts=1737231343 src=service-ricxapp-dc-rmr.ricxapp:4560 target=service-ricplt-a1mediator-rmr.ricplt:4562 open=0 succ=0 fail=0 (hard=0 soft=0)
Training completed for current batch. Loss: 0.2434
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2433
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2434
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2433
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2433
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2433
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2433
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2433
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2432
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2432
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2432
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2432
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2432
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2432
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2431
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2431
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2431
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2431
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2431
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2430
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2430
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2430
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2430
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2430
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2429
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2429
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2429
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2429
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2429
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2428
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2429
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2428
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2428
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2428
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2428
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2428
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2428
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2428
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2427
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2427
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2427
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2427
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2426
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2426
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2426
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2426
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2426
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2426
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2426
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2425
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2425
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2426
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2425
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2425
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2425
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2424
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2424
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2424
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2424
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2424
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2424
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2424
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2424
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2423
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2423
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2423
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2423
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2423
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2423
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2423
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2422
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2422
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2422
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2422
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2422
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2421
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2422
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2421
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2421
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2421
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2421
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2421
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2421
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2421
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2420
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2420
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2420
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2420
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2420
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2420
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2420
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2420
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2419
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2419
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2419
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2419
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2418
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2418
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2418
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2418
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2418
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2418
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2418
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2418
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2418
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2417
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2417
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2417
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2417
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2417
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2417
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2417
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2417
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2416
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2416
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2416
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2417
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2416
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2416
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2416
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2416
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2415
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2415
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2416
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2415
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2415
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2415
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2415
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2415
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2414
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2415
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2414
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2414
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2414
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2414
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2414
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2414
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2414
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2414
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2414
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2413
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2413
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2414
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2413
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2413
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2413
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2413
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2412
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2413
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2412
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2412
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2412
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2412
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2412
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2412
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2412
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2412
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2411
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2411
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2411
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2411
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2411
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2411
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2411
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2411
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2411
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2410
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2411
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2410
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2411
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2410
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2410
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2410
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2410
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2409
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2410
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2410
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2409
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2409
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2409
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2409
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2409
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2409
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2409
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2409
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2409
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2408
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2408
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2408
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2408
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2408
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2408
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2408
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2408
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2408
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2407
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2407
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2408
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2407
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2407
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2407
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2407
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2407
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2407
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2407
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2407
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2406
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2406
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2407
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2406
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2406
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2406
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2406
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2406
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2406
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2406
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2406
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2406
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2405
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2405
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2405
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2405
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2405
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2405
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2405
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2405
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2405
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2404
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2405
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2404
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2404
1737231374985 1/RMR [INFO] sends: ts=1737231374 src=service-ricxapp-dc-rmr.ricxapp:4560 target=10.106.64.163:38000 open=1 succ=7 fail=0 (hard=0 soft=0)
1737231374985 1/RMR [INFO] sends: ts=1737231374 src=service-ricxapp-dc-rmr.ricxapp:4560 target=service-ricplt-e2term-rmr-alpha.ricplt:38000 open=0 succ=0 fail=0 (hard=0 soft=0)
1737231374985 1/RMR [INFO] sends: ts=1737231374 src=service-ricxapp-dc-rmr.ricxapp:4560 target=service-ricplt-submgr-rmr.ricplt:4560 open=1 succ=2 fail=0 (hard=0 soft=0)
1737231374985 1/RMR [INFO] sends: ts=1737231374 src=service-ricxapp-dc-rmr.ricxapp:4560 target=service-ricplt-e2mgr-rmr.ricplt:3801 open=0 succ=0 fail=0 (hard=0 soft=0)
1737231374985 1/RMR [INFO] sends: ts=1737231374 src=service-ricxapp-dc-rmr.ricxapp:4560 target=service-ricplt-a1mediator-rmr.ricplt:4562 open=0 succ=0 fail=0 (hard=0 soft=0)
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2404
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2404
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2404
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2404
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2404
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2404
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2404
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2403
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2403
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2404
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2403
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2403
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2403
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2403
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2403
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2403
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2403
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2403
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2402
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2403
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2403
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2402
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2402
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2402
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2402
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2402
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2402
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2402
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2402
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2402
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2401
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2402
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2402
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2401
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2401
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2401
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2401
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2401
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2401
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2401
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2401
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2401
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2401
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2401
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2401
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2400
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2400
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2400
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2400
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2401
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2400
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2400
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2400
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2400
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2400
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2400
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2400
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2399
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2399
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2399
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2399
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2399
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2399
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2399
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2399
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2399
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2399
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2399
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2399
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2399
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2399
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2399
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2398
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2398
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2399
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2398
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2399
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2398
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2398
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2398
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2398
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2398
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2397
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2398
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2398
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2397
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2397
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2397
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2397
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2397
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2397
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2397
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2397
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2397
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2397
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2397
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2397
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2397
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2396
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2397
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2396
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2397
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2396
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2396
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2396
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2396
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2396
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2396
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2396
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2396
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2396
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2395
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2395
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2395
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2396
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2395
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2395
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2395
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2395
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2395
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2395
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2395
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2395
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2395
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2395
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2395
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2395
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2395
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2394
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2395
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2394
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2394
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2394
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2394
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2394
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2394
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2394
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2394
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2394
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2394
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2394
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2394
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2394
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2393
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2394
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2393
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2393
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2394
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2394
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2393
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2393
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2393
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2393
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2393
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2393
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2393
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2393
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2393
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2393
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2393
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2393
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2393
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2393
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2392
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2392
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2392
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2392
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2392
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2392
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2392
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2392
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2392
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2392
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2392
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2392
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2392
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2391
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2391
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2391
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2392
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2392
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2391
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2391
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2391
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2391
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2391
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2391
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2391
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2391
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2391
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2391
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2391
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2391
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2391
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2391
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2391
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2390
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2390
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2390
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2390
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2390
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2390
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2390
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2390
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2390
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2391
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2390
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2390
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2390
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2390
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2390
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2390
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2389
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2390
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2390
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2390
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2389
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2390
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2389
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2389
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2389
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2389
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2389
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2389
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2389
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2389
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2389
1737231405980 1/RMR [INFO] sends: ts=1737231405 src=service-ricxapp-dc-rmr.ricxapp:4560 target=10.106.64.163:38000 open=1 succ=7 fail=0 (hard=0 soft=0)
1737231405980 1/RMR [INFO] sends: ts=1737231405 src=service-ricxapp-dc-rmr.ricxapp:4560 target=service-ricplt-e2term-rmr-alpha.ricplt:38000 open=0 succ=0 fail=0 (hard=0 soft=0)
1737231405980 1/RMR [INFO] sends: ts=1737231405 src=service-ricxapp-dc-rmr.ricxapp:4560 target=service-ricplt-submgr-rmr.ricplt:4560 open=1 succ=2 fail=0 (hard=0 soft=0)
1737231405980 1/RMR [INFO] sends: ts=1737231405 src=service-ricxapp-dc-rmr.ricxapp:4560 target=service-ricplt-e2mgr-rmr.ricplt:3801 open=0 succ=0 fail=0 (hard=0 soft=0)
1737231405980 1/RMR [INFO] sends: ts=1737231405 src=service-ricxapp-dc-rmr.ricxapp:4560 target=service-ricplt-a1mediator-rmr.ricplt:4562 open=0 succ=0 fail=0 (hard=0 soft=0)
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2389
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2389
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2389
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2389
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2388
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2388
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2389
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2389
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2388
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2388
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2389
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2388
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2388
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2388
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2388
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2388
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2388
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2388
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2388
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2388
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2388
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2388
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2388
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2388
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2388
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2387
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2388
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2388
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2387
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2387
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2387
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2387
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2388
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2387
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2387
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2387
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2387
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2387
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2387
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2387
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2387
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2387
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2387
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2387
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2387
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2386
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2387
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2386
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2386
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2386
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2386
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2386
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2386
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2386
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2386
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2386
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2386
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2386
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2386
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2386
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2386
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2386
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2386
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2386
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2386
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2386
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2386
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2386
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2385
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2385
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2385
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2385
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2385
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2385
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2385
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2385
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2385
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2386
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2385
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2385
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2385
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2385
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2385
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2385
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2385
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2385
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2385
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2384
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2385
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2385
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2385
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2384
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2385
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2384
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2384
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2384
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2384
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2384
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2384
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2384
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2384
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2384
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Batch data shape: torch.Size([1, 10, 3])
Input x shape: torch.Size([1, 10, 3])
Shape of encoder hidden state h[-1]: torch.Size([1, 64])
Shape of latent: torch.Size([1, 32])
Shape of decoded hidden state: torch.Size([1, 1, 3])
Shape of decoded cell state: torch.Size([1, 1, 3])
Shape of decoder_input: torch.Size([1, 10, 64])
Shape of reconstructed output: torch.Size([1, 10, 3])
Reconstructed data shape: torch.Size([1, 10, 3])
Training completed for current batch. Loss: 0.2384
Initial training completed. Switching to evaluation mode...
1737231436986 1/RMR [INFO] sends: ts=1737231436 src=service-ricxapp-dc-rmr.ricxapp:4560 target=10.106.64.163:38000 open=1 succ=7 fail=0 (hard=0 soft=0)
1737231436986 1/RMR [INFO] sends: ts=1737231436 src=service-ricxapp-dc-rmr.ricxapp:4560 target=service-ricplt-e2term-rmr-alpha.ricplt:38000 open=0 succ=0 fail=0 (hard=0 soft=0)
1737231436986 1/RMR [INFO] sends: ts=1737231436 src=service-ricxapp-dc-rmr.ricxapp:4560 target=service-ricplt-submgr-rmr.ricplt:4560 open=1 succ=2 fail=0 (hard=0 soft=0)
1737231436986 1/RMR [INFO] sends: ts=1737231436 src=service-ricxapp-dc-rmr.ricxapp:4560 target=service-ricplt-e2mgr-rmr.ricplt:3801 open=0 succ=0 fail=0 (hard=0 soft=0)
1737231436986 1/RMR [INFO] sends: ts=1737231436 src=service-ricxapp-dc-rmr.ricxapp:4560 target=service-ricplt-a1mediator-rmr.ricplt:4562 open=0 succ=0 fail=0 (hard=0 soft=0)
1737231467986 1/RMR [INFO] sends: ts=1737231467 src=service-ricxapp-dc-rmr.ricxapp:4560 target=10.106.64.163:38000 open=1 succ=7 fail=0 (hard=0 soft=0)
1737231467986 1/RMR [INFO] sends: ts=1737231467 src=service-ricxapp-dc-rmr.ricxapp:4560 target=service-ricplt-e2term-rmr-alpha.ricplt:38000 open=0 succ=0 fail=0 (hard=0 soft=0)
1737231467986 1/RMR [INFO] sends: ts=1737231467 src=service-ricxapp-dc-rmr.ricxapp:4560 target=service-ricplt-submgr-rmr.ricplt:4560 open=1 succ=2 fail=0 (hard=0 soft=0)
1737231467986 1/RMR [INFO] sends: ts=1737231467 src=service-ricxapp-dc-rmr.ricxapp:4560 target=service-ricplt-e2mgr-rmr.ricplt:3801 open=0 succ=0 fail=0 (hard=0 soft=0)
1737231467986 1/RMR [INFO] sends: ts=1737231467 src=service-ricxapp-dc-rmr.ricxapp:4560 target=service-ricplt-a1mediator-rmr.ricplt:4562 open=0 succ=0 fail=0 (hard=0 soft=0)
